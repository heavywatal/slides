<!DOCTYPE html>
<html>
<head prefix="og: http://ogp.me/ns#">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<title>4. 階層ベイズモデル — 統計モデリング概論 DSHC 2021</title>
<link rel="stylesheet" href="/slides/lib/reveal.js/reveal.css">
<link rel="stylesheet" href="/slides/css/theme-reveal.css">
<meta name="author" content="Watal M. Iwasaki">
<meta property="og:title" content="4. 階層ベイズモデル — 統計モデリング概論 DSHC 2021">
<meta property="og:type" content="article">
<meta property="og:url" content="https://heavywatal.github.io/slides/tokiomarine2021/4-bayesian.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/heavywatal">
<meta property="og:description" content="">
<meta property="og:site_name" content="Slide decks — Heavy Watal">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@heavywatal">
<meta name="twitter:creator" content="@heavywatal">
<meta name="generator" content="Hugo 0.83.1" />
<link rel="stylesheet" href="/lib/katex/katex.min.css">
<script defer src="/lib/katex/katex.min.js"></script>
<script defer src="/lib/katex/contrib/auto-render.min.js"></script>
<script>
document.addEventListener("DOMContentLoaded", function() {
  renderMathInElement(document.body, {
    delimiters: [
      {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false}
    ]
  });
});
</script>
<style>
.katex {
  font-size: 1.12em;
}

.katex-display > .katex {
  text-align: left;
  padding-left: 2rem;
}
</style>

<script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin="anonymous"></script>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-41178626-2', 'auto');
	
	ga('send', 'pageview');
}
</script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section>
<link rel="stylesheet" href="style.css">
<h1 id="統計モデリング概論-dshc-2021"><a href=".">統計モデリング概論 DSHC 2021</a></h1>
<div class="author">
岩嵜 航 (Watal M. Iwasaki, PhD)
</div>
<div class="affiliation">
東北大学 生命科学研究科 進化ゲノミクス分野 特任助教<br>
(Graduate School of Life Sciences, Tohoku University)
</div>
<ol>
<li><a href="1-introduction.html">導入</a>
<li><a href="2-stats-model.html">統計モデルの基本</a>
<li><a href="3-glm.html">一般化線形モデル</a>
<li class="current-deck"><a href="4-bayesian.html">階層ベイズモデル</a>
</ol>
<div class="footnote">
2021-06-30 東京海上 Data Science Hill Climb
<a href="https://heavywatal.github.io/slides/tokiomarine2021/">https://heavywatal.github.io/slides/tokiomarine2021/</a>
</div>

</section>
<section>
<h2 id="コイントス4回たまたま表が1回だったら">コイントス4回、たまたま表が1回だったら</h2>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">
<dl>
<dt>最尤法(頻度主義)</dt>
<dd>尤もらしいパラメータを点推定。</dd>
<dd>データが少ないとき過剰適合気味。</dd>
<dd>表が出る確率 p = 0.25 のコインだろう。<br>
(信じ難いけどデータはこう言っている)</dd>
</dl>
<br>
<dl>
<dt>ベイズ推定</dt>
<dd>推定結果は確率分布そのもの。</dd>
<dd>データが少ないなりの不確実さも表現。</dd>
<dd>p = 0.25 らへんである確率は高いが、<br>
p = 0.6 とかである可能性もまあある。
</div>
<div class="column" style="flex-shrink: 1.4;">
</dd>
</dl>
<p><img src="figure/freq-vs-bayes-1.png" alt="plot of chunk freq-vs-bayes"><img src="figure/freq-vs-bayes-2.png" alt="plot of chunk freq-vs-bayes"></p>
  </div>
</div>

</section>
<section>
<h2 id="コイントスの回数が増えていったら">コイントスの回数が増えていったら</h2>
<p><strong>最尤法(頻度主義)</strong>: 推定値が真の値に近づいていく</p>
<p><img src="figure/coin-frequentist-1.png" alt="plot of chunk coin-frequentist"></p>
<p><strong>ベイズ推定</strong>: 確率分布がどんどん尖り、確信が強まる</p>
<p><img src="figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian"></p>

</section>
<section>
<h2 id="確率おさらい">確率おさらい</h2>
<dl>
<dt>同時分布/結合確率: <span style="font-weight: normal;"> <span style="color: #E69F00;">A</span>かつ<span style="color: #0072B2;">B</span>の確率</span></dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#E69F00}{A} \cap \textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#E69F00}{A}) \text{Prob}(\textcolor{#0072B2}{B})$</dd>
<dt>周辺確率: <span style="font-weight: normal;"> <span style="color: #0072B2;">B</span>によらず<span style="color: #E69F00;">A</span>になる確率</span></dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A}) = \sum_{\textcolor{#0072B2}{B}} \text{Prob}(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B})$</dd>
<dt>条件付き確率: <span style="font-weight: normal;"> <span style="color: #0072B2;">B</span>のとき<span style="color: #E69F00;">A</span>になる確率</span></dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B}) = \frac {\text{Prob}(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B})} {\text{Prob}(\textcolor{#0072B2}{B})}$</dd>
</dl>
<p><img src="figure/venn-1.png" alt="plot of chunk venn">
</section>
<section>
<h2 id="条件付き確率がよくわかる具体例">条件付き確率がよくわかる具体例</h2>
<dl>
<dt><span style="color: #0072B2;">B Brewery</span>のビールが<span style="color: #E69F00;">Awesome</span>な確率</dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{\text{Awesome}} \mid \textcolor{#0072B2}{\text{B Brewery}}) = \frac {\text{Prob}(\textcolor{#E69F00}{\text{Awesome}},~\textcolor{#0072B2}{\text{B Brewery}})} {\text{Prob}(\textcolor{#0072B2}{\text{B Brewery}})}$</dd>
<dd>かなり高い確率。良い醸造所。</dd>
<dt><span style="color: #E69F00;">Awesome</span>なビールが<span style="color: #0072B2;">B Brewery</span>のものである確率</dt>
<dd>$\text{Prob}(\textcolor{#0072B2}{\text{B Brewery}} \mid \textcolor{#E69F00}{\text{Awesome}}) = \frac {\text{Prob}(\textcolor{#E69F00}{\text{Awesome}},~\textcolor{#0072B2}{\text{B Brewery}})} {\text{Prob}(\textcolor{#E69F00}{\text{Awesome}})}$</dd>
<dd>かなり低い確率。Awesomeなビールはほかにもたっくさんある。</dd>
</dl>
<img src="figure/venn-1.png" alt="plot of chunk venn">

</section>
<section>
<h2 id="ベイズの定理">ベイズの定理</h2>
<dl>
<dt>乗法定理</dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A},~\textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B})~\text{Prob}(\textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A})~\text{Prob}(\textcolor{#E69F00}{A})$</dd>
</dl>
<p>移項するだけで<strong>ベイズの定理</strong>:
<img src="bayes.drawio.svg" style="padding-left: 1rem;"></p>
<p>宴会場にビールが運ばれてきた。これはどこのブルワリーの？</p>
<dl>
<dt>事前確率: $\text{Prob}(\textcolor{#0072B2}{B})$</dt>
<dd>飲む前、手元のビールが<span style="color: #0072B2;">B Brewery</span>のである確率。</dd>
<dd>↓ 🍻 飲んでみて更新</dd>
<dt>事後確率: $\text{Prob}(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A})$</dt>
<dd>飲んでみて<span style="color: #E69F00;">Awesome</span>だったビールが
<span style="color: #0072B2;">B Brewery</span>のである確率。</dd>
</dl>

</section>
<section>
<h2 id="ベイズの定理-in-感染症検査">ベイズの定理 in 感染症検査</h2>
<ul>
<li>有病率 $\text{Prob}(M)$ : 2% (この地域の感染者の割合)</li>
<li>感度 $\text{Prob}(P \mid M)$ : 80% (感染してる人に陽性判定が出る)</li>
<li>特異度 $\text{Prob}(N \mid \overline{M})$: 99% (感染してない人に陰性判定が出る)</li>
</ul>
<p>$\text{Prob}(M \mid P)$ 真陽性率(検査陽性の人が実際に感染者である確率)は？</p>
<div>\[\begin{split}
\text{Prob}(M \mid P)
  &= \frac {\text{Prob}(P \mid M)~\text{Prob}(M)} {\text{Prob}(P)} \\
  &= \frac {\text{Prob}(P \mid M)~\text{Prob}(M)}
           {\text{Prob}(P \mid M)~\text{Prob}(M) + (1 - \text{Prob}(N \mid \overline{M}))~\text{Prob}(\overline{M})} \\
  &= \frac {0.8 \times 0.02} {0.8 \times 0.02 + 0.01 \times 0.98} \approx 0.62
\end{split}\]</div>
<p>🔰 同様に真陰性率、偽陽性率、偽陰性率を計算してみよう<br>
🔰 計算結果が検査精度だけでなく有病率によっても変わることを確認しよう</p>

</section>
<section>
<h2 id="ベイズの定理-in-統計モデリング">ベイズの定理 in 統計モデリング</h2>
<p>
<img src="bayesian.drawio.svg">
</p>
<p><strong>周辺尤度</strong>は「確率分布の積分は1」を満たすための正規化定数とみなせる。<br>
比例関係だけ抜き出してこう書くことが多い:</p>
<div>\[\begin{split}
\text{Prob}(\mathcal M \mid \mathcal D) \propto \text{Prob}(\mathcal D \mid \mathcal M)~\text{Prob}(\mathcal M)
\end{split}\]</div>
<p>モデルの<strong>事後分布</strong> $\text{Prob}(\mathcal M \mid \mathcal D)$ は次の積に比例する:</p>
<ul>
<li><strong>尤度</strong> $\text{Prob}(\mathcal D \mid \mathcal M)$:
モデル$\mathcal M$の下で観察データ$\mathcal D$を得る確率</li>
<li><strong>事前分布</strong> $\text{Prob}(\mathcal M)$:
データ$\mathcal D$を得る前の思い込み</li>
</ul>
<p>解析前から持ってるモデル$\mathcal M$のに対すを、
データ$\mathcal D$を得て尤度計算して更新、
データ
確信の度合いをデータによって更新するようなイメージ。</p>

</section>
<section>
<h2 id="逐次学習">逐次学習</h2>
<p>コイントス4回のうち表1回、に基づく<strong>事前分布</strong>: $\text{Beta}(p \mid 1, 3)$</p>
<p>さらに16回投げたら表が7回、の<strong>尤度</strong>: $\text{Binomial}(7 \mid 16,~p)$</p>
<p><strong>事後分布</strong>を計算してみると、事前分布と同じ形になる:</p>
<div>\[\begin{split}
\text{Beta}(p \mid 8, 12) \propto
  \text{Beta}(p \mid 1, 3) \times \text{Binomial}(7 \mid 16,~p)
\end{split}\]</div>
<p>これを事前分布としてまた新しいデータで更新できる。</p>
<img src="figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian">

</section>
<section>
<h2 id="共役事前分布">共役事前分布</h2>
<p>事後分布が事前分布と同じ形なので計算しやすい、という組み合わせ。</p>
<table>
<thead>
<tr>
<th>尤度関数</th>
<th>共役事前分布</th>
</tr>
</thead>
<tbody>
<tr>
<td>二項分布</td>
<td>ベータ分布</td>
</tr>
<tr>
<td>ポアソン分布</td>
<td>ガンマ分布</td>
</tr>
<tr>
<td>正規分布</td>
<td>ガンマ分布</td>
</tr>
<tr>
<td>正規分布 (分散既知)</td>
<td>正規分布</td>
</tr>
</tbody>
</table>
<p>共役事前分布を使うことが常に正しいとも限らない。<br>
計算コストがかかっても<strong>無情報事前分布</strong>を使う風潮。</p>

</section>
<section>
<h2 id="事後分布を用いた推定">事後分布を用いた推定</h2>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">
<dl>
<dt>区間推定</dt>
<dd>幅のある推定値を提示</dd>
<dd>e.g., 95%ベイズ確信区間<br>(credible interval)</dd>
<dt>点推定</dt>
<dd>値を1点だけ提示</dd>
<dd>e.g., MAP推定
</div>
<div class="column" style="flex-shrink: 1.0;">
</dd>
</dl>
<p><img src="figure/integrate-1.png" alt="plot of chunk integrate"></p>
  </div>
</div>
<p>コイン投げモデルのベータ分布は美しい例。<br>
→ 解析的(数学的)に解ける。</p>
<p>実践的なモデル・事後分布はもっと複雑。<br>
→ コンピュータに頼って数値計算: MCMC</p>

</section>
<section>
<h2 id="mcmc-umuarcov-ucuhain-umuonte-ucuarlo">MCMC: <u>M</u>arcov <u>C</u>hain <u>M</u>onte <u>C</u>arlo</h2>
<a href="https://en.wikipedia.org/wiki/Andrey_Markov">
<img src="figure/AAMarkov.jpg" height="180" align="right"></a>
<dl>
<dt>マルコフ連鎖</dt>
<dd>次の時点の挙動が現在の値だけで決定されるような確率過程。</dd>
<dd>$\ldots \to X_{t - 2} \to X_{t - 1} \to X_{t} \to X_{t + 1}$</dd>
<dd>$\text{Prob}(X_{t+1} \mid X_{t}, X_{t-1}, X_{t-2}, \ldots) = \text{Prob}(X_{t+1} \mid X_{t})$</dd>
<dd>e.g., すごろく</dd>
<dt>モンテカルロ法</dt>
<dd>乱数を用いた計算方法の総称。</dd>
<dd><a href="https://en.wikipedia.org/wiki/Monte_Carlo_Casino">
<img src="figure/Real_Monte_Carlo_Casino.jpg" height="200"></a>
<a href="https://en.wikipedia.org/wiki/Stanislaw_Ulam">
<img src="figure/Stanislaw_Ulam.jpg" height="200"></a>
<a href="https://en.wikipedia.org/wiki/John_von_Neumann">
<img src="figure/John_von_Neumann.jpg" height="200"></a>
<a href="https://en.wikipedia.org/wiki/Nicholas_Metropolis">
<img src="figure/Nicholas_Metropolis.png" height="200"></a>
</dd>
</dl>

</section>
<section>
<h2 id="モンテカルロ法は乱数を用いた計算方法">モンテカルロ法は乱数を用いた計算方法</h2>
<p>e.g., 半径1の円の面積</p>
<p>面積4の正方形に400個の一様乱数を打ち込んだら318個乗った:<br>
$4 \times \frac {318} {400} = 3.18$</p>
<p><img src="figure/circle-1.png" alt="plot of chunk circle"></p>
<p>数学を知っていれば $\pi r ^ 2 \approx 3.14$</p>

</section>
<section>
<h2 id="変な分布もモンテカルロ法で扱えそう">変な分布もモンテカルロ法で扱えそう</h2>
<p>e.g., 確率密度分布に従って変数Xを集める(棄却サンプリング)。</p>
<p><img src="figure/mcpdf-1.png" alt="plot of chunk mcpdf"></p>
<p>でも、ハズレの値もけっこう引いてしまう。</p>

</section>
<section>
<h2 id="次元の呪い-高次元になるほど当たりにくくなる">次元の呪い: 高次元になるほど当たりにくくなる</h2>
<p>(N次元球の体積 / N次元の立方体) はゼロに近づいていく。</p>
<img src="figure/circle-1.png" width="210" align="right">
<ul>
<li>2次元: $\frac {\pi r ^ 2} {(2r) ^ 2} = \frac \pi 4 \approx 0.79$</li>
<li>3次元: $\frac {\frac 4 3 \pi r ^ 3} {(2r) ^ 3} = \frac \pi 6 \approx 0.52$</li>
<li>N次元: $\frac {\frac {\pi ^ {N/2}} {\Gamma (N/2 + 1)} r ^ N} {(2r) ^ N} = \frac {\pi ^ {N/2}} {2^N \Gamma (N/2 + 1)} \to 0$</li>
</ul>
<p>パラメータが増えると計算量(≈乱数の無駄撃ち)が急増。</p>
<hr>
<p>密度の高い「当たり」付近を効率よく探索したい。<br>
「当たり」は「当たり」の近くにありがちだろう。<br>
→ マルコフ連鎖が使えそう</p>

</section>
<section>
<h2 id="metropolis--hastings法-mh法">Metropolis&ndash;Hastings法 (MH法)</h2>
<ol start="0">
<li>パラメータ $\theta$ の初期値を選ぶ</li>
<li>$\theta$ をちょっと増減させて $\theta_\text{new}$ を作る</li>
<li>それぞれ尤度を計算し、比較。
<ul>
<li>$L(\theta_\text{new}) \ge L(\theta)$ なら $\theta_\text{new}$ を即採択</li>
<li>$L(\theta_\text{new}) &lt; L(\theta)$ でも
確率 $r = \frac {L(\theta_\text{new})} {L(\theta)}$ で  $\theta_\text{new}$ を採択</li>
</ul>
</li>
<li>$\theta_\text{new}$ が採択されたら $\theta$ を更新。手順1に戻る。</li>
</ol>
<p><img src="figure/metropolis-1.png" alt="plot of chunk metropolis">
</section>
<section>
<h2 id="採択されたパラメータ値の軌跡">採択されたパラメータ値の軌跡</h2>
<p>尤度が高い方にただ向かうだけでなく、結構うろつく。<br>
 </p>
<p><img src="figure/metropolis-trajectory-head-1.png" alt="plot of chunk metropolis-trajectory-head"></p>

</section>
<section>
<h2 id="採択されたパラメータ値の軌跡">採択されたパラメータ値の軌跡</h2>
<p>尤度が高い方にただ向かうだけでなく、結構うろつく。<br>
通ったパラメータ値を集めるといい感じの分布が得られる。</p>
<p><img src="figure/metropolis-trajectory-1.png" alt="plot of chunk metropolis-trajectory"></p>

</section>
<section>
<h2 id="尤度に比例する事後分布からサンプルしたのと等価">尤度に比例する事後分布からサンプルしたのと等価</h2>
<p>全体にばら撒く棄却サンプリングよりも効率よく集められる。<br>
が、パラメータ1つの1次元ではご利益はわかりにくい。</p>
<p><img src="figure/propto-lik-1.png" alt="plot of chunk propto-lik"></p>
<p>パラメータが複数ある場合は？</p>

</section>
<section>
<h2 id="gibbs-sampling">Gibbs Sampling</h2>
<p>「ほかを固定してひとつ更新」を繰り返す。</p>
<p>e.g., 二次元正規分布。(-2, 2) からスタート。</p>
<p><img src="figure/gibbs-1.png" alt="plot of chunk gibbs"></p>
<p>TODO: アニメーション、周辺分布</p>

</section>
<section>
<h2 id="中間まとめ">中間まとめ</h2>
<ul>
<li>ベイズ推定では不確実性も表現できる。</li>
<li>コンピュータに頼った計算方法としてのモンテカルロ法。</li>
<li>多次元でも効率よくサンプルするためのMCMC。</li>
</ul>
<hr>
<p>ここから、実行するにあたっての注意点を見ていく。
</section>
<section>
<h2 id="何回やっても似たような結果になってほしい">何回やっても似たような結果になってほしい</h2>
<p>乱数や初期値によって偶々、じゃないことを確認したい。</p>
<p>e.g., <code>chains = 3, iter = 600</code> 。ほぼ同じところをうろうろ:</p>
<p><img src="figure/chains-1.png" alt="plot of chunk chains"></p>
<p>収束(convergence)の判定については後ほど。</p>

</section>
<section>
<h2 id="初期値の影響が消えるまでウォーミングアップ">初期値の影響が消えるまでウォーミングアップ</h2>
<p>定常分布の山に到達してからが本番。</p>
<p>e.g., <code>iter = 600, warmup = 200</code> で灰色の部分を捨てる:</p>
<p><img src="figure/warmup-1.png" alt="plot of chunk warmup"></p>
<p>どれくらい長く捨てるべきかは場合による。</p>

</section>
<section>
<h2 id="適度に間引いて自己相関を軽減したい">適度に間引いて自己相関を軽減したい</h2>
<p>直前の値と似すぎていたら独立サンプルとして扱えないので。</p>
<p>e.g., <code>thin = 5</code> で5回に1回だけサンプルする:</p>
<p><img src="figure/thin-1.png" alt="plot of chunk thin"></p>
<p>間引かなくても大丈夫な場合も、間引いても解決しない場合もある。</p>

</section>
<section>
<h2 id="収束判定">収束判定</h2>
<ul>
<li>複数chains・複数初期値で実行し、軌跡や分布を可視化</li>
<li>Gelman-Rubin統計量 $\hat R &lt; 1.05$</li>
<li>Effective Sample Size (ESS) $N_\text{eff} &gt; 100$ per chain</li>
</ul>
<p>TODO: 収束してる例 vs してない例
</section>
<section>
<h2 id="収束自己相関が悪い場合にどう改善するか">収束・自己相関が悪い場合にどう改善するか</h2>
<ul>
<li>小手先の対処
<ul>
<li>warmupとiterをもっと長くする</li>
<li>thinを大きくして間引く</li>
</ul>
</li>
<li>ちょっと大掛かり
<ul>
<li>モデルを見直す</li>
<li>プログラムを見直す</li>
<li>アルゴリズム・ソフトウェアを変える</li>
</ul>
</li>
</ul>

</section>
<section>
<h2 id="mcmcの方法いろいろ">MCMCの方法いろいろ</h2>
<p>採択率を高め、早く収束するように改良されてきている。</p>
<ul>
<li>Metropolis&ndash;Hastings法
<ul>
<li>Gibbs Sampling</li>
<li>Hamiltonian Monte Carlo (HMC)
<ul>
<li>No-U-Turn Sampler (NUTS)</li>
</ul>
</li>
</ul>
</li>
</ul>

</section>
<section>
<h2 id="mcmcソフトウェア">MCMCソフトウェア</h2>
<ul>
<li><a href="https://www.mrc-bsu.cam.ac.uk/software/bugs/">BUGS</a>
<ul>
<li>クローズドソースで、ほぼWindows専用。</li>
</ul>
</li>
<li><a href="https://mcmc-jags.sourceforge.io/">JAGS</a>
<ul>
<li>オープンソースで、さまざまなOS・言語から利用可能。</li>
<li>マニュアルや用例が不足。</li>
</ul>
</li>
<li><a href="https://mc-stan.org/"><strong>Stan</strong></a> 👈
<ul>
<li>オープンソースで、さまざまなOS・言語から利用可能。</li>
<li>開発も利用も活発。マニュアルや用例も充実。</li>
<li>HMC/NUTSにより早く収束。</li>
</ul>
</li>
<li><a href="https://docs.pymc.io/">PyMC3</a></li>
<li><a href="https://num.pyro.ai/">NumPyro</a></li>
<li><a href="https://www.tensorflow.org/probability/">TensorFlow Probability</a></li>
</ul>

</section>
<section>
<h2 id="stan">Stan</h2>
<a href="https://mc-stan.org/">
<img src="/slides/figure/stan/logo_name.png" width="120" align="right">
</a>
<ul>
<li>C++で書かれている</li>
<li>Stan言語でモデルを書く</li>
<li>PythonやRなどから呼び出して使うのが便利</li>
</ul>

</section>
<section>
<h2 id="おおまかな流れ-in-r">おおまかな流れ in R</h2>
<p>TODO: in Python</p>
<div class="highlight"><pre class="chroma"><code class="language-r" data-lang="r"><span class="n">mydata</span> <span class="o">=</span> <span class="n">readr</span><span class="o">::</span><span class="nf">read_tsv</span><span class="p">(</span><span class="s">&#34;mydata.tsv.gz&#34;</span><span class="p">)</span>

<span class="c1"># Stan言語で書いたモデルをコンパイル</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">rstan</span><span class="o">::</span><span class="nf">stan_model</span><span class="p">(</span><span class="n">file</span> <span class="o">=</span> <span class="s">&#34;model1.stan&#34;</span><span class="p">)</span>

<span class="c1"># MCMCサンプリング</span>
<span class="n">fit1</span> <span class="o">=</span> <span class="n">rstan</span><span class="o">::</span><span class="nf">sampling</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">)</span>

<span class="c1"># 結果を眺める</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit1</span><span class="p">)</span>
<span class="n">rstan</span><span class="o">::</span><span class="nf">stan_trace</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="n">rstan</span><span class="o">::</span><span class="nf">stan_hist</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
<span class="n">rstan</span><span class="o">::</span><span class="nf">stan_ac</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
</code></pre></div>
</section>
<section>
<h2 id="stan言語でモデルを書く">Stan言語でモデルを書く</h2>
<p>いくつかのブロックに分ける。</p>
<pre><code class="language-stan" data-lang="stan">data {         // passed from R/Python
  int&lt;lower=0&gt; N;
  real x[N];
}

parameters {   // sampled via MCMC
  real mu;
  real&lt;lower=0&gt; sigma;
}

model {
  x ~ normal(mu, sigma);
}
</code></pre>
</section>
<section>
<h2 id="stan言語の7種のブロック">Stan言語の7種のブロック</h2>
<p>順番厳守。使うのはだいたい太字のやつだけ。</p>
<ol>
<li><code>functions {...}</code></li>
<li><strong><code>data {...}</code></strong></li>
<li><code>transformed data {...}</code></li>
<li><strong><code>parameters {...}</code></strong></li>
<li><code>transformed parameters {...}</code></li>
<li><strong><code>model {...}</code></strong></li>
<li><code>generated quantities {...}</code></li>
</ol>

</section>
<section>
<h2 id="変数の型">変数の型</h2>
<p>整数と実数は区別される。<br>
配列的なものが複数あってややこしい。</p>
<pre><code class="language-stan" data-lang="stan"># scalar
int N;
real x;

# linear algebra
vector[N] v;
row_vector[N] rv;
matrix[M, N] m;

# array
real a[N];
</code></pre><p>TODO: rstan 2.27 が出たら <code>array</code> syntax 更新</p>

</section>
<section>
<h2 id="data-"><code>data {...}</code></h2>
<p>R/Pythonから受け取る定数の宣言。</p>
<p>配列の大きさは動的に変えられない。<br>
上限・下限を設定可能。<br></p>
<pre><code class="language-stan" data-lang="stan">data {
  int&lt;lower=0&gt; N;
  real x[N];
}
</code></pre>
</section>
<section>
<h2 id="parameters-"><code>parameters {...}</code></h2>
<p>サンプリングされる変数の宣言。</p>
<pre><code class="language-stan" data-lang="stan">parameters {
  real mu;
  real&lt;lower=0&gt; sigma;
}
</code></pre>
</section>
<section>
<h2 id="model-"><code>model {...}</code></h2>
<p>確率変数と事前分布・パラメータの関係を記述。</p>
<pre><code class="language-stan" data-lang="stan">model {
  x ~ normal(mu, sigma);
}
</code></pre><p>このようにチルダを使うのは“sampling statement”。<br>
代わりに <code>target += normal_lpdf(x | mu, sigma);</code>
のように対数確率の加算を明示的に書いてもいい。</p>
<p>サンプルされないローカル変数を宣言してもよいが、制約をかけることはできない。</p>

</section>
<section>
<h2 id="関数">関数</h2>
<p><a href="https://mc-stan.org/docs/functions-reference/">定義済みの関数</a>がたくさんある。</p>
<p><code>functions</code> ブロックで<a href="https://mc-stan.org/docs/reference-manual/functions-chapter.html">新しい関数を定義する</a>ことも可能:</p>
<pre><code class="language-stan" data-lang="stan">real radius(real x, real y) {
  return sqrt(x ^ 2 + x ^ 2);
}
</code></pre>
</section>
<section>
<h2 id="other-blocks">Other blocks</h2>
<p><code>transformed data {...}</code></p>
<ul>
<li><code>data</code> ブロックで読み込む変数の決定論的変換</li>
<li>決め打ちのハイパーパラメータを宣言するとか</li>
</ul>
<p><code>transformed parameters {...}</code></p>
<ul>
<li><code>model</code> で使いやすい形にパラメータを変形しておくとか</li>
</ul>
<p><code>generated quantities {...}</code></p>
<ul>
<li>サンプリング後の値を使って好きなことをする。
ここを使わずR/Pythonで結果を受け取ってからどうにかするほうが簡単。</li>
</ul>

</section>
<section>
<h2 id="説明変数なしのベイズ推定をやってみる">説明変数なしのベイズ推定をやってみる</h2>

</section>
<section>
<h2 id="線形単回帰をわざわざstanでやってみる">線形単回帰をわざわざStanでやってみる</h2>

</section>
<section>
<h2 id="非線形回帰">非線形回帰</h2>
<p>非対称なひと山。応答変数も説明変数も正の値。</p>
<div>\[\begin{split}
y = ae ^ {-bx} - ce ^ {-dx}
\end{split}\]</div>
<p><img src="figure/non-linear-1.png" alt="plot of chunk non-linear"></p>

</section>
<section>
<h2 id="練習問題">練習問題</h2>

</section>
<section>
<h2 id="階層ベイズモデル">階層ベイズモデル</h2>
<p>GLMでは説明できない現象</p>
<figure>
<a href="https://kuboweb.github.io/-kubo/ce/LinksGlm.html">
<img src="figure/kubo-p2.png" width="100%">
<figcaption class="url">久保さん https://kuboweb.github.io/-kubo/ce/LinksGlm.html</figcaption>
</a>
</figure>

</section>
<section>
<h2 id="二項分布なはずなのにおかしい">二項分布なはずなのに、おかしい</h2>
<p>生存種子</p>
<p>個体差が過分散を起こしてるっぽい</p>

</section>
<section>
<h2 id="個体差をモデルに組み込みたい">個体差をモデルに組み込みたい</h2>
<p>個体差をそのままモデルに組み込むと<strong>過剰適合</strong><br>
(パラメータ数 ≥ サンプルサイズ)</p>
<p>個体差を「平均0、標準偏差$s$の正規分布」としてモデル化</p>
<p>パラメータ1つの追加で済む</p>

</section>
<section>
<h2 id="モデルの全体像">モデルの全体像</h2>
<p>事前分布のパラメータに、さらに事前分布を設定するので階層ベイズ</p>
<p>超パラメータ、超事前分布</p>

</section>
<section>
<h2 id="階層ベイズをstanで書くと">階層ベイズをStanで書くと</h2>

</section>
<section>
<h2 id="うまくフィットできた">うまくフィットできた</h2>
<p>事後分布からのMCMCサンプル
</section>
<section>
<h2 id="個体差だけでなくグループ差も考慮">個体差だけでなく、グループ差も考慮</h2>

</section>
<section>
<h2 id="階層ベイズモデルのほかの応用先">階層ベイズモデルのほかの応用先</h2>
<ul>
<li>時系列モデル (状態空間モデル)</li>
<li>空間構造のあるモデル (e.g., CARモデル)</li>
<li>欠損値の補完</li>
</ul>
<p>TODO: それぞれ理論・実践を紹介する？
</section>
<section>
<h2 id="事前分布の選別">事前分布の選別</h2>
<ol>
<li>
<p>とりあえず<strong>無情報事前分布</strong> $[-\infty, \infty]$。Stanのデフォルト。</p>
</li>
<li>
<p>収束が悪かったら<strong>弱情報事前分布</strong>を試す。<br>
事後分布を更新していったとき<strong>事前分布っぽさが残らない</strong>のが良い。</p>
<ul>
<li>取りうる値を逃すような狭すぎる分布はダメ。</li>
<li>狭すぎるよりはマシだが、広すぎても良くない。</li>
<li>一様分布 $[a, b]$ は一見無情報っぽくて良さそうだが、<br>
事後分布に裾野が残ったり絶壁ができたりしがちなので微妙。</li>
</ul>
<p>おすすめ: <strong>Student&rsquo;s t分布</strong>、正規分布、指数分布など。</p>
</li>
</ol>
<p><cite><a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations</a></cite></p>

</section>
<section>
<h2 id="stanおすすめ弱情報事前分布-students-t分布">Stanおすすめ弱情報事前分布: Student&rsquo;s t分布</h2>
<p>Student&rsquo;s $t(\nu=\nu_0, \mu = 0, \sigma = \sigma_0)$</p>
<ul>
<li>自由度 $\nu$: 小さいほど裾野が広い。$3 \le \nu_0 \le 7 $ で適当に固定。</li>
<li>スケール $\sigma$: 「推定したい値は$[-\sigma_0, \sigma_0]$に収まるだろう」という値。</li>
</ul>
<p><img src="figure/student_t-1.png" alt="plot of chunk student_t"></p>
<p>正の値しか取らない場合は <code>&lt;lower=0&gt;</code> として右半分だけ使うとか。</p>

</section>
<section>
<h2 id="区間推定-ベイズ確信区間-credible-interval">区間推定: ベイズ確信区間 (credible interval)</h2>
<p>e.g., 95%ベイズ確信区間 (credible interval): 真の値が95%の確率で含まれる区間。</p>
<p>等裾事後信用区間 (equal-tailed interval): 両端から2.5%ずつ削る</p>
<p>TODO: 図</p>
<p>最高密度区間 (highest density interval): 分布密度に閾値を設ける</p>
<p>TODO: 図</p>

</section>
<section>
<h2 id="点推定">点推定</h2>
<ul>
<li>事後中央値 (Posteriori <u>Med</u>ian: MED)</li>
<li>事後期待値 (<u>E</u>xpected <u>A</u> <u>P</u>osteriori: EAP)</li>
<li>事後確率最大値 (<u>M</u>aximum <u>A</u> <u>P</u>osteriori: MAP)</li>
</ul>
<p>TODO: 図
</section>
<section>
<h2 id="ベイズ推定まとめ">ベイズ推定まとめ</h2>

</section>
<section>
<h2 id="階層ベイズの練習問題">階層ベイズの練習問題</h2>

</section>
<section>
<h2 id="全体まとめ">全体まとめ</h2>

</section>
<section>
<h2 id="参考文献">参考文献</h2>
<ul>
<li><a href="https://amzn.to/33suMIZ">データ解析のための統計モデリング入門</a> 久保拓弥 2012</li>
<li><a href="https://amzn.to/3uwx7Pb">StanとRでベイズ統計モデリング</a> 松浦健太郎 2016</li>
<li><a href="https://amzn.to/3o1eCzP">RとStanではじめる ベイズ統計モデリングによるデータ分析入門</a> 馬場真哉 2019</li>
<li><a href="https://amzn.to/3ty80Kv">統計学を哲学する</a> 大塚淳 2020</li>
<li><a href="https://amzn.to/3uCxTKo">データ解析のための数理モデル入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3uznzCK">分析者のためのデータ解釈学入門</a> 江崎貴裕 2020</li>
</ul>
<a href="." class="readmore">
目次に戻る
</a>

</section>
</div>
</div>
<script src="/slides/lib/reveal.js/reveal.js"></script>
<script src="/slides/lib/reveal.js/plugin/notes.js"></script>
<script>
Reveal.initialize({
  width: 960,
  height: 720,
  margin: 0,
  controls: true,
  controlsLayout: 'bottom-right',
  controlsTutorial: false,
  controlsBackArrows: 'faded',
  progress: false,
  slideNumber: 'c/t',
  showSlideNumber: 'all',
  hashOneBasedIndex: true,
  hash: true,
  history: false,
  keyboard: true,
  overview: true,
  center: false,
  touch: true,
  loop: false,
  rtl: false,
  navigationMode: 'linear',
  shuffle: false,
  fragments: true,
  fragmentInURL: true,
  embedded: false,
  help: true,
  showNotes: false,
  autoPlayMedia: null,
  preloadIframes: null,
  mouseWheel: false,
  previewLinks: false,
  transition: 'none',
  transitionSpeed: 'fast',
  backgroundTransition: 'none',
  pdfMaxPagesPerSlide: 1,
  pdfSeparateFragments: false,
  viewDistance: 2,
  plugins: [ RevealNotes ]
});
</script>
<script>
{
const reload_all_img = function() {
  const imgs = document.getElementsByTagName("img");
  for (let i = 0; i < imgs.length; ++i) {
    const src = imgs[i].src;
    imgs[i].src += "?q";
    imgs[i].src = src;
  }
};
const reload_src_element = function(ev) {
  const original_src = ev.srcElement.src;
  ev.srcElement.src += "?q";
  ev.srcElement.src = original_src;
};
const reload_src = function(ev) {
  if (ev.shiftKey || ev.metaKey || ev.altKey) {
    reload_all_img();
  } else {
    reload_src_element(ev);
  }
};
const img_elements = document.getElementsByTagName("img");
for (let i = 0; i < img_elements.length; ++i) {
  img_elements[i].onclick = reload_src;
}
};
</script>
</body>
</html>
