# %% [markdown]
# # çµ±è¨ˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°æ¦‚è«– DSHC 2022
#
# å²©åµœ èˆª (Watal M. Iwasaki, PhD)<br>
# æ±åŒ—å¤§å­¦ ç”Ÿå‘½ç§‘å­¦ç ”ç©¶ç§‘ é€²åŒ–ã‚²ãƒãƒŸã‚¯ã‚¹åˆ†é‡ ç‰¹ä»»åŠ©æ•™
#
# 2022-08-24 æ±äº¬æµ·ä¸Š Data Science Hill Climb<br>
# https://heavywatal.github.io/slides/tokiomarine2022/
#
# ## Pythonã‹ã‚‰Stanã‚’ä½¿ã†ã€ãŠãŠã¾ã‹ãªæµã‚Œ
# - ãƒ‡ãƒ¼ã‚¿æº–å‚™
# - Stanè¨€èªã§ãƒ¢ãƒ‡ãƒ«ã‚’æ›¸ã
# - ãã‚Œã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¦æ©Ÿæ¢°èªã«ç¿»è¨³â†’å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«
# - å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ¸¡ã—ã¦MCMCã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
# - çµæœã‚’è¦‹ã‚‹
#
# ## ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

# %% active="py"
# %pip install 'matplotlib>=3.1' 'seaborn>=0.11' 'statsmodels'
# %pip install 'arviz>=0.12.1' 'cmdstanpy>=1.0.4'

# %%
from pathlib import Path

import arviz as az
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import statsmodels.api as sm
from cmdstanpy import CmdStanModel
from scipy.special import expit

rng = np.random.default_rng(seed=24601)

# %% [markdown]
# ## å˜ç´”ãªç›´ç·šå›å¸°
#
# ### ãƒ‡ãƒ¼ã‚¿æº–å‚™
#
# %%
penguins = sm.datasets.get_rdataset("penguins", "palmerpenguins", True).data
penguins_dropna = penguins.dropna()
print(penguins_dropna)
pen_data = {
    "N": penguins_dropna.shape[0],
    "body_mass_g": penguins_dropna.body_mass_g,
    "flipper_length_mm": penguins_dropna.flipper_length_mm,
}

# %% [markdown]
# ### ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
# %%
model_code = """
data {
  int<lower=0> N;
  vector<lower=0>[N] body_mass_g;
  vector<lower=0>[N] flipper_length_mm;
}

parameters {
  real intercept;
  real slope;
  real<lower=0> sigma;
}

model {
  flipper_length_mm ~ normal(intercept + slope * body_mass_g, sigma);
}
"""
stan_file = Path("penguins-lm.stan")
if not stan_file.exists():
    with open(stan_file, "w") as fout:
        fout.write(model_code)

model = CmdStanModel(stan_file=stan_file)

# %% [markdown]
# ### MCMCã‚µãƒ³ãƒ—ãƒ«
# %%
fit = model.sample(pen_data, chains=4, iter_sampling=2000)

# %% [markdown]
# ### æ¨å®šçµæœã®è¦ç´„ã¨åæŸè¨ºæ–­
# %%
fit.summary()
# %%
print(fit.diagnose())

# %% [markdown]
# ### ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆç¢ºèª
# åˆ†å¸ƒã¯ãã‚Œã„ãªã²ã¨å±±ã€è»Œè·¡ã¯ãã‚Œã„ãªæ¯›è™«
# %%
stan_data = az.from_cmdstanpy(fit, observed_data=pen_data)
az.plot_trace(stan_data)

# %% [markdown]
#
# ### æ¨å®šçµæœã®äº‹å¾Œåˆ†å¸ƒã‚’ç¢ºèª
# - ç‚¹æ¨å®š: äº‹å¾Œåˆ†å¸ƒå¹³å‡
# - åŒºé–“æ¨å®š: HDI(Highest Density Interval)
# %%
az.plot_posterior(stan_data)

# %% [markdown]
# äº‹å¾Œåˆ†å¸ƒã®å¹³å‡ã‚’ä½¿ã£ã¦å›å¸°ç·šã‚’å¼•ã„ã¦ã¿ã‚‹ã€‚
# %%
post_mean = stan_data.posterior.mean().to_pandas()

# %%
pen_pred = penguins.assign(
    pred=post_mean["intercept"] + penguins_dropna.body_mass_g * post_mean["slope"]
)
grid = sns.FacetGrid(pen_pred)
grid.map(sns.scatterplot, "body_mass_g", "flipper_length_mm")
grid.map(sns.lineplot, "body_mass_g", "pred")


# %% [markdown]
# ### ğŸ”° ç›´ç·šå›å¸°ã®ç·´ç¿’å•é¡Œ
# TODO

# %%

# %% [markdown]
# ----
#
# ## Stanã§ãƒã‚¢ã‚½ãƒ³å›å¸°

# %%
_N = 300
_x = rng.uniform(0.4, 1.7, _N)
_y = rng.poisson(np.exp(3 * _x - 3))
df_poisson = pd.DataFrame(dict(x=_x, y=_y))
poisson_data = {
    "N": _N,
    "x": _x,
    "y": _y,
}
# %%
model_code = """
data {
  int<lower=0> N;
  vector<lower=0>[N] x;
  array[N] int<lower=0> y;
}

parameters {
  real intercept;
  real slope;
}

model {
  y ~ poisson(exp(intercept + slope * x));
}
"""
stan_file = Path("poisson.stan")
if not stan_file.exists():
    with open(stan_file, "w") as fout:
        fout.write(model_code)

model = CmdStanModel(stan_file=stan_file)

# %%
fit = model.sample(poisson_data, chains=4, iter_sampling=2000)
fit.summary()
print(fit.diagnose())

# %%
stan_data = az.from_cmdstanpy(fit, observed_data=poisson_data)
az.plot_trace(stan_data)
az.plot_posterior(stan_data)
# %%
post_mean = stan_data.posterior.mean().to_pandas()
df_poisson_pred = df_poisson.assign(
    pred=np.exp(post_mean["intercept"] + post_mean["slope"] * df_poisson.x)
)
grid = sns.FacetGrid(df_poisson_pred)
grid.map(sns.scatterplot, "x", "y")
grid.map(sns.lineplot, "x", "pred")
grid.add_legend()

# %% [markdown]
# ### ğŸ”° ãƒã‚¢ã‚½ãƒ³å›å¸°ã®ç·´ç¿’å•é¡Œ
# TODO

# %%

# %% [markdown]
# ----
# ## Stanã§ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°
#
# %%
_N = 200
_n = 10
temp = rng.uniform(-10, 35, size=_N)
logit_p = -3 + np.array(0.3) * temp
p = expit(logit_p)
sales = rng.binomial(_n, p)

df_logistic = pd.DataFrame(dict(temp=temp, sales=sales))
logistic_data = {
    "N": _N,
    "temp": temp,
    "sales": sales,
}
# %%
model_code = """
data {
  int<lower=0> N;
  vector[N] temp;
  array[N] int<lower=0,upper=10> sales;
}

parameters {
  real intercept;
  real slope;
}

model {
  sales ~ binomial(10, inv_logit(intercept + slope * temp));
}
"""
stan_file = Path("binomial.stan")
if not stan_file.exists():
    with open(stan_file, "w") as fout:
        fout.write(model_code)

model = CmdStanModel(stan_file=stan_file)

# %%
fit = model.sample(logistic_data, chains=4, iter_sampling=2000)
fit.summary()
print(fit.diagnose())

# %%
stan_data = az.from_cmdstanpy(fit, observed_data=logistic_data)
az.plot_trace(stan_data)
az.plot_posterior(stan_data)
# %%
post_mean = stan_data.posterior.mean().to_pandas()
df_logistic_pred = df_logistic.assign(
    pred=10 * expit(post_mean["intercept"] + post_mean["slope"] * df_logistic.temp)
)
grid = sns.FacetGrid(df_logistic_pred)
grid.map(sns.scatterplot, "temp", "sales")
grid.map(sns.lineplot, "temp", "pred")
grid.add_legend()

# %% [markdown]
#
# ### ğŸ”° ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã®ç·´ç¿’å•é¡Œ
# TODO
# %%

# %% [markdown]
# ----
#
# ## Stanã§é‡å›å¸°
#
# ### ãƒ‡ãƒ¼ã‚¿æº–å‚™
# %%
penguins_sp = (penguins_dropna
  .assign(sp_Chinstrap=(penguins_dropna.species == "Chinstrap").astype(int))
  .assign(sp_Gentoo=(penguins_dropna.species == "Gentoo").astype(int))
)
pen_sp_data = {
    "N": penguins_sp.shape[0],
    "body_mass_g": penguins_sp.body_mass_g,
    "flipper_length_mm": penguins_sp.flipper_length_mm,
    "sp_Chinstrap": penguins_sp.sp_Chinstrap,
    "sp_Gentoo": penguins_sp.sp_Gentoo,
}

# %% [markdown]
# ### ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
# %%
model_code = """
data {
  int<lower=0> N;
  vector<lower=0>[N] body_mass_g;
  vector<lower=0>[N] flipper_length_mm;
  array[N] int<lower=0,upper=1> sp_Chinstrap;
  array[N] int<lower=0,upper=1> sp_Gentoo;
}

parameters {
  real intercept;
  real slope;
  real b_chinstrap;
  real b_gentoo;
  real<lower=0> sigma;
}

model {
  array[N] real mu;
  for (i in 1:N) {
    mu[i] = intercept + slope * body_mass_g[i] + b_chinstrap * sp_Chinstrap[i] + b_gentoo * sp_Gentoo[i];
  }
  flipper_length_mm ~ normal(mu, sigma);
}
"""
stan_file = Path("penguins-multiple.stan")
if not stan_file.exists():
    with open(stan_file, "w") as fout:
        fout.write(model_code)

model = CmdStanModel(stan_file=stan_file)

# %% [markdown]
# ### MCMCã‚µãƒ³ãƒ—ãƒ«
# %%
fit = model.sample(pen_sp_data, chains=4, iter_sampling=2000)

# %% [markdown]
# ### æ¨å®šçµæœã®è¦ç´„ã¨åæŸè¨ºæ–­
# %%
fit.summary()
# %%
print(fit.diagnose())

# %% [markdown]
# ### ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆç¢ºèª
# åˆ†å¸ƒã¯ãã‚Œã„ãªã²ã¨å±±ã€è»Œè·¡ã¯ãã‚Œã„ãªæ¯›è™«
# %%
stan_data = az.from_cmdstanpy(fit, observed_data=pen_sp_data)
az.plot_trace(stan_data)

# %% [markdown]
#
# ### æ¨å®šçµæœã®äº‹å¾Œåˆ†å¸ƒã‚’ç¢ºèª
# - ç‚¹æ¨å®š: äº‹å¾Œåˆ†å¸ƒå¹³å‡
# - åŒºé–“æ¨å®š: HDI(Highest Density Interval)
# %%
az.plot_posterior(stan_data)

# %% [markdown]
# äº‹å¾Œåˆ†å¸ƒã®å¹³å‡ã‚’ä½¿ã£ã¦å›å¸°ç·šã‚’å¼•ã„ã¦ã¿ã‚‹ã€‚
# %%
post_mean = stan_data.posterior.mean().to_pandas()

# %%
pen_pred = penguins_sp.assign(
    pred=post_mean["intercept"] + penguins_sp.body_mass_g * post_mean["slope"] +
         penguins_sp["sp_Chinstrap"] * post_mean["b_chinstrap"] +
         penguins_sp["sp_Gentoo"] * post_mean["b_gentoo"]
)
palette = {"Adelie": "#ff6600", "Gentoo": "#c35bcc", "Chinstrap": "#007174"}
grid = sns.FacetGrid(pen_pred, hue="species", palette=palette)
grid.map(sns.scatterplot, "body_mass_g", "flipper_length_mm")
grid.map(sns.lineplot, "body_mass_g", "pred")
grid.add_legend()

# %% [markdown]
#
# ### ğŸ”° é‡å›å¸°ã®ç·´ç¿’å•é¡Œ
# TODO
# %%

# %%
# pyright: reportGeneralTypeIssues=false
# pyright: reportMissingTypeStubs=false
# pyright: reportUnknownArgumentType=false
# pyright: reportUnknownMemberType=false
# pyright: reportUnknownVariableType=false
