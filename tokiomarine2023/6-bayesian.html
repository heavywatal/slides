<!DOCTYPE html>
<html lang="ja">
<head prefix="og: http://ogp.me/ns#">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<title>6. ベイズの定理、事後分布、MCMC — 統計モデリング概論 DSHC 2023</title>
<meta name="author" content="Watal M. Iwasaki">
<meta property="og:title" content="6. ベイズの定理、事後分布、MCMC — 統計モデリング概論 DSHC 2023">
<meta property="og:type" content="article">
<meta property="og:url" content="https://heavywatal.github.io/slides/tokiomarine2023/6-bayesian.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/heavywatal">
<meta property="og:description" content="">
<meta property="og:site_name" content="Slide decks — Heavy Watal">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@heavywatal">
<meta name="twitter:creator" content="@heavywatal">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-V60H2JH0G6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-V60H2JH0G6');
</script>
<link rel="stylesheet" href="/slides/lib/reveal.js/reveal.css">
<script type="module">
import { Reveal } from "/slides/lib/reveal.js/reveal.js";
Reveal.configure({width: 1333, height: 1000});
</script>
<style>
html { font-size: 222%; }
</style>
<link rel="stylesheet" href="/slides/lib/katex/katex.min.css">
<script type="module" src="/slides/lib/katex/katex.min.js"></script>
<script type="module" src="/slides/lib/iconify.js"></script>
<script defer src="/slides/lib/reload-img-onclick.js"></script>
<link rel="stylesheet" href="/slides/css/style-reveal.css">
<link rel="stylesheet" href="style.css">
</head>
<body>
<div class="reveal">
<div class="slides">
<section>
<h1 id="統計モデリング概論-dshc-2023"><a href=".">統計モデリング概論 DSHC 2023</a></h1>
<div class="author">
岩嵜 航 (Watal M. Iwasaki, PhD)
</div>
<div class="affiliation">
東北大学 生命科学研究科 進化ゲノミクス分野 特任助教<br>
(Graduate School of Life Sciences, Tohoku University)
</div>
<ol>
<li><a href="1-introduction.html">導入</a>
<li><a href="2-distribution.html">直線回帰、確率分布、擬似乱数生成</a>
<li><a href="3-likelihood.html">尤度、最尤推定</a>
<li><a href="4-glm.html">一般化線形モデル(GLM)</a>
<li><a href="5-glmm.html">個体差、一般化線形混合モデル(GLMM)</a>
<li class="current-deck"><a href="6-bayesian.html">ベイズの定理、事後分布、MCMC</a>
<li><a href="7-stan.html">StanでGLM</a>
<li><a href="8-hbm.html">階層ベイズモデル(HBM)</a>
</ol>
<div class="footnote">
2023-08-30 東京海上 Data Science Hill Climb<br>
<a href="https://heavywatal.github.io/slides/tokiomarine2023/">https://heavywatal.github.io/slides/tokiomarine2023/</a>
</div>

</section>
<section>
<h2 id="コイントス4回たまたま表が1回だったら">コイントス4回、たまたま表が1回だったら</h2>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">
<dl>
<dt>最尤推定</dt>
<dd>推定結果は最も尤もらしい1点。</dd>
<dd>データが少ないとき過剰適合気味。</dd>
<dd>表が出る確率 p = 0.25 のコインだろう。<br>
(信じ難いけどデータはこう言っている)</dd>
</dl>
<br>
<dl>
<dt>ベイズ推定</dt>
<dd>推定結果は確率分布そのもの。</dd>
<dd>データが少ないなりの不確実さも表現。</dd>
<dd>p = 0.25 らへんである確率は高いが、<br>
p = 0.6 とかである可能性もまあある。
</div>
<div class="column" style="flex-shrink: 1.4;">
</dd>
</dl>
<p><img src="./figure/freq-vs-bayes-1.png" alt="plot of chunk freq-vs-bayes"><img src="./figure/freq-vs-bayes-2.png" alt="plot of chunk freq-vs-bayes"></p>
  </div>
</div>
</section>
<section>
<h2 id="コイントスの回数が増えていったら">コイントスの回数が増えていったら</h2>
<p><strong>最尤推定</strong>: 推定値が真の値に近づいていく</p>
<p><img src="./figure/coin-frequentist-1.png" alt="plot of chunk coin-frequentist"></p>
<p><strong>ベイズ推定</strong>: 確率分布がどんどん尖り、確信が強まる</p>
<p><img src="./figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian"></p>

</section>
<section>
<h2 id="確率おさらい">確率おさらい</h2>
<dl>
<dt>同時分布/結合確率: <span style="font-weight: normal;"> <span style="color: #E69F00;">A</span>かつ<span style="color: #0072B2;">B</span>の確率</span></dt>
<dd>$\Pr(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B}) = \Pr(\textcolor{#E69F00}{A} \cap \textcolor{#0072B2}{B}) = \Pr(\textcolor{#E69F00}{A}) \Pr(\textcolor{#0072B2}{B})$</dd>
<dt>周辺確率: <span style="font-weight: normal;"> <span style="color: #0072B2;">B</span>によらず<span style="color: #E69F00;">A</span>になる確率</span></dt>
<dd>$\Pr(\textcolor{#E69F00}{A}) = \sum_{\textcolor{#0072B2}{B}} \Pr(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B})$</dd>
<dt>条件付き確率: <span style="font-weight: normal;"> <span style="color: #0072B2;">B</span>である条件の下で<span style="color: #E69F00;">A</span>になる確率。重要。</span></dt>
<dd>$\Pr(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B}) = \frac {\Pr(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B})} {\Pr(\textcolor{#0072B2}{B})}$</dd>
</dl>
<p><img src="./figure/venn-1.png" alt="plot of chunk venn"></p>
</section>
<section>
<h2 id="条件付き確率がよくわかる具体例">条件付き確率がよくわかる具体例</h2>
<dl>
<dt><span style="color: #0072B2;">B Brewery</span>のビールが<span style="color: #E69F00;">Awesome</span>な確率</dt>
<dd>$\Pr(\textcolor{#E69F00}{\text{Awesome}} \mid \textcolor{#0072B2}{\text{B Brewery}}) = \frac {\Pr(\textcolor{#E69F00}{\text{Awesome}},~\textcolor{#0072B2}{\text{B Brewery}})} {\Pr(\textcolor{#0072B2}{\text{B Brewery}})}$</dd>
<dd>かなり高い確率。良い醸造所。</dd>
<dt><span style="color: #E69F00;">Awesome</span>なビールが<span style="color: #0072B2;">B Brewery</span>のものである確率</dt>
<dd>$\Pr(\textcolor{#0072B2}{\text{B Brewery}} \mid \textcolor{#E69F00}{\text{Awesome}}) = \frac {\Pr(\textcolor{#E69F00}{\text{Awesome}},~\textcolor{#0072B2}{\text{B Brewery}})} {\Pr(\textcolor{#E69F00}{\text{Awesome}})}$</dd>
<dd>かなり低い確率。Awesomeなビールはほかにもたっくさんある。</dd>
</dl>
<img src="figure/venn-1.png" alt="plot of chunk venn">

</section>
<section>
<h2 id="ベイズの定理">ベイズの定理</h2>
<dl>
<dt>乗法定理</dt>
<dd>$\Pr(\textcolor{#E69F00}{A},~\textcolor{#0072B2}{B}) = \Pr(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B})~\Pr(\textcolor{#0072B2}{B}) = \Pr(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A})~\Pr(\textcolor{#E69F00}{A})$</dd>
</dl>
<a href="https://en.wikipedia.org/wiki/Thomas_Bayes">
<img src="../tokiomarine2021/image/Thomas_Bayes.gif" height="200" align="right"></a>
<p>移項するだけで<strong>ベイズの定理</strong>:</p>
<div>
<div style="margin-block: -0.5em;">
<span class="bubble left30" style="margin-inline-start: 2em;">事後確率</span>
<span class="bubble" style="margin-inline-start: 6em;">事前確率</span>
</div>
\[
\Pr(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A}) = \frac
{\Pr(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B})~\Pr(\textcolor{#0072B2}{B})}
{\Pr(\textcolor{#E69F00}{A})}
\]
</div>
<p>宴会場にビールが運ばれてきた。これはどこのブルワリーの？</p>
<dl>
<dt>事前確率: $\Pr(\textcolor{#0072B2}{B})$</dt>
<dd>飲む前、手元のビールが<span style="color: #0072B2;">B Brewery</span>のである確率。</dd>
<dd>↓ 🍻 飲んでみて更新</dd>
<dt>事後確率: $\Pr(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A})$</dt>
<dd>飲んでみて<span style="color: #E69F00;">Awesome</span>だったビールが
<span style="color: #0072B2;">B Brewery</span>のである確率。</dd>
</dl>

</section>
<section>
<h2 id="ベイズの定理-in-感染症検査">ベイズの定理 in 感染症検査</h2>
<ul>
<li>有病率 $\Pr(I)$ : 0.3% (この地域の感染者の割合; 事前確率)</li>
<li>感度 $\Pr(P \mid I)$ : 90% (感染してる人に陽性判定が出る)</li>
<li>特異度 $\Pr(\lnot P \mid \lnot I)$: 99% (感染してない人に陰性判定が出る)</li>
</ul>
<p>さて、陽性適中率(検査陽性の人が実際に感染者である確率)は？</p>
<div>\[\begin{split}
\Pr(I \mid P)
  &= \frac {\Pr(P \mid I)~\Pr(I)} {\Pr(P)} \\
  &= \frac {\Pr(P \mid I)~\Pr(I)}
           {\Pr(P \mid I)~\Pr(I) + \Pr(P \mid \lnot I)~\Pr(\lnot I)} \\
  &= \frac {0.9 \times 0.003} {0.9 \times 0.003 + 0.01 \times 0.997} \approx 0.21
\end{split}\]</div>
<p>感染者を隔離するスクリーニング目的では使いものにならない性能。</p>
<p>🔰 同様に $\Pr(\lnot I \mid \lnot P)$ 陰性的中率を計算してみよう<br>
🔰 計算結果が検査性能だけでなく有病率にも依存することを確認しよう</p>

</section>
<section>
<h2 id="ベイズの定理-in-統計モデリング">ベイズの定理 in 統計モデリング</h2>
<p>
<div style="margin-block-end: -0.5em;">
<span class="bubble left30" style="margin-inline-start: 2em;">事後分布</span>
<span class="bubble" style="margin-inline-start: 2em;">尤度</span>
<span class="bubble" style="margin-inline-start: 2em;">事前分布</span>
</div>
<div>\[
\Pr(M \mid D) = \frac {\Pr(D \mid M)~\Pr(M)} {\Pr(D)}
\]</div>
<div style="margin-block-start: -0.5em;">
<span class="bubble flipY" style="margin-inline-start: 11em;">周辺尤度</span>
<div>
</p>
<p>モデル$M$に対する確信度合いをデータ$D$に基づいて更新する。<br>
モデル$M$を仮説$H$やパラメータ$\theta$に置き換えてもいい。</p>
<p><strong>周辺尤度</strong>は「確率分布の積分は1」を満たすための正規化定数とみなせる。<br>
比例関係だけ抜き出してこう書くことが多い:</p>
<div>\[\begin{align}
\Pr(M \mid D) &\propto \Pr(D \mid M)~\Pr(M) \tag{Model}\\
\Pr(H \mid D) &\propto \Pr(D \mid H)~\Pr(H) \tag{Hypothesis} \\
\Pr(\theta \mid D) &\propto \Pr(D \mid \theta)~\Pr(\theta) \tag{Parameter}
\end{align}\]</div>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-1-事前分布">表が出る確率のベイズ推定: 1. 事前分布</h2>
<div class="column-container">
  <div class="column" style="opacity: 0.2;">
<img src="figure/posterior-beta-1.png" alt="plot of chunk posterior-beta" style="vertical-align: middle;">
&ensp;$\propto$
  </div>
  <div class="column" style="opacity: 0.2;">
<img src="figure/likelihood-binom-1.png" alt="plot of chunk likelihood-binom" style="vertical-align: middle;">
&ensp;⨉
  </div>
  <div class="column">
<img src="figure/prior-beta-1.png" alt="plot of chunk prior-beta" style="vertical-align: middle;">
  </div>
</div>
<p>コイントスを繰り返して、表が出る確率pをベイズ推定したい。</p>
<p>事前分布には<strong>ベータ分布</strong>を採用(理由は後で分かる):</p>
<div>\[\begin{split}
\text{Beta}(p \mid a, b) =
   \frac{\Gamma(a + b)}{\Gamma(a) \Gamma(b)} p^{a-1} (1 - p)^{b-1}
\end{split}\]</div>
<p>分布の形は $a,~b$ によって決まる。<br>
ガンマ関数の部分は厳つく見えるけどただの正規化定数。<br>
投げる前なのでとりあえず真っ平らを仮定 $\text{Beta}(p \mid a = 1, b = 1)$:</p>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-2-尤度関数">表が出る確率のベイズ推定: 2. 尤度関数</h2>
<div class="column-container">
  <div class="column" style="opacity: 0.2;">
<img src="figure/posterior-beta-1.png" alt="plot of chunk posterior-beta" style="vertical-align: middle;">
&ensp;$\propto$
  </div>
  <div class="column">
<img src="figure/likelihood-binom-1.png" alt="plot of chunk likelihood-binom" style="vertical-align: middle;">
&ensp;⨉
  </div>
  <div class="column" style="opacity: 0.2;">
<img src="figure/prior-beta-1.png" alt="plot of chunk prior-beta" style="vertical-align: middle;">
  </div>
</div>
<p>4回投げて表が1回だった、というデータで<strong>尤度</strong>を計算(<strong>二項分布</strong>):</p>
<div>\[\begin{split}
\text{Binom}(1 \mid 4,~p) = \binom {1} {4} p^{1} (1 - p)^{3}
\end{split}\]</div>
<p>これに事前分布を掛けて正規化したら事後分布になるはず。</p>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-3-事後分布">表が出る確率のベイズ推定: 3. 事後分布</h2>
<div class="column-container">
  <div class="column">
<img src="figure/posterior-beta-1.png" alt="plot of chunk posterior-beta" style="vertical-align: middle;">
&ensp;$\propto$
  </div>
  <div class="column" style="opacity: 0.66;">
<img src="figure/likelihood-binom-1.png" alt="plot of chunk likelihood-binom" style="vertical-align: middle;">
&ensp;⨉
  </div>
  <div class="column" style="opacity: 0.66;">
<img src="figure/prior-beta-1.png" alt="plot of chunk prior-beta" style="vertical-align: middle;">
  </div>
</div>
<p>なんと、事後分布もベータ分布になる。</p>
<div>\[\begin{split}
\text{Posterior}
  &\propto \text{Binom}(1 \mid 4,~p) \times \text{Beta}(p \mid  1, 1)\\
  &= \binom {1} {4} p^{1} (1 - p)^{3} \times
     \frac{\Gamma(1 + 1)}{\Gamma(1) \Gamma(1)} p^{1-1} (1 - p)^{1-1} \\
  &= C p^{2-1} (1 - p)^{4-1} \\
  &= \text{Beta}(p \mid 2, 4)
\end{split}\]</div>
<p>ベータ分布の形パラメータ$a$が表、$b$が裏の回数分だけ増加。</p>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-4-逐次学習">表が出る確率のベイズ推定: 4. 逐次学習</h2>
<p>さっきの事後分布を事前分布として、さらにデータを集める。</p>
<p>コイントス4回のうち表1回、に基づく<strong>事前分布</strong>: $\text{Beta}(p \mid 2,~4)$</p>
<p>さらに16回投げたら表が7回、の<strong>尤度</strong>: $\text{Binomial}(7 \mid 16,~p)$</p>
<p><strong>事後分布</strong>はまた事前分布と同じ形になる:</p>
<div>\[\begin{split}
\text{Beta}(p \mid 9, 13) \propto
  \text{Binomial}(7 \mid 16,~p) \times \text{Beta}(p \mid 2, 4)
\end{split}\]</div>
<p>データを加えるたびに更新していける:</p>
<img src="figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian" width="85%">
</section>
<section>
<h2 id="共役事前分布">共役事前分布</h2>
<p>事後分布が事前分布と同じ形なので計算しやすい、という組み合わせ。</p>
<table>
  <thead>
      <tr>
          <th>尤度関数</th>
          <th>共役事前分布</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>二項分布</td>
          <td>ベータ分布</td>
      </tr>
      <tr>
          <td>ポアソン分布</td>
          <td>ガンマ分布</td>
      </tr>
      <tr>
          <td>正規分布</td>
          <td>ガンマ分布</td>
      </tr>
      <tr>
          <td>正規分布 (分散既知)</td>
          <td>正規分布</td>
      </tr>
  </tbody>
</table>
<p>共役事前分布を使うことが常に最善とは限らない。<br>
<strong>無情報事前分布</strong>を使って計算機に頑張らせる風潮。</p>

</section>
<section>
<h2 id="事後分布を用いた推定">事後分布を用いた推定</h2>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">
<dl>
<dt>区間推定</dt>
<dd>幅のある推定値を提示</dd>
<dd>e.g., 95%ベイズ確信区間:<br>
等裾事後確信区間 (<u>E</u>qual-<u>T</u>ailed <u>I</u>nterval)<br>
最高密度区間 (<u>H</u>ighest <u>D</u>ensity <u>I</u>nterval)</dd>
<dt>点推定</dt>
<dd>値を1点だけ提示</dd>
<dd>e.g.,<br>
事後確率最大値 (<u>M</u>aximum <u>A</u> <u>P</u>osteriori)<br>
事後中央値 (Posterior <u>Med</u>ian)<br>
事後期待値 (<u>E</u>xpected <u>A</u> <u>P</u>osteriori)
</div>
<div class="column" style="flex-shrink: 1.3;">
</dd>
</dl>
<p><img src="./figure/integrate-1.png" alt="plot of chunk integrate"></p>
  </div>
</div>
</section>
<section>
<h2 id="ベイズ推定の中間まとめ">ベイズ推定の中間まとめ</h2>
<ul>
<li>推定結果は<strong>事後分布</strong> ∝ 尤度関数。
<ul>
<li>広がり具合によって不確実性も表現できる。</li>
<li><strong>逐次学習</strong>で尖っていき、確信が強まる。</li>
</ul>
</li>
</ul>
<img src="figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian" width="70%">
<hr>
<p>コイン投げモデルのベータ分布は美しい例。<br>
→ 解析的(数学的)に解ける。</p>
<p>実践的なモデル・事後分布はもっと複雑。<br>
→ コンピュータに頼って数値計算: MCMC</p>

</section>
<section>
<h2 id="mcmc-marcov-chain-monte-carlo">MCMC: <u>M</u>arcov <u>C</u>hain <u>M</u>onte <u>C</u>arlo</h2>
<a href="https://en.wikipedia.org/wiki/Andrey_Markov">
<img src="../tokiomarine2021/image/AAMarkov.jpg" height="240" align="right"></a>
<dl>
<dt>マルコフ連鎖</dt>
<dd>次の時点の挙動が現在の値だけで決定されるような確率過程。</dd>
<dd>$\ldots \to X_{t - 2} \to X_{t - 1} \to X_{t} \to X_{t + 1}$</dd>
<dd>$\Pr(X_{t+1} \mid X_{t}, X_{t-1}, X_{t-2}, \ldots) = \Pr(X_{t+1} \mid X_{t})$</dd>
<dd>e.g., すごろく</dd>
<dt>モンテカルロ法</dt>
<dd>乱数を用いた計算方法の総称。</dd>
<dd><a href="https://en.wikipedia.org/wiki/Monte_Carlo_Casino">
<img src="../tokiomarine2021/image/Real_Monte_Carlo_Casino.jpg" height="300"></a>
<a href="https://en.wikipedia.org/wiki/Stanislaw_Ulam">
<img src="../tokiomarine2021/image/Stanislaw_Ulam.jpg" height="300"></a>
<a href="https://en.wikipedia.org/wiki/John_von_Neumann">
<img src="../tokiomarine2021/image/John_von_Neumann.jpg" height="300"></a>
<a href="https://en.wikipedia.org/wiki/Nicholas_Metropolis">
<img src="../tokiomarine2021/image/Nicholas_Metropolis.png" height="300"></a>
</dd>
</dl>

</section>
<section>
<h2 id="モンテカルロ法は乱数を用いた計算方法">モンテカルロ法は乱数を用いた計算方法</h2>
<p>e.g., 半径1の円の面積</p>
<p>数学を知っていれば $\pi r ^ 2 \approx 3.14159$</p>
<p>面積4の正方形に400個の一様乱数を打ち込んだら318個が円に乗った:<br>
$4 \times \frac {318} {400} = 3.18$</p>
<p><img src="./figure/circle-1.png" alt="plot of chunk circle"></p>

</section>
<section>
<h2 id="変な分布もモンテカルロ法で扱えそう">変な分布もモンテカルロ法で扱えそう</h2>
<p>e.g., 確率密度分布に従って変数Xを集める(棄却サンプリング)。</p>
<div>
<img src="figure/mcpdf-2.png" alt="plot of chunk mcpdf" style="vertical-align: middle;">
$\;\sim\;$
<img src="figure/mcpdf-1.png" alt="plot of chunk mcpdf" style="vertical-align: middle;">
</div>
<p>でも、ハズレの値もけっこう引いてしまう。</p>

</section>
<section>
<h2 id="次元の呪い-高次元になるほど当たりにくくなる">次元の呪い: 高次元になるほど当たりにくくなる</h2>
<p>(N次元球の体積 / N次元の立方体) はゼロに近づいていく。</p>
<img src="figure/circle-1.png" alt="plot of chunk circle" align="right">
<ul>
<li>2次元: $\frac {\pi r ^ 2} {(2r) ^ 2} = \frac \pi 4 \approx 0.79$</li>
<li>3次元: $\frac {\frac 4 3 \pi r ^ 3} {(2r) ^ 3} = \frac \pi 6 \approx 0.52$</li>
<li>N次元: $\frac {\frac {\pi ^ {N/2}} {\Gamma (N/2 + 1)} r ^ N} {(2r) ^ N} = \frac {\pi ^ {N/2}} {2^N \Gamma (N/2 + 1)} \to 0$</li>
</ul>
<p>パラメータが増えると計算量(≈乱数の無駄撃ち)が急増。</p>
<hr>
<p>密度の高い「当たり」付近を効率よく探索したい。<br>
「当たり」は「当たり」の近くにありがちだろう。<br>
→ マルコフ連鎖が使えそう</p>

</section>
<section>
<h2 id="metropolishastings法-mh法">Metropolis&ndash;Hastings法 (MH法)</h2>
<ol start="0">
<li>パラメータ $\theta$ の初期値を選ぶ</li>
<li>$\theta$ をちょっと増減させて $\theta_\text{new}$ を作る</li>
<li>それぞれ尤度を計算し、比較。
<ul>
<li>$L(\theta_\text{new}) \ge L(\theta)$ なら $\theta_\text{new}$ を即採択</li>
<li>$L(\theta_\text{new}) &lt; L(\theta)$ でも
確率 $r = \frac {L(\theta_\text{new})} {L(\theta)}$ で  $\theta_\text{new}$ を採択</li>
</ul>
</li>
<li>$\theta_\text{new}$ が採択されたら $\theta$ を更新。手順1に戻る。</li>
</ol>
<p><img src="./figure/metropolis-1.png" alt="plot of chunk metropolis"></p>
</section>
<section>
<h2 id="採択されたパラメータ値の軌跡">採択されたパラメータ値の軌跡</h2>
<p>尤度が高い方にただ向かうだけでなく、結構うろつく。<br>
通ったパラメータ値を集めるといい感じの分布が得られる。</p>
<p><img src="./figure/metropolis-trajectory-.gif" alt="plot of chunk metropolis-trajectory"></p>

</section>
<section>
<h2 id="尤度に比例する事後分布からサンプルしたのと等価">尤度に比例する事後分布からサンプルしたのと等価</h2>
<p>全体にばら撒く棄却サンプリングよりも効率よく集められる。<br>
が、パラメータ1つの1次元ではご利益はわかりにくい。</p>
<div>
<img src="figure/propto-lik-1.png" alt="plot of chunk propto-lik" style="vertical-align: middle;">
$\;\sim\;$
<img src="figure/propto-lik-2.png" alt="plot of chunk propto-lik" style="vertical-align: middle;">
$\;\propto\;$
<img src="figure/propto-lik-3.png" alt="plot of chunk propto-lik" style="vertical-align: middle;">
</div>
<p>パラメータが複数ある場合は？</p>

</section>
<section>
<h2 id="gibbs-sampling">Gibbs Sampling</h2>
<p>パラメータが複数の場合「ほかを固定してひとつ更新」を繰り返す。</p>
<p>e.g., 二次元正規分布。(-2, 2) からスタート。</p>
<p><img src="./figure/gibbs-.gif" alt="plot of chunk gibbs"></p>

</section>
<section>
<h2 id="何回やっても似たような結果になってほしい">何回やっても似たような結果になってほしい</h2>
<p>乱数や初期値によって偶々、じゃないことを確認したい。</p>
<p>e.g., <code>chains = 3</code> 。ほぼ同じところをうろうろ:</p>
<p><img src="./figure/chains-1.png" alt="plot of chunk chains"></p>
<p>収束(convergence)の判定については後ほど。</p>

</section>
<section>
<h2 id="初期値の影響が消えるまでウォーミングアップ">初期値の影響が消えるまでウォーミングアップ</h2>
<p>定常分布の山に到達してからが本番。</p>
<p>e.g., <code>iter_warmup = 200, iter_sampling = 600</code> で灰色の部分を捨てる:</p>
<p><img src="./figure/warmup-1.png" alt="plot of chunk warmup"></p>
<p>どれくらい長く捨てるべきかは場合による。</p>

</section>
<section>
<h2 id="適度に間引いて自己相関を軽減したい">適度に間引いて自己相関を軽減したい</h2>
<p>直前の値と似すぎていたら独立サンプルとして扱えないので。</p>
<p>e.g., <code>thin = 5</code> で5回に1回だけサンプルする:</p>
<p><img src="./figure/thin-1.png" alt="plot of chunk thin"></p>
<p>間引かなくても大丈夫な場合も、間引いても解決しない場合もある。</p>

</section>
<section>
<h2 id="収束判定">収束判定</h2>
<ul>
<li>複数chainsで異なる初期値から実行し、軌跡を可視化(traceplot)</li>
<li>Gelman-Rubin統計量 $\hat R &lt; 1.05$</li>
<li>Effective Sample Size (ESS) $N_\text{eff} &gt; 100$ per chain</li>
</ul>
<p><img src="./figure/convergence-1.png" alt="plot of chunk convergence"></p>
<p><a href="https://mc-stan.org/docs/cmdstan-guide/diagnose.html"><code>diagnose()</code></a>
みたいな機能が提供されていれば利用する。</p>
<p>実行時に<a href="https://mc-stan.org/misc/warnings.html">警告してもらえること</a>もある。</p>

</section>
<section>
<h2 id="収束自己相関が悪い場合にどう改善するか">収束・自己相関が悪い場合にどう改善するか</h2>
<ul>
<li>小手先の対処
<ul>
<li>iteration (warmup + sampling) をもっと長く</li>
<li>thinを大きくして間引く</li>
</ul>
</li>
<li>ちょっと大掛かり
<ul>
<li>プログラムの書き方を改善する</li>
<li>モデルの構造を見直す</li>
<li>アルゴリズム・ソフトウェアを変える</li>
</ul>
</li>
</ul>

</section>
<section>
<h2 id="似て非なる-mcmcサンプル増やす-vs-データ増やす">似て非なる: MCMCサンプル増やす vs データ増やす</h2>
<div>
<img src="figure/propto-lik-1.png" alt="plot of chunk propto-lik" style="vertical-align: middle;">
$\;\sim\;$
<img src="figure/propto-lik-2.png" alt="plot of chunk propto-lik" style="vertical-align: middle;">
$\;\propto\;$
<img src="figure/propto-lik-3.png" alt="plot of chunk propto-lik" style="vertical-align: middle;">
</div>
<ul>
<li>MCMCサンプルを増やす → 事後分布・尤度関数をより良く近似</li>
<li>データを増やす → 分布の裾野が狭まり、確信が強まる</li>
</ul>
<img src="figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian">

</section>
<section>
<h2 id="mcmcの方法いろいろ">MCMCの方法いろいろ</h2>
<p>採択率を高め、早く収束するように改良されてきている。</p>
<ul>
<li>Metropolis&ndash;Hastings法
<ul>
<li>Gibbs Sampling</li>
<li>Hamiltonian Monte Carlo (HMC)
<ul>
<li>No-U-Turn Sampler (NUTS)</li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section>
<h2 id="mcmcソフトウェア">MCMCソフトウェア</h2>
<ul>
<li><a href="https://www.mrc-bsu.cam.ac.uk/software/bugs/">BUGS</a>
<ul>
<li>クローズドソースで、ほぼWindows専用。</li>
</ul>
</li>
<li><a href="https://mcmc-jags.sourceforge.io/">JAGS</a>
<ul>
<li>オープンソースで、さまざまなOS・言語から利用可能。</li>
<li>マニュアルや用例が不足。</li>
</ul>
</li>
<li><a href="https://mc-stan.org/"><strong>Stan</strong></a> 👈
<ul>
<li>オープンソースで、さまざまなOS・言語から利用可能。</li>
<li>開発も利用も活発。マニュアルや用例も充実。</li>
<li>HMC/NUTSにより早く収束。</li>
</ul>
</li>
<li><a href="https://docs.pymc.io/">PyMC3</a></li>
<li><a href="https://num.pyro.ai/">NumPyro</a></li>
<li><a href="https://www.tensorflow.org/probability/">TensorFlow Probability</a></li>
</ul>

</section>
<section>
<h2 id="stan">Stan</h2>
<a href="https://mc-stan.org/">
<img src="/slides/image/stan/logo_name.png" width="180" align="right">
</a>
<ul>
<li>Stan言語で<strong>モデルを柔軟に記述</strong>できる。</li>
<li>C++で書かれていて<strong>高速に動作</strong>。</li>
<li>RやPythonなどから呼び出して使うのが便利。</li>
</ul>
<h2 id="python-interface">Python Interface</h2>
<dl>
<dt><a href="https://pystan.readthedocs.io">PyStan</a></dt>
<dd>WindowsやJupyterで使うには難あり。</dd>
<dt><a href="https://cmdstanpy.readthedocs.io">CmdStanPy</a> 👈 今後の主流</dt>
<dd><a href="https://mc-stan.org/users/interfaces/cmdstan">CmdStan</a>
を呼び出し、書き出されたCSVを読み取る。</dd>
</dl>

</section>
<section>
<h2 id="参考文献">参考文献</h2>
<ul>
<li><a href="https://amzn.to/33suMIZ">データ解析のための統計モデリング入門</a> 久保拓弥 2012</li>
<li><a href="https://amzn.to/3uwx7Pb">StanとRでベイズ統計モデリング</a> 松浦健太郎 2016</li>
<li><a href="https://amzn.to/3o1eCzP">RとStanではじめる ベイズ統計モデリングによるデータ分析入門</a> 馬場真哉 2019</li>
<li><a href="https://amzn.to/3uCxTKo">データ分析のための数理モデル入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3uznzCK">分析者のためのデータ解釈学入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3ty80Kv">統計学を哲学する</a> 大塚淳 2020</li>
</ul>
<a href="7-stan.html" class="readmore">
7. StanでGLM
</a>

</section>
</div>
</div>
</body>
</html>
