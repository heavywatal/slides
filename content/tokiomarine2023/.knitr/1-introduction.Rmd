```{r, setup-common}
#| file: "setup.R"
#| echo: false
#| results: "asis"
```
```{r, setup-local}
#| include: false
#| cache: false
```


---
## データを使ってやりたいこと

- 現象を**理解**したい
- 将来を**予測**したい
- ものを**分類・判別**したい
- 挙動を**制御**したい
- 新しい何かを**生成**したい

そのために解析は必要？
未加工の生データこそ宝？

???
よりよい職場に転職したい

---
## データ解析って必要？ 生データ見ればいいべ？

往々にして複雑過ぎ、情報多すぎ、そのままでは手に負えない

```{r, diamonds}
print(ggplot2::diamonds)
```

ダイヤモンド53,940個について10項目の値を持つデータセット

---
## 要約統計量を見てみよう

各列の**平均**とか**標準偏差**とか:

```{r, summary-diamonds}
#| echo: false
dia_cols = c("carat", "depth", "table", "price")
diamonds |>
  dplyr::summarize(dplyr::across(all_of(dia_cols), list(mean = mean, sd = sd, max = max, min = min))) |>
  tidyr::pivot_longer(everything(), names_to = c(".value", "stat"), names_sep = "_") |>
  dplyr::mutate(dplyr::across(where(is.numeric), \(x) round(x, digits = 2)))
```

大きさ `carat` と価格 `price` の**相関係数**はかなり高い:
```{r, cov-diamonds}
#| echo: false
diamonds |>
  dplyr::select(all_of(dia_cols)) |>
  scale() |>
  cov() |>
  wtl::printmat("%.2f", upper = FALSE)
```

<hr>

**生のままよりは把握しやすい**かも。

---
## 分布を特徴づける代表値 central tendency

<div class="column-container">
  <div class="column" style="flex-shrink: 1.6;">

平均値 mean
: 和を観察数で割る

中央値 median
: 順に並べて真ん中

最頻値 mode
: 最も頻度が高い値

  </div>
  <div class="column">
  <a href="https://www.mhlw.go.jp/toukei/list/20-21.html">
  <img src="../tohoku2022r/image/hist-income-japan-2019.png" width="100%" style="">
  <figcaption><cite>所得金額階級別世帯数の頻度分布 厚生労働省 国民生活基礎調査 2019</cite></figcaption>
  </a>
  </div>
</div>

目的や状況に応じて使い分けよう。

外れ値に対する応答
: もし総資産額20兆円の大富豪が鳥取県に引っ越してきたら<br>
  → 県民の**平均**資産は4000万円上昇。**中央値**・**最頻値**はほぼそのまま。

---
## ばらつきを捉える記述統計量

分散 variance
: 平均値からの差の自乗の平均。 $\frac 1 n \sum _i ^n (X_i - \bar X)^2$
: これの平方根が**標準偏差 (standard deviation)**。

Percentile, Quantile (四分位)
: 小さい順にならべて上位何%にあるか。
: 中央値 = 50th percentile = 第二四分位(Q2)

```{r, quantile}
#| fig.width: 10
#| fig.height: 4
#| echo: false
df = tibble::tibble(x = rnorm(200)) |>
  dplyr::filter(abs(x) < 2) |>
  dplyr::mutate(x = x + 3)
probs = c(min = 0, Q1 = 0.25, Q2 = 0.5, Q3 = 0.75, max = 1)
dfq = df |>
  dplyr::reframe(x = quantile(x, probs)) |>
  dplyr::mutate(name = names(probs), percent = sprintf("%d%%", 100 * probs))

p_hist = ggplot(df) + aes(x) +
  geom_histogram(bins = 30) +
  theme_void()
built = ggplot_build(p_hist)
bdata = built$data[[1]]
xlim = bdata |> dplyr::select(xmin, xmax) |> range()
p_box = ggplot(df) + aes(x) +
  geom_boxplot() +
  geom_rug(sides = "t", length = unit(0.06, "npc"), alpha = 0.66) +
  geom_point(data = dfq, aes(y = -0.6), shape = 17, size = 4) +
  geom_text(data = dfq, aes(y = -0.75, label = name), size = 5) +
  geom_text(data = dfq, aes(y = -0.95, label = percent), size = 5) +
  coord_cartesian(xlim = xlim, ylim = c(-1.2, 0.5)) +
  theme_void()
cowplot::plot_grid(p_hist, p_box, ncol = 1L)
```

---
## ばらつきの様子は大小の判断にも重要

<div class="column-container" style="padding-left: 10px;">
<div class="column" style="flex-shrink: 1.1;">
観測値1つずつ。<br>
たまたまかも。
</div>
<div class="column" style="flex-shrink: 1;">
ばらつき大きい。<br>
Bが高いのもたまたま?
</div>
<div class="column" style="flex-shrink: 1;">
ばらつき小さい。<br>
AとBには差がありそう。
</div>
</div>

```{r, comparison}
#| fig.width: 11
#| fig.height: 4
#| echo: false
n = 20
df1 = tibble::tibble(x = c("A", "B"), y = c(42, 51))
df2 = dplyr::bind_rows(
  tibble::tibble(x = "A", y = runif(n, 42 - 20, 42 + 20)),
  tibble::tibble(x = "B", y = runif(n, 51 - 20, 51 + 20)))
df3 = dplyr::bind_rows(
  tibble::tibble(x = "A", y = rnorm(n, 42, 1)),
  tibble::tibble(x = "B", y = rnorm(n, 51, 1)))
.lim = c(0, max(df2$y, df3$y))
.th = list(coord_cartesian(ylim = .lim),
  theme_classic(base_size = 20),
  theme(legend.position = "none", axis.title = element_blank()))

p1 = ggplot(df1) + aes(x, y, color = x) +
  geom_point(shape = 16, size = 5) +
  .th
p2 = ggplot(df2) + aes(x, y, color = x) +
  geom_jitter(height = 0, width = 0.2, shape = 16, size = 4, alpha = 0.66) +
  .th
cowplot::plot_grid(p1, p2, p2 %+% df3, nrow = 1)
```

「こんなことがたまたま起こる確率はすごく低いです！」<br>
をちゃんと示す手続きが**統計的仮説検定**。

---
## 記述統計量に頼りすぎず分布を可視化する

同じデータでも見せ方で印象・情報量が変わる。

```{r, visualize-distribution}
#| echo: false
#| fig.width: 9
#| fig.height: 6
df = mpg |> dplyr::mutate(y = hwy)
df_mean = df |> dplyr::summarize(y = mean(y))
p0 = ggplot(df) + aes(y = y) +
  theme_classic() +
  theme(axis.title = element_blank(), axis.text.x = element_blank(), axis.ticks = element_blank())

ylim = c(0, max(df$y))
coord_y = coord_cartesian(ylim = ylim)
coord_one = coord_cartesian(ylim = ylim, xlim = c(-1, 1))

pcol = p0 + aes(x = 0) +
  geom_col(data = df_mean, fill = "#999999") +
  stat_summary(fun.data = wtl::mean_sd, geom = "linerange")

cowplot::plot_grid(nrow = 2L,
  pcol + coord_one,
  p0 + geom_boxplot() + coord_one,
  p0 + geom_density(fill = "#999999", color = NA) + coord_y,
  p0 + geom_histogram(fill = "#999999", bins = 30L) + coord_y,
  p0 + geom_jitter(aes(x = 0), height = 0, shape = 16, alpha = 0.3, stroke = 0) + coord_one,
  p0 + geom_violin(aes(x = 0), fill = "#999999", color = NA) + coord_one,
  p0 + geom_dotplot(aes(x = 0), binaxis = "y", binwidth = 1, stackratio = 0.8,
    stroke = 0, alpha = 0.66, stackdir = "center") + coord_y,
  p0 + geom_dotplot(aes(x = 0), binaxis = "y", binwidth = 1, stackratio = 0.8,
    stroke = 0, alpha = 0.66) + coord_y
)
```


---
## 代表値ばかり見て可視化を怠ると構造を見逃す

<figure style="position: relative;">
<a href="https://www.autodesk.com/research/publications/same-stats-different-graphs">
<img src="/slides/image/rstats/datasaurus.png" width="95%">
<figcaption class="url">https://www.autodesk.com/research/publications/same-stats-different-graphs</figcaption>
</a>
<img src="/slides/image/rstats/DataDino-600x455.gif" width="22%"
     style="position: absolute; left: 0; top: 0; z-index: 255;">
</figure>


---
## データ可視化は理解の第一歩

情報をうまく絞って整理 → **直感的にわかる**

```{r, simplify-diamonds}
#| echo: false
#| fig.height: 6
#| fig.width: 7
diamonds |>
  dplyr::filter(clarity %in% c("I1", "SI2", "IF")) |>
  ggplot(aes(carat, price, color = clarity)) +
  geom_point(alpha = 0.4, size = 3) +
  scale_color_viridis_d(
    guide = guide_legend(reverse = TRUE, override.aes = list(alpha = 1))
  ) +
  labs(title = "Diamonds") +
  theme_gray(base_size = 22) +
  theme(
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "#bbbbbb"),
    legend.key = element_rect(fill = "#bbbbbb"),
    axis.ticks = element_blank()
  )
```

`carat` が大きいほど `price` も高いらしい。<br>
その度合いは `clarity` によって異なるらしい。

---
## 統計とは

データをうまくまとめ、それに基づいて推論するための手法。

- **記述統計**: データそのものを要約する
    - 要約統計量 (e.g., 平均、標準偏差、etc.)
    - 作図、作表
- **推測統計**: データの背後にある母集団・生成過程を考える
    - 数理モデル
    - 確率分布
    - パラメータ(母数)

「グラフを眺めてなんとなく分かる」以上の分析には**モデル**が必要

---
## モデルとは

対象システムを単純化・理想化して扱いやすくしたもの

Mathematical Model 数理モデル<img src="../tokiomarine2021/image/hill-equation.png" width="210" align="right" style="margin: 0 -5px;">
: 数学的な方程式として記述されるもの。
: e.g., Lotka-Volterra eq., <span style="color: #888;">Hill eq.</span>
: <br>

Computational Model 数値計算モデル<img src="/slides/image/tumopp/Chex_Lconst.gif" width="210" align="right">
: 数値計算の手続きとして記述されるもの。
: e.g., Schelling’s Segregation Model, <span style="color: #888;"><em>tumopp</em></span>
: <br>

Concrete Model 具象モデル<img src="../tokiomarine2021/image/weisberg-sfbay.jpg" width="330" align="right">
: 具体的な事物で作られるもの。
: e.g., San Francisco Bay-Delta Model

<cite>
Weisberg 2012 "Simulation and Similarity" (科学とモデル)
</cite>

???
数理モデルが決定論的、数値計算が確率論的、になる場合が多いけど必ずしもそうではない。
解析的に解くことを諦めて計算機にやらせるという点で実装方法は異なるが、
数理的に記述して解釈するという大枠では同じとみなしたほうがいいかもしれない。

プラモデル: 車や飛行機の重さ・材質は無視して色や形を模倣

---
## データ科学における数理モデル

データ生成をうまく真似できそうな仮定の数式表現。<br>
&nbsp;

<figure>
<img src="../tokiomarine2021/math-model.drawio.svg" width="1100"><br>
<figcaption><cite>「データ分析のための数理モデル入門」江崎貴裕 2020 より改変</cite></figcaption>
</figure>


???

確率モデル: 決定論的なモデルじゃなくて確率論的なゆらぎを導入したもの。
ただし、大塚淳さんの定義は異なる。
帰納推論を可能にする枠組みとして自然の斉一性(ヒューム)を仮定した上で、
データを生成している真の現象を確率用語で記述したものが確率モデルだ、という感じ。
そこからさらに強い仮定としてパラメトリックな確率分布を生成元としたのが統計モデル。

---
## データ科学における数理モデル

データ生成をうまく真似できそうな仮定の数式表現。<br>
e.g., 大きいほど高く売れる: $\text{price} = A \times \text{carat} + B + \epsilon$

```{r, lm-diamonds}
#| echo: false
#| fig.height: 5
#| fig.width: 6
diamonds |>
  dplyr::filter(clarity %in% c("I1", "SI2", "IF")) |>
  ggplot(aes(carat, price)) +
  geom_point(alpha = 0.3, size = 3) +
  stat_smooth(formula = y ~ x, method = lm, se = FALSE) +
  coord_cartesian(ylim = c(0, 20000)) +
  labs(title = "Diamonds") +
  theme_classic(base_size = 22)
```

新しく採れたダイヤモンドの価格予想とかにも使える。

このように「YをXの関数として表す」ようなモデルを**回帰**と呼ぶ。


---
## 本講義の主題: 回帰

単純な直線あてはめから出発し、ちょっとずつ統計モデリング。

<figure>
<a href="https://kuboweb.github.io/-kubo/ce/LinksGlm.html">
<img src="../tokiomarine2021/image/kubo-p2.png" width="1100">
<figcaption class="url">久保さん https://kuboweb.github.io/-kubo/ce/LinksGlm.html</figcaption>
</a>
</figure>

---
## 何でもかんでも直線あてはめではよろしくない

<img `r src_alt_fig_chunk("glm-better")`>

- 観察データは常に**正の値**なのに予測が負に突入してない？
- **縦軸は整数**。しかもの**ばらつき**が横軸に応じて変化？
- **データに合わせた統計モデルを使うとマシ**


---
## 回帰は教師あり機械学習の一種とも言える

<figure>
<img src="../tokiomarine2021/regression-in-ml.drawio.svg" width="1000">
</figure>

でも統計モデリングはいわゆる“機械学習”とは違う気もする...?


---
## モデリングにおける2つのアプローチ

<figure>
<img src="../tokiomarine2021/model-approaches.drawio.svg" width="1100"><br>
<figcaption><cite>「データ分析のための数理モデル入門」江崎貴裕 2020 より改変</cite></figcaption>
</figure>

---
## どっちも知っておいて使い分けたい

項目       | 統計モデリング | 近年の機械学習
---------- | -------------- | ----------------
モデル構造 | 単純化したい | 性能のためなら複雑化
モデル解釈 | **ここが強み** | 難しい。重視しない。途上。
予測・生成 | うまくすれば頑健 | **主目的**。強力。高精度
データ量   | 少なくてもそれなり | 大量に必要
計算量     | 場合による  | 場合による
例 | 一般化線形モデル<br>階層ベイズモデル | ランダムフォレスト<br>ニューラルネットワーク

教科書的には概ねこんな感じとして、実際の仕事ではどうだろう？

---
## 現役データサイエンティスト2人に聞きました

- 統計モデルはデータ加工など事前の手続きが多め。<br>
  機械学習は事前の決定が少ないので楽ちん。
- 「要因の効果はどれくらい？」<br>
  意思決定をするのは結局人間。物事を分かった上で判断したい。<br>
  **実務の人への説明**や**意思決定**の場面で解析の解釈性が重要。<br>
- **仮説があるなら**、それに基づいて統計モデリング。<br>
  何もないところからまず機械学習で要因抽出・仮説生成するのもあり。
- 統計モデル縛り・実行環境縛りなどの案件もある。
- 分析方針を決める立場の上級職になるつもりなら統計モデルも必要。

協力: [`@kato_kohaku`](https://twitter.com/kato_kohaku)さん、[`@teuder`](https://twitter.com/teuder)さん


---
## 本講義のお品書き

<figure style="float: right;">
<a href="https://kuboweb.github.io/-kubo/ce/IwanamiBook.html">
<img src="../tokiomarine2021/image/kubo-book.jpg" width="400" alt="データ解析のための統計モデリング入門 久保拓弥 2012">
</a>
</figure>

久保先生の"緑本"こと<br>
「データ解析のための統計モデリング入門」<br>
をベースに回帰分析の概要を紹介。

1. イントロ 👈 いまここ
1. Rの基礎を駆け足で
1. 統計モデルの基本
    - 直線回帰
    - 確率変数・**確率分布** 👈 次回の主役
    - 尤度・最尤推定
1. 一般化線形モデル、混合モデル
1. ベイズ統計（、階層ベイズモデル）

<!-- 回帰のキモは**線ではなく分布** -->










---
## 参考文献

R for Data Science --- Hadley Wickham and Garrett Grolemund
: <https://r4ds.had.co.nz/>,
  [Book](https://amzn.to/2tbRmVc),
  [日本語版書籍(Rではじめるデータサイエンス)](https://amzn.to/2yyFRKt)

- [データ解析のための統計モデリング入門](https://amzn.to/33suMIZ) 久保拓弥 2012
- [データ分析のための数理モデル入門](https://amzn.to/3uCxTKo) 江崎貴裕 2020
- [分析者のためのデータ解釈学入門](https://amzn.to/3uznzCK) 江崎貴裕 2020

Other versions
: 「[Rによるデータ前処理実習](/slides/tmd2022/)」
  東京医科歯科大 [データ関連人材育成プログラム](https://ds.tmdu.org/) (2022-09)
: 「[進化学実習2023](/slides/tohoku2023r/)」
  東北大学 理学部生物学科 (2023-04)
: 「[Rを用いたデータ解析の基礎と応用](https://comicalcommet.github.io/r-training-2023/)」
   石川由希 2023 名古屋大学

`r .meta$next_link`
