```{r, setup-common}
#| file: "setup.R"
#| echo: false
#| results: "asis"
```
```{r, setup-local}
#| include: false
#| cache: false
```


---
## 有名な確率分布対応関係ふりかえり

<figure style="float: right;">
<img src="../tokiomarine2021/math-model.drawio.svg" width="450"><br>
</figure>

離散一様分布
: コインの表裏、サイコロの出目1–6

負の二項分布 (幾何分布 if n = 1)
: 成功率pの試行がn回成功するまでの失敗回数

二項分布
: 成功率p、試行回数nのうちの成功回数

ポアソン分布
: 単位時間あたり平均$\lambda$回起こる事象の発生回数

ガンマ分布 (指数分布 if k = 1)
: ポアソン過程でk回起こるまでの待ち時間

正規分布
: 確率変数の和、平均値。使い勝手が良く、よく登場する。


---
## データに分布をあてはめたい

ある植物を50個体調べて、それぞれの種子数Xを数えた。<br>
個体Aは種2個、個体Bは種4個、、、サンプルサイズ n = 50 のデータ。

```{r, df-poisson}
#| echo: false
set.seed(24601)
df_rpois = tibble::tibble(X = rpois(50L, 3))
max_x = 11L
df_dpois = purrr::map(c(1, 3, 5), \(lambda) {
  tibble::tibble(lambda, X = seq.int(0L, max_x), Prob = dpois(X, lambda))
}) |> purrr::list_rbind()
```
```{r, poisson-seed}
#| echo: false
#| fig.height: 4
#| fig.width: 4.4
p_rpois = ggplot(df_rpois) +
  aes(X) +
  geom_bar(aes(y = after_stat(prop)), width = 0.4) +
  coord_cartesian(xlim = c(0, max_x)) +
  theme_bw(base_size = 20) +
  theme(
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(), axis.ticks = element_blank()
  )
p_rpois
```

カウントデータだし形も<span class="fragment custom blur">ポアソン</span>分布っぽい。<br>
分布のパラメータ $\lambda$ はどれくらいがいいだろう？


---
## データに分布をあてはめたい

ある植物を50個体調べて、それぞれの種子数Xを数えた。<br>
個体Aは種2個、個体Bは種4個、、、サンプルサイズ n = 50 のデータ。

```{r, poisson-seed-lambda}
#| echo: false
#| fig.height: 4
#| fig.width: 12
p_pois = p_rpois +
  geom_col(data = df_dpois, aes(y = Prob), alpha = 0.5, fill = "#56B4E9") +
  facet_wrap(vars(lambda), nrow = 1L, labeller = label_both)
p_pois
```

カウントデータだし形もポアソン分布っぽい。<br>
分布のパラメータ $\lambda$ はどれくらいがいいだろう？

黒が観察データ。<span style="color: #56B4E9;">青がポアソン分布</span>。
よく重なるのは $\lambda \approx 3$ くらいか。


---
## <ruby>尤<rt>ゆう</rt>度</ruby> (likelihood)

<ruby>尤<rt>もっと</rt></ruby>もらしさ。
モデルのあてはまりの良さの尺度のひとつ。

**あるモデル$M$の下でそのデータ$D$が観察される確率**。<br>
定義通り素直に書くと<br>
$\Pr(D \mid M)$

データ$D$を固定し、モデル$M$の関数とみなしたものが**尤度関数**:<br>
$L(M \mid D)$

モデルの構造も固定してパラメータ$\theta$だけ動かす場合はこう書く:<br>
$L(\theta \mid D)$ とか $L(\theta)$ とか


---
## 尤度を手計算できる例

コインを5枚投げた結果 $D$: 表 4, 裏 1

表が出る確率 $p = 0.5$ と仮定:
<div>\[\begin{split}
L(0.5 \mid D)
  &= \binom 5 1 \times \Pr(\text{表} \mid 0.5) ^ 4 \times \Pr(\text{裏} \mid 0.5) ^ 1 \\
  &= 5 \times 0.5 ^ 4 \times 0.5 ^ 1 = 0.15625
\end{split}\]</div>

表が出る確率 $p = 0.8$ と仮定:
<div>\[\begin{split}
L(0.8 \mid D)
  &= \binom 5 1 \times \Pr(\text{表} \mid 0.8) ^ 4 \times \Pr(\text{裏} \mid 0.8) ^ 1 \\
  &= 5 \times 0.8 ^ 4 \times 0.2 ^ 1 = 0.4096
\end{split}\]</div>

$L(0.8 \mid D) > L(0.5 \mid D)$

$p = 0.8$ のほうがより尤もらしい。



---
## 種子数ポアソン分布の例でも尤度を計算してみる

$n = 50$個体ぶん、且つ、且つ、且つ、と確率を掛けていく:

<div>\[\begin{split}
L(\lambda \mid D)
  = \prod _i ^n \Pr(X_i \mid \lambda)
  = \prod _i ^n \frac {\lambda ^ {X_i} e ^ {-\lambda}} {X_i !}
\end{split}\]</div>

```{r, poisson-seed-likelihood}
#| echo: false
#| fig.height: 4
#| fig.width: 12
df_likelihood = df_rpois |>
  dplyr::left_join(df_dpois, by = "X") |>
  dplyr::group_by(lambda) |>
  dplyr::summarize(L = prod(Prob)) |>
  dplyr::mutate(logL = log(L), label = sprintf("L(%.0f|D) = %.1e", lambda, L))
p_pois +
  geom_text(data = df_likelihood, aes(label = label), color = "#56B4E9",
            x = Inf, y = Inf, hjust = 1.1, vjust = 1.3, size = 7)
```

この中では $\lambda = 3$ がいいけど、より尤もらしい値を求めたい。

---
## 最尤推定 <u>M</u>aximum <u>L</u>ikelihood <u>E</u>stimation

扱いやすい **対数尤度** (log likelihood) にしてから計算する。<br>
一階微分が0になる $\lambda$ を求めると...**標本平均**と一致。

<div>\[\begin{split}
\log L(\lambda \mid D)
  &= \sum _i ^n \left[ X_i \log (\lambda) - \lambda - \log (X_i !) \right] \\
\frac {\mathrm d \log L(\lambda \mid D)} {\mathrm d \lambda}
  &= \frac 1 \lambda \sum _i ^n X_i - n = 0 \\
\hat \lambda &= \frac 1 n \sum _i ^n X_i
\end{split}\]</div>


```{r, poisson-mle}
#| echo: false
#| fig.height: 2.8
#| fig.width: 11
count_rpois = df_rpois |> dplyr::count(X)
calc_likelihood_rpois = function(lambda) {
  prod(dpois(count_rpois[["X"]], lambda)**count_rpois[["n"]])
}
X_mle = mean(df_rpois[["X"]])
L_mle = calc_likelihood_rpois(X_mle)
p_mle = tibble::tibble(lambda = seq(1, 5, 0.1), L = purrr::map_dbl(lambda, calc_likelihood_rpois)) |>
  dplyr::mutate(logL = log(L)) |>
  ggplot() +
  aes(lambda, logL) +
  geom_line() +
  geom_vline(xintercept = X_mle, color = "#56B4E9", linewidth = 1) +
  annotate("point", x = X_mle, y = log(L_mle), size = 4, color = "#56B4E9") +
  annotate("text", label = sprintf("lambda = %.2f", X_mle), color = "#56B4E9",
           x = Inf, y = -Inf, hjust = 1.2, vjust = -0.8, size = 7) +
  labs(y = "log L") +
  theme_bw(base_size = 20) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    axis.ticks = element_blank()
  )

.df_mle = tibble::tibble(lambda = X_mle, X = seq(0, 11), Prob = dpois(X, lambda))
.p_pois_mle = p_rpois +
  geom_col(data = .df_mle, aes(y = Prob), alpha = 0.5, fill = "#56B4E9")

cowplot::plot_grid(p_mle, .p_pois_mle, nrow = 1L, rel_widths = c(2, 1))
```

---
## 最尤推定を使っても“真のλ”は得られない

今回のデータは真の生成ルール“$X \sim \text{Poisson}(\lambda = 3.0)$”で作った。<br>
「50個体サンプル→最尤推定」を1,000回繰り返してみると:

```{r, poisson-mle-repl}
#| echo: false
#| fig.height: 5
#| fig.width: 12
set.seed(19937)
nrep = 1000L
df_repl = tibble::tibble(X = rpois(50L * nrep, 3), repl = rep(seq_len(nrep), each = 50L))
df_sum = df_repl |>
  dplyr::group_by(repl) |>
  dplyr::summarize(lambda = mean(X))
df_minmax = dplyr::bind_rows(dplyr::slice_max(df_sum, lambda), dplyr::slice_min(df_sum, lambda))

p_repl = df_sum |>
  ggplot() +
  aes(lambda) +
  geom_histogram(bins = 25, center = 3) +
  annotate("point", x = df_minmax$lambda, y = 0, color = "#56B4E9", size = 8, alpha = 0.5) +
  labs(x = "estimated_lambda") +
  theme_bw(base_size = 20) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    axis.ticks = element_blank()
  )

.df_dminmax = tidyr::crossing(lambda = df_minmax$lambda, X = seq(0, 11)) |>
  dplyr::mutate(Prob = dpois(X, lambda))
p_minmax = df_repl |>
  dplyr::filter(repl %in% df_minmax$repl) |>
  dplyr::left_join(df_minmax, by = "repl") |>
  ggplot() +
  aes(X) +
  geom_bar(aes(y = after_stat(prop)), width = 0.4) +
  geom_col(data = .df_dminmax, aes(y = Prob), alpha = 0.5, fill = "#56B4E9") +
  facet_wrap(vars(lambda), ncol = 1L, labeller = label_both) +
  theme_bw(base_size = 20) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(), axis.ticks = element_blank()
  )

cowplot::plot_grid(p_repl, p_minmax, nrow = 1L, rel_widths = c(2, 1))
```

サンプルの取れ方によってはかなりズレた推定をしてしまう。<br>
(標本データへのあてはまりはかなり良く見えるのに！)


---
## サンプルサイズを増やすほどマシにはなる

“$X \sim \text{Poisson}(\lambda = 3.0)$”からnサンプル→最尤推定を1,000回繰り返す:

```{r, poisson-mle-nsam}
#| echo: false
#| fig.height: 4
#| fig.width: 11
set.seed(19937)
nrep = 1000L
purrr::map(c(5, 50, 500, 5000), \(n) {
  tibble::tibble(X = rpois(n * nrep, 3), repl = rep(seq_len(nrep), each = n)) |>
    dplyr::group_by(repl) |>
    dplyr::summarize(estimated_lambda = mean(X)) |>
    dplyr::mutate(n = n)
}) |>
  purrr::list_rbind() |>
  ggplot() +
  aes(estimated_lambda) +
  geom_histogram(bins = 25, center = 3) +
  facet_wrap(vars(n), nrow = 1L, labeller = label_both) +
  theme_bw(base_size = 20) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    axis.ticks = element_blank()
  )
```

Q. じゃあどれくらいのサンプル数nを確保すればいいのか？<br>
A. 推定したい統計量とか、許容できる誤差とかによる。


---
## すべてのモデルは間違っている

確率分布がいい感じに最尤推定できたとしても、<br>
それはあくまでモデル。仮定。近似。

> All models are wrong, but some are useful. --- George E. P. Box

<figure>
<img src="../tokiomarine2021/math-model.drawio.svg" width="1080"><br>
<figcaption><small>「<a href="https://amzn.to/3uCxTKo"><cite>データ分析のための数理モデル入門</cite></a>」江崎貴裕 2020 より改変</small></figcaption>
</figure>


---
## 統計モデリングの道具 --- まとめ

- 何はともあれ作図して俯瞰
- **確率変数** $X$
- **確率分布** $X \sim f(\theta)$
    - **少ないパラメータ** $\theta$ でばらつきの様子を表現
    - **この現象はこの分布を作りがち(〜に従う)** という知見がある
- **尤度**
    - あるモデルでこのデータになる確率 $\Pr(D \mid M)$
    - データ固定でモデル探索 → **尤度関数** $L(M \mid D),~L(\theta \mid D)$
    - 対数を取ったほうが扱いやすい → **対数尤度** $\log L(M \mid D)$
    - これを最大化するようなパラメータ $\hat \theta$ 探し ＝ **最尤法**


---
## 🔰 尤度の練習問題 [@`3-likelihood.ipynb`](./3-likelihood.ipynb)

サイコロを10回振ったら6の目が3回出た。

1. 6の目の出る確率が1/6だとした場合の尤度は?
1. 6の目の出る確率が0.2だとした場合の尤度は?
1. 横軸を6の目の出る確率、縦軸を対数尤度とするグラフを描こう。
1. このサイコロで6の目が出る確率を最尤推定しよう。<br>
   数学で解ければ**優**。Rで見つければ**良**。目分量・勘で**可**。

ヒント
: 確率pで当たるクジをn回引いてk回当たる確率、と同じ計算を使う。
: 数学の $\binom 5 2 = {}_5 \mathrm{C} _2 = 10$ はRでは `choose(5, 2)` 。<br>
  Pythonでは [`scipy.special.comb(5, 2)`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.comb.html).

```{r, get-likelihood}
#| include: false
get_likelihood = function(p, k = 3, n = 10) {
  choose(n, k) * p ** k * (1 - p) ** (n - k)
  # dbinom(k, n, p)
}

get_likelihood(0.2)
```

---
## 🔰 分布を当てはめる練習問題

植物25個体から8個ずつ種をとって植え、生き残ったものを数えた。

1. データの分布を描いてみて、当てはまりそうな確率分布を検討する
1. <span style="color: #56B4E9;">理論分布</span>を適当なパラメータで描いてみる
1. パラメータや分布を変えてみて、データの分布にすり寄せる
1. 対数尤度の変化を可視化し、パラメータを最尤推定する

```{r, distribution-datasets}
#| include: false
set.seed(19937)
sample_size = 25L
trials = 8
true_p = 0.8
df_seeds = tibble::tibble(
  trials,
  survived = rbinom(sample_size, trials, true_p)
)

p_hat = sum(df_seeds$survived) / (sample_size * trials)
.df_exp = tibble::tibble(
  y = seq.int(0, trials),
  expected = sample_size * dbinom(y, trials, p_hat)
)
tidy_seeds = df_seeds |>
  dplyr::rename(y = survived) |>
  dplyr::count(y, name = "observed") |>
  dplyr::full_join(.df_exp, by = "y")
```

<div class="column-container">
  <div class="column" style="height: 440px; overflow: scroll; flex-shrink: 1.2;">

```{r, distribution-datasets-print}
#| echo: false
df_seeds |> readr::write_csv(stdout())
# knitr::kable(df_seeds)
```

  </div>
  <div class="column">

```{r, distribution-datasets-plot}
#| echo: false
#| fig.height: 4
#| fig.width: 4
ggplot(tidy_seeds) +
  geom_col(aes(y, observed), width = 0.4, fill = "#333333") +
  geom_col(aes(y, expected), tidy_seeds, fill = "#56B4E9", alpha = 0.5, width = 0.8) +
  labs(x = "# survived seeds", y = "count") +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank(),
        legend.title = element_blank(), legend.position = "top")
```

  </div>
  <div class="column">

```{r, distribution-datasets-mle}
#| echo: false
#| fig.height: 4
#| fig.width: 4
fun_loglik = function(p) {
  purrr::map_dbl(p, \(x) sum(dbinom(df_seeds$survived, trials, x, log = TRUE)))
}
.delta = 0.02
.df_loglik = tibble::tibble(
  p = seq(.delta, 1 - .delta, .delta),
  loglik = fun_loglik(p)
)
ggplot(.df_loglik) +
  aes(p, loglik) +
  geom_line(linewidth = 1) +
  geom_vline(xintercept = p_hat, linewidth = 1, color = "#56B4E9") +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank())
```

  </div>
</div>


---
## 参考文献

- [データ解析のための統計モデリング入門](https://amzn.to/33suMIZ) 久保拓弥 2012
- [StanとRでベイズ統計モデリング](https://amzn.to/3uwx7Pb) 松浦健太郎 2016
- [RとStanではじめる ベイズ統計モデリングによるデータ分析入門](https://amzn.to/3o1eCzP) 馬場真哉 2019
- [データ分析のための数理モデル入門](https://amzn.to/3uCxTKo) 江崎貴裕 2020
- [分析者のためのデータ解釈学入門](https://amzn.to/3uznzCK) 江崎貴裕 2020
- [統計学を哲学する](https://amzn.to/3ty80Kv) 大塚淳 2020

`r .meta$next_link`
