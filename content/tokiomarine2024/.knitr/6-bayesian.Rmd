```{r, setup-common}
#| file: "setup.R"
#| echo: false
#| results: "asis"
```
```{r, setup-local}
#| include: false
#| cache: false
wtl::knit_engines_set_cache_stan("stan/")
```


---
## ちょっとずつ線形モデルを発展させていく

<figure style="float: right;">
<a href="https://kuboweb.github.io/-kubo/ce/IwanamiBook.html">
<img src="../tokiomarine2021/image/kubo-book.jpg" width="400" alt="データ解析のための統計モデリング入門 久保拓弥 2012">
</a>
</figure>

久保先生の"緑本"こと<br>
「[データ解析のための統計モデリング入門](https://kuboweb.github.io/-kubo/ce/IwanamiBook.html)」<br>
をベースに回帰分析の概要を紹介。

**線形モデル LM** (単純な直線あてはめ)

<span style="color: #888888;">&nbsp; &nbsp; ↓ いろんな<span style="font-weight: bold; color: #56B4E9;">確率分布</span>を扱いたい</span>

**一般化線形モデル GLM**

<span style="color: #888888;">&nbsp; &nbsp; ↓ <span style="font-weight: bold; color: #E69F00;">個体差</span>などの変量効果を扱いたい</span>

**一般化線形混合モデル GLMM**

<span style="color: #888888;">&nbsp; &nbsp; ↓ もっと<span style="font-weight: bold; color: #B2001D;">自由なモデリング</span>を！</span>

**階層ベイズモデル HBM**


---
## コイントス4回、たまたま表が1回だったら

<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">

最尤推定
: 推定結果は最も尤もらしい1点。
: データが少ないとき過剰適合気味。
: 表が出る確率 p = 0.25 のコインだろう。<br>
  (信じ難いけどデータはこう言っている)

<br>

ベイズ推定
: 推定結果は確率分布そのもの。
: データが少ないなりの不確実さも表現。
: p = 0.25 らへんである確率は高いが、<br>
  p = 0.6 とかである可能性もまあある。

  </div>
  <div class="column" style="flex-shrink: 1.4;">

```{r, freq-vs-bayes}
#| echo: false
#| fig.height: 4
#| fig.width: 4
tibble::tibble(p = seq(0, 1, 0.01), logLik = dbinom(1, 4, p, log = TRUE)) |>
  dplyr::filter(logLik > -1e6) |>
  ggplot() + aes(p, logLik) +
  geom_line() +
  geom_point(data = \(.x) {dplyr::slice_max(.x, logLik)}, shape = 16, size = 5, color = "#56B4E9") +
  geom_vline(data = \(.x) {dplyr::slice_max(.x, logLik)}, aes(xintercept = p), linewidth = 1, color = "#56B4E9") +
  scale_x_continuous(breaks = c(0, 0.5, 1)) +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor.y = element_blank(), axis.ticks = element_blank())

tibble::tibble(p = seq(0, 1, 0.01), Density = dbeta(p, 2, 4)) |>
  ggplot() + aes(p, Density) +
  geom_area(fill = "#56B4E9", alpha = 0.5) +
  scale_x_continuous(breaks = c(0, 0.5, 1)) +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor.y = element_blank(), axis.ticks = element_blank())
```

  </div>
</div>


---
## コイントスの回数が増えていったら

**最尤推定**: 推定値が真の値に近づいていく

```{r, df-coin-beta}
#| echo: false
set.seed(24601)
coin_X = c(0L, 0L, 0L, 1L, rbinom(496L, 1L, 0.5))
coin_show = c(4, 20, 100, 500)
df_coin = purrr::map(c(0, 1, 2, 3, coin_show), \(i) {
  k = sum(head(coin_X, i))
  tibble::tibble(
    i = i,
    label = sprintf("%d / %d", k, i),
    p = seq(0, 1, 0.01),
    logLik = dbinom(k, i, p, log = TRUE),
    Density = dbeta(p, k + 1, i - k + 1)
  )
}) |>
  purrr::list_rbind() |>
  dplyr::mutate(label = factor(label, levels = unique(label)))
```
```{r, coin-frequentist}
#| echo: false
#| fig.width: 11
#| fig.height: 3
df_coin |>
  dplyr::filter(i %in% coin_show) |>
  dplyr::filter(logLik > -20) |>
  dplyr::group_by(label) |>
  ggplot() + aes(p, logLik) +
  geom_line() +
  geom_point(data = \(.x) {dplyr::slice_max(.x, logLik)}, shape = 16, size = 5, color = "#56B4E9") +
  geom_vline(data = \(.x) {dplyr::slice_max(.x, logLik)}, aes(xintercept = p), linewidth = 1, color = "#56B4E9") +
  scale_x_continuous(breaks = c(0, 0.5, 1)) +
  facet_wrap(vars(label), nrow = 1L) +
  theme_bw(base_size = 20) +
  theme(panel.spacing.x = grid::unit(1, "lines"),
        panel.grid.minor.y = element_blank(), axis.ticks = element_blank())
```

**ベイズ推定**: 確率分布がどんどん尖り、確信が強まる

```{r, coin-bayesian}
#| echo: false
#| fig.width: 11
#| fig.height: 3
df_coin |>
  dplyr::filter(i %in% coin_show) |>
  ggplot() + aes(p, Density) +
  geom_area(fill = "#56B4E9", alpha = 0.5) +
  scale_x_continuous(breaks = c(0, 0.5, 1)) +
  facet_wrap(vars(label), nrow = 1L) +
  theme_bw(base_size = 20) +
  theme(panel.spacing.x = grid::unit(1, "lines"),
        panel.grid.minor.y = element_blank(), axis.ticks = element_blank())
```

---
## 確率おさらい

同時分布/結合確率: <span style="font-weight: normal;"> <span style="color: #E69F00;">A</span>かつ<span style="color: #0072B2;">B</span>の確率</span>
: $\Pr(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B}) = \Pr(\textcolor{#E69F00}{A} \cap \textcolor{#0072B2}{B}) = \Pr(\textcolor{#E69F00}{A}) \Pr(\textcolor{#0072B2}{B})$

周辺確率: <span style="font-weight: normal;"> <span style="color: #0072B2;">B</span>によらず<span style="color: #E69F00;">A</span>になる確率</span>
: $\Pr(\textcolor{#E69F00}{A}) = \sum_{\textcolor{#0072B2}{B}} \Pr(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B})$

条件付き確率: <span style="font-weight: normal;"> <span style="color: #0072B2;">B</span>である条件の下で<span style="color: #E69F00;">A</span>になる確率。重要。</span>
: $\Pr(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B}) = \frac {\Pr(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B})} {\Pr(\textcolor{#0072B2}{B})}$

```{r, venn}
#| echo: false
#| fig.width: 6
#| fig.height: 3
make_circle = function(radius, center, n = 100L) {
  tibble::tibble(theta = seq(0, 2 * pi, length.out = n + 1L)[-1]) |>
    dplyr::mutate(x = radius * cos(theta) + center[1],
                  y = radius * sin(theta) + center[2])
}
ggplot() + aes(x, y) +
  geom_polygon(data = make_circle(5, c(0, 0)), fill = "#E69F00", alpha = 0.5) +
  geom_polygon(data = make_circle(1, c(4.3, 0)), fill = "#0072B2", alpha = 0.5) +
  coord_fixed(xlim = c(-7, 7)) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        axis.title = element_blank(), axis.text = element_blank(), axis.ticks = element_blank())
```


---
## 条件付き確率がよくわかる具体例

<span style="color: #0072B2;">B Brewery</span>のビールが<span style="color: #E69F00;">Awesome</span>な確率
: $\Pr(\textcolor{#E69F00}{\text{Awesome}} \mid \textcolor{#0072B2}{\text{B Brewery}}) = \frac {\Pr(\textcolor{#E69F00}{\text{Awesome}},~\textcolor{#0072B2}{\text{B Brewery}})} {\Pr(\textcolor{#0072B2}{\text{B Brewery}})}$
: かなり高い確率。良い醸造所。

<span style="color: #E69F00;">Awesome</span>なビールが<span style="color: #0072B2;">B Brewery</span>のものである確率
: $\Pr(\textcolor{#0072B2}{\text{B Brewery}} \mid \textcolor{#E69F00}{\text{Awesome}}) = \frac {\Pr(\textcolor{#E69F00}{\text{Awesome}},~\textcolor{#0072B2}{\text{B Brewery}})} {\Pr(\textcolor{#E69F00}{\text{Awesome}})}$
: かなり低い確率。Awesomeなビールはほかにもたっくさんある。

<img `r src_alt_fig_chunk("venn")`>


---
## ベイズの定理

乗法定理
: $\Pr(\textcolor{#E69F00}{A},~\textcolor{#0072B2}{B}) = \Pr(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B})~\Pr(\textcolor{#0072B2}{B}) = \Pr(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A})~\Pr(\textcolor{#E69F00}{A})$

<a href="https://en.wikipedia.org/wiki/Thomas_Bayes">
<img src="../tokiomarine2021/image/Thomas_Bayes.gif" height="200" align="right"></a>
<style>
[class^=bubble] {
  position: relative;
  font-size: 0.9em;
  padding: 0.2em 0.6em;
  border-radius: 0.2em;
  background: #8885;
}
[class^=bubble]::after {
  content: "";
  position: absolute;
  bottom: -0.5em;
  left: 50%;
  width: 0.5em;
  aspect-ratio: 1;
  clip-path: polygon(0 0, 100% 0, 0 100%);
  background: #8885;
}
[class^=bubble-top]::after {
  bottom: unset;
  top: -0.5em;
  transform: scaleY(-1);
}
.after-flipX::after {
  transform: translateX(-0.5em) scaleX(-1);
}
.after-l25::after {left: 25%;}
.after-l75::after {left: 75%;}
</style>

移項するだけで**ベイズの定理**:
<div>
<div style="margin-block: -0.5em;">
<span class="bubble after-l25" style="margin-inline-start: 2rem;">事後確率</span>
<span class="bubble after-flipX" style="margin-inline-start: 4.7rem;">事前確率</span>
</div>
\[
\Pr(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A}) =
\frac {\Pr(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B})~\Pr(\textcolor{#0072B2}{B})} {\Pr(\textcolor{#E69F00}{A})}
\]
</div>

宴会場にビールが運ばれてきた。これはどこのブルワリーの？

事前確率: $\Pr(\textcolor{#0072B2}{B})$
: 飲む前、手元のビールが<span style="color: #0072B2;">B Brewery</span>のである確率。
: ↓ 🍻 飲んでみて更新

事後確率: $\Pr(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A})$
: 飲んでみて<span style="color: #E69F00;">Awesome</span>だったビールが
  <span style="color: #0072B2;">B Brewery</span>のである確率。


---
## ベイズの定理 in 感染症検査

- 有病率 $\Pr(I)$ : 0.3% (この地域の感染者の割合; 事前確率)
- 感度 $\Pr(P \mid I)$ : 90% (感染してる人に陽性判定が出る)
- 特異度 $\Pr(\lnot P \mid \lnot I)$: 99% (感染してない人に陰性判定が出る)

さて、陽性適中率(検査陽性の人が実際に感染者である確率)は？

<div>\[\begin{split}
\Pr(I \mid P)
  &= \frac {\Pr(P \mid I)~\Pr(I)} {\Pr(P)} \\
  &= \frac {\Pr(P \mid I)~\Pr(I)}
           {\Pr(P \mid I)~\Pr(I) + \Pr(P \mid \lnot I)~\Pr(\lnot I)} \\
  &= \frac {0.9 \times 0.003} {0.9 \times 0.003 + 0.01 \times 0.997} \approx 0.21
\end{split}\]</div>

感染者を隔離するスクリーニング目的では使いものにならない性能。

🔰 同様に $\Pr(\lnot I \mid \lnot P)$ 陰性的中率を計算してみよう<br>
🔰 計算結果が検査性能だけでなく有病率にも依存することを確認しよう

```{r, infection-test}
#| eval: false
#| include: false
sensitivity = 0.9
specificity = 0.99
prevalence = 0.003
p_positive = (prevalence * sensitivity + (1 - prevalence) * (1 - specificity))
p_negative = ((1 - prevalence) * specificity + prevalence * (1 - sensitivity))
devnull = tibble::tibble(
  true_positive = prevalence * sensitivity / p_positive,
  false_positive = (1 - prevalence) * (1 - specificity) / p_positive,
  true_negative = (1 - prevalence) * specificity / p_negative,
  false_negative = prevalence * (1 - sensitivity) / p_negative
)
```


---
## ベイズの定理 in 統計モデリング

<p>
<img src="../iwate2023stats/bayesian.drawio.svg">
</p>

モデル$M$に対する確信度合いをデータ$D$に基づいて更新する。<br>
モデル$M$を仮説$H$やパラメータ$\theta$に置き換えてもいい。

**周辺尤度**は「確率分布の積分は1」を満たすための正規化定数とみなせる。<br>
比例関係だけ抜き出してこう書くことが多い:
<div>\[\begin{align}
\Pr(M \mid D) &\propto \Pr(D \mid M)~\Pr(M) \tag{Model}\\
\Pr(H \mid D) &\propto \Pr(D \mid H)~\Pr(H) \tag{Hypothesis} \\
\Pr(\theta \mid D) &\propto \Pr(D \mid \theta)~\Pr(\theta) \tag{Parameter}
\end{align}\]</div>


---
## 表が出る確率のベイズ推定: 1. 事前分布

<div class="column-container">
  <div class="column" style="opacity: 0.2;">
<img `r src_alt_fig_chunk("posterior-beta")` style="vertical-align: middle;">
&ensp;$\propto$
  </div>
  <div class="column" style="opacity: 0.2;">
<img `r src_alt_fig_chunk("likelihood-binom")` style="vertical-align: middle;">
&ensp;⨉
  </div>
  <div class="column">
<img `r src_alt_fig_chunk("prior-beta")` style="vertical-align: middle;">
  </div>
</div>

コイントスを繰り返して、表が出る確率pをベイズ推定したい。

事前分布には**ベータ分布**を採用(理由は後で分かる):
<div>\[\begin{split}
\text{Beta}(p \mid a, b) =
   \frac{\Gamma(a + b)}{\Gamma(a) \Gamma(b)} p^{a-1} (1 - p)^{b-1}
\end{split}\]</div>

分布の形は $a,~b$ によって決まる。<br>
ガンマ関数の部分は厳つく見えるけどただの正規化定数。<br>
投げる前なのでとりあえず真っ平らを仮定 $\text{Beta}(p \mid a = 1, b = 1)$:

```{r, prior-beta}
#| include: false
#| fig.width: 3.2
#| fig.height: 3.2
prior_beta = df_coin |>
  dplyr::filter(i == 0) |>
  ggplot() + aes(p, Density) +
  geom_area(fill = "#56B4E9", alpha = 0.5) +
  scale_x_continuous(breaks = c(0, 0.5, 1)) +
  coord_cartesian(ylim = c(0, 3)) +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor.y = element_blank(), axis.ticks = element_blank())
prior_beta + labs(title = "Prior")
```
```{r, likelihood-binom}
#| include: false
#| fig.width: 3.2
#| fig.height: 3.2
df_coin |>
  dplyr::filter(i == 4) |>
  dplyr::mutate(Lik = exp(logLik)) |>
  ggplot() + aes(p, Lik) +
  geom_line(color = "#56B4E9", linewidth = 2) +
  scale_x_continuous(breaks = c(0, 0.5, 1)) +
  labs(title = "Likelihood") +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor.y = element_blank(), axis.ticks = element_blank())
```
```{r, posterior-beta}
#| include: false
#| fig.width: 3.2
#| fig.height: 3.2
prior_beta %+%
  (df_coin |> dplyr::filter(i == 4)) +
  labs(title = "Posterior")
```


---
## 表が出る確率のベイズ推定: 2. 尤度関数

<div class="column-container">
  <div class="column" style="opacity: 0.2;">
<img `r src_alt_fig_chunk("posterior-beta")` style="vertical-align: middle;">
&ensp;$\propto$
  </div>
  <div class="column">
<img `r src_alt_fig_chunk("likelihood-binom")` style="vertical-align: middle;">
&ensp;⨉
  </div>
  <div class="column" style="opacity: 0.2;">
<img `r src_alt_fig_chunk("prior-beta")` style="vertical-align: middle;">
  </div>
</div>

4回投げて表が1回だった、というデータで**尤度**を計算(**二項分布**):
<div>\[\begin{split}
\text{Binom}(1 \mid 4,~p) = \binom {1} {4} p^{1} (1 - p)^{3}
\end{split}\]</div>

これに事前分布を掛けて正規化したら事後分布になるはず。


---
## 表が出る確率のベイズ推定: 3. 事後分布

<div class="column-container">
  <div class="column">
<img `r src_alt_fig_chunk("posterior-beta")` style="vertical-align: middle;">
&ensp;$\propto$
  </div>
  <div class="column" style="opacity: 0.66;">
<img `r src_alt_fig_chunk("likelihood-binom")` style="vertical-align: middle;">
&ensp;⨉
  </div>
  <div class="column" style="opacity: 0.66;">
<img `r src_alt_fig_chunk("prior-beta")` style="vertical-align: middle;">
  </div>
</div>

なんと、事後分布もベータ分布になる。

<div>\[\begin{split}
\text{Posterior}
  &\propto \text{Binom}(1 \mid 4,~p) \times \text{Beta}(p \mid  1, 1)\\
  &= \binom {1} {4} p^{1} (1 - p)^{3} \times
     \frac{\Gamma(1 + 1)}{\Gamma(1) \Gamma(1)} p^{1-1} (1 - p)^{1-1} \\
  &= C p^{2-1} (1 - p)^{4-1} \\
  &= \text{Beta}(p \mid 2, 4)
\end{split}\]</div>

ベータ分布の形パラメータ$a$が表、$b$が裏の回数分だけ増加。


---
## 表が出る確率のベイズ推定: 4. 逐次学習

さっきの事後分布を事前分布として、さらにデータを集める。

コイントス4回のうち表1回、に基づく**事前分布**: $\text{Beta}(p \mid 2,~4)$

さらに16回投げたら表が7回、の**尤度**: $\text{Binomial}(7 \mid 16,~p)$

**事後分布**はまた事前分布と同じ形になる:

<div>\[\begin{split}
\text{Beta}(p \mid 9, 13) \propto
  \text{Binomial}(7 \mid 16,~p) \times \text{Beta}(p \mid 2, 4)
\end{split}\]</div>

データを加えるたびに更新していける:

<img `r src_alt_fig_chunk("coin-bayesian")` width="90%">

---
## 共役事前分布

事後分布が事前分布と同じ形なので計算しやすい、という組み合わせ。

| 尤度関数 | 共役事前分布 |
| ---------- | ------------ |
| 二項分布 | ベータ分布 |
| ポアソン分布 | ガンマ分布 |
| 正規分布 | ガンマ分布 |
| 正規分布 (分散既知) | 正規分布 |

共役事前分布を使うことが常に最善とは限らない。<br>
**無情報事前分布**を使って計算機に頑張らせる風潮。

---
## 事後分布を用いた推定

<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">

区間推定
: 幅のある推定値を提示
: e.g., 95%ベイズ確信区間:<br>
  等裾事後確信区間 (<u>E</u>qual-<u>T</u>ailed <u>I</u>nterval)<br>
  最高密度区間 (<u>H</u>ighest <u>D</u>ensity <u>I</u>nterval)

点推定
: 値を1点だけ提示
: e.g.,<br>
  事後確率最大値 (<u>M</u>aximum <u>A</u> <u>P</u>osteriori)<br>
  事後中央値 (Posterior <u>Med</u>ian)<br>
  事後期待値 (<u>E</u>xpected <u>A</u> <u>P</u>osteriori)

  </div>
  <div class="column" style="flex-shrink: 1.3;">

```{r, integrate}
#| echo: false
#| fig.width: 5
#| fig.height: 8.2
#| cache-globals: false
hdi_lowerbound = function(density, ci = 0.95) {
  x = sort(density, decreasing = TRUE)
  cumsum_x = cumsum(x)
  sum_x = cumsum_x[length(x)]
  y = x[cumsum_x < (ci * sum_x)]
  y[length(y)]
}

n_head = 3
n_total = 12
df_density = tibble::tibble(
  p = seq(0, 1, 0.001),
  Density = dbeta(p, n_head, n_total - n_head)
)

.theme = theme_minimal(base_size = 20) + theme(
  panel.grid.minor = element_blank(),
  panel.grid.major.y = element_blank(),
  axis.text = element_blank()
)

bound = qbeta(c(0.025, 0.975), n_head, n_total - n_head)
.f = function(.x) {dplyr::filter(.x, dplyr::between(p, bound[1], bound[2]))}
.g = function(.x) {dplyr::mutate(.x, Density = ifelse(dplyr::between(p, bound[1], bound[2]), 0, Density))}
p_eti = df_density |>
  ggplot() + aes(p, Density) +
  geom_hline(yintercept = 0) +
  geom_line(color = "#999999", linewidth = 1) +
  geom_area(data = .f, fill = "#56B4E9", alpha = 0.5) +
  geom_area(data = .g, fill = "#333333", alpha = 0.8) +
  annotate("text", x = bound[1], y = 0.7, label = "2.5%", color = "#333333", hjust = 1) +
  annotate("text", x = bound[2], y = 0.7, label = "2.5%", color = "#333333", hjust = 0) +
  scale_x_continuous(breaks = bound) +
  labs(title = "Equal-Tailed Interval (ETI)", x = "Parameter") +
  .theme + theme(panel.grid.major = element_line(color = "#56B4E9"))

hdi_lb = hdi_lowerbound(df_density$Density)
df_hdi = df_density |> dplyr::filter(Density >= hdi_lb)
range_hdi = df_hdi |> dplyr::reframe(p = range(p)) |> dplyr::pull(p)
p_hdi = df_density |>
  ggplot() + aes(p, Density) +
  geom_hline(yintercept = 0) +
  geom_area(data = df_hdi, fill = "#56B4E9", alpha = 0.5) +
  geom_line(color = "#999999", linewidth = 1) +
  geom_hline(aes(yintercept = hdi_lb), color = "#444444", linewidth = 1, linetype = "dashed") +
  scale_x_continuous(breaks = range_hdi) +
  labs(title = "Highest Density Interval (HDI)", x = "Parameter") +
  .theme + theme(panel.grid.major = element_line(color = "#56B4E9"))

.map = function(.x) {dplyr::slice_max(.x, Density)}
.med = function(.x) {
  .x |>
    dplyr::mutate(cs = cumsum(Density)) |>
    dplyr::mutate(diff = abs(cs - 0.5 * max(cs))) |>
    dplyr::slice_min(diff)
}
.eap = function(.x) {
  .x |>
    dplyr::mutate(diff = abs(.data$p - sum(p * Density) / sum(Density))) |>
    dplyr::slice_min(diff)
}
.colors = setNames(palette()[2:4], c("map", "med", "eap"))
p_point = df_density |>
  ggplot() + aes(p, Density) +
  geom_hline(yintercept = 0) +
  geom_line(color = "#999999", linewidth = 1) +
  geom_vline(aes(xintercept = p), .map, color = .colors["map"], linewidth = 1) +
  geom_vline(aes(xintercept = p), .med, color = .colors["med"], linewidth = 1) +
  geom_vline(aes(xintercept = p), .eap, color = .colors["eap"], linewidth = 1) +
  geom_point(aes(y = 0), .map, color = .colors["map"], size = 4, shape = 16) +
  geom_point(aes(y = 0), .med, color = .colors["med"], size = 4, shape = 16) +
  geom_point(aes(y = 0), .eap, color = .colors["eap"], size = 4, shape = 16) +
  ggrepel::geom_text_repel(aes(y = 0.25, label = "MAP"), .map, color = .colors["map"], size = 5, nudge_x = -0.08) +
  ggrepel::geom_text_repel(aes(y = 0.45, label = "MED"), .med, color = .colors["med"], size = 5, nudge_x = 0.1) +
  ggrepel::geom_text_repel(aes(y = 0.25, label = "EAP"), .eap, color = .colors["eap"], size = 5, nudge_x = 0.2) +
  labs(title = "Point Estimation", x = "Parameter") +
  .theme + theme(panel.grid = element_blank())
cowplot::plot_grid(p_eti, p_hdi, p_point, ncol = 1L)
```

  </div>
</div>

???

ベイズ確信区間 (credible interval)
: 真の値が95%の確率で含まれる区間。

信頼区間 (confidence interval)
: 頻度主義の考え方に基づいていて、解釈が難しい。
「標本抽出を100回繰り返すとそのうちの95回はその区間に母平均が含まれる」
真の値は1つに定まっていて、不確実性は有限のサンプリングに由来する。



---
## ベイズ推定の中間まとめ

- 推定結果は**事後分布** ∝ 尤度関数。
    - 広がり具合によって不確実性も表現できる。
    - **逐次学習**で尖っていき、確信が強まる。

<img `r src_alt_fig_chunk("coin-bayesian")` width="80%">

<hr>

コイン投げモデルのベータ分布は美しい例。<br>
→ 解析的(数学的)に解ける。

実践的なモデル・事後分布はもっと複雑。<br>
→ コンピュータに頼って数値計算: MCMC


---
## MCMC: <u>M</u>arcov <u>C</u>hain <u>M</u>onte <u>C</u>arlo

<a href="https://en.wikipedia.org/wiki/Andrey_Markov">
<img src="../tokiomarine2021/image/AAMarkov.jpg" height="270" align="right"></a>

マルコフ連鎖
: 次の時点の挙動が現在の値だけで決定されるような確率過程。
: $\ldots \to X_{t - 2} \to X_{t - 1} \to X_{t} \to X_{t + 1}$
: $\Pr(X_{t+1} \mid X_{t}, X_{t-1}, X_{t-2}, \ldots) = \Pr(X_{t+1} \mid X_{t})$
: e.g., すごろく

モンテカルロ法
: 乱数を用いた計算方法の総称。
: <a href="https://en.wikipedia.org/wiki/Monte_Carlo_Casino">
  <img src="../tokiomarine2021/image/Real_Monte_Carlo_Casino.jpg" height="320"></a>
  <a href="https://en.wikipedia.org/wiki/Stanislaw_Ulam">
  <img src="../tokiomarine2021/image/Stanislaw_Ulam.jpg" height="320"></a>
  <a href="https://en.wikipedia.org/wiki/John_von_Neumann">
  <img src="../tokiomarine2021/image/John_von_Neumann.jpg" height="320"></a>
  <a href="https://en.wikipedia.org/wiki/Nicholas_Metropolis">
  <img src="../tokiomarine2021/image/Nicholas_Metropolis.png" height="320"></a>

???
スタニスワフ・ウラムがソリテアの成功率を考えてた時に思いついて、
同僚のジョン・フォン・ノイマンが計算機上での実用まで持ってった。
モナコ公国のモンテカルロ地区に国営カジノがあって、
ウラムの叔父がそこで負けて親戚から借金したことにちなんで
同僚のニコラス・メトロポリスが命名したらしい。

マルコフ連鎖
: マルコフ過程のうち、離散的な時間を考えるもの。

マルコフ過程
: マルコフ性を持つ確率過程

マルコフ性
: 次の時点の挙動が現在の値だけで決定され、過去の値と無関係


最適化ではなくサンプリング法


---
## モンテカルロ法は乱数を用いた計算方法

e.g., 半径1の円の面積

数学を知っていれば $\pi r ^ 2 \approx 3.14159$

面積4の正方形に400個の一様乱数を打ち込んだら318個が円に乗った:<br>
$4 \times \frac {318} {400} = 3.18$

```{r, circle}
#| echo: false
#| fig.width: 4.2
#| fig.height: 4.2
set.seed(19937)
.n = 200L
.theta = seq(0, 2 * pi, length.out = 100)
tibble(x = runif(.n, -1, 1), y = runif(.n, -1, 1)) |>
  dplyr::mutate(accepted = x ^ 2 + y ^ 2 < 1) |>
  ggplot() + aes(x, y) +
  annotate("polygon", x = cos(.theta), y = sin(.theta), fill = "#888888", alpha = 0.4) +
  geom_point(data = \(x) dplyr::filter(x, !accepted), shape = 16, alpha = 0.5, size = 2) +
  geom_point(data = \(x) dplyr::filter(x, accepted), color = "#56B4E9", shape = 16, size = 2) +
  coord_fixed(xlim = c(-1, 1), ylim = c(-1, 1), expand = FALSE)  +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank(), axis.ticks = element_blank())
```

---
## 変な分布もモンテカルロ法で扱えそう

e.g., 確率密度分布に従って変数Xを集める(棄却サンプリング)。

```{r, mcpdf}
#| include: false
#| fig.width: 5
#| fig.height: 5
set.seed(24601)
n = 800
df_point = tibble::tibble(p = runif(n, -0.2, 1.2), Density = runif(n, 0, 5)) |>
  dplyr::mutate(accepted = Density < (dbeta(p, 4, 6) + dbeta(p, 70, 30)) / 2)
p_pdf = tibble::tibble(p = seq(0, 1, 0.01), Density = (dbeta(p, 4, 6) + dbeta(p, 70, 30)) / 2) |>
  ggplot() + aes(p, Density) +
  geom_hline(yintercept = 0) +
  geom_area(fill = "#000000", alpha = 0.33) +
  geom_point(data = df_point |> dplyr::filter(!accepted), shape = 16, alpha = 0.5) +
  geom_point(data = df_point |> dplyr::filter(accepted), color = "#56B4E9", shape = 16, size = 2, alpha = 1) +
  labs(x = "X") +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank(), axis.ticks = element_blank(),
        panel.grid.major.y = element_blank(), panel.border = element_blank(),
        axis.text = element_blank())

p_accepted = tibble::tibble(p = runif(n), th = dbeta(p, 4, 6) + dbeta(p, 70, 30)) |>
  dplyr::filter(runif(length(p), 0, max(th)) < th) |>
  ggplot() + aes(p) +
  geom_hline(yintercept = 0) +
  coord_cartesian(xlim = c(-0.2, 1.2)) +
  geom_histogram(bins = 20, center = 0.5, fill = "#56B4E9", alpha = 0.66) +
  labs(x = "X") +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank(), axis.ticks = element_blank(),
        panel.grid.major.y = element_blank(), panel.border = element_blank(),
        axis.text = element_blank())

print(p_pdf)
print(p_accepted)
```

<div>
<img `r src_alt_fig_chunk("mcpdf", number = 2)` style="vertical-align: middle;">
$\;\sim\;$
<img `r src_alt_fig_chunk("mcpdf")` style="vertical-align: middle;">
</div>

でも、ハズレの値もけっこう引いてしまう。


---
## 次元の呪い: 高次元になるほど当たりにくくなる

(N次元球の体積 / N次元の立方体) はゼロに近づいていく。

<img `r src_alt_fig_chunk("circle")` align="right">

- 2次元: $\frac {\pi r ^ 2} {(2r) ^ 2} = \frac \pi 4 \approx 0.79$
- 3次元: $\frac {\frac 4 3 \pi r ^ 3} {(2r) ^ 3} = \frac \pi 6 \approx 0.52$
- N次元: $\frac {\frac {\pi ^ {N/2}} {\Gamma (N/2 + 1)} r ^ N} {(2r) ^ N} = \frac {\pi ^ {N/2}} {2^N \Gamma (N/2 + 1)} \to 0$

パラメータが増えると計算量(≈乱数の無駄撃ち)が急増。

<hr>

密度の高い「当たり」付近を効率よく探索したい。<br>
「当たり」は「当たり」の近くにありがちだろう。<br>
→ マルコフ連鎖が使えそう


---
## Metropolis--Hastings法 (MH法)

0.  パラメータ $\theta$ の初期値を選ぶ
1.  $\theta$ をちょっと増減させて $\theta_\text{new}$ を作る
2.  それぞれ尤度を計算し、比較。
    - $L(\theta_\text{new}) \ge L(\theta)$ なら $\theta_\text{new}$ を即採択
    - $L(\theta_\text{new}) < L(\theta)$ でも
      確率 $r = \frac {L(\theta_\text{new})} {L(\theta)}$ で  $\theta_\text{new}$ を採択
3.  $\theta_\text{new}$ が採択されたら $\theta$ を更新。手順1に戻る。

```{r, metropolis-globals}
#| include: false
n_head = 12
n_total = 20
```
```{r, metropolis}
#| echo: false
#| fig.width: 12
#| fig.height: 3.6
.logLik = function(p) dbinom(n_head, n_total, p, log = TRUE)
.delta = 0.02
df_point = tibble::tibble(p = seq(0.48, 0.64, .delta), logLik = .logLik(p))
df_arrow = df_point |>
  dplyr::group_by(p) |>
  dplyr::mutate(data = purrr::map(p, \(.p) {
    pl = .p + 0.005
    pr = .p + .delta - 0.005
    ll = .logLik(pl)
    lr = .logLik(pr)
    if (ll < lr) {
      data.frame(pbegin = pl, pend = pr, lbegin = ll, lend = lr)
    } else {
      data.frame(pbegin = pr, pend = pl, lbegin = lr, lend = ll)
    }
  })) |>
  tidyr::unnest(data)

.ar = grid::arrow(angle = 20, length = grid::unit(0.11, "inches"), type = "closed")
.ar2 = grid::arrow(angle = 20, length = grid::unit(0.09, "inches"), type = "closed", ends = "first")
.aes = aes(pbegin, lbegin, xend = pend, yend = lend)
df_point |>
  ggplot() + aes(p, logLik) +
  geom_segment(.aes, df_arrow, linejoin = "mitre", linewidth = 1,
    position = position_nudge(0, +0.009), arrow = .ar) +
  geom_segment(.aes, df_arrow, linejoin = "mitre", linewidth = 1,
    position = position_nudge(0, -0.009), arrow = .ar2, alpha = 0.33) +
  geom_point(size = 6, alpha = 0.6, shape = 16) +
  labs(x = expression(theta)) +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank(), axis.ticks = element_blank())
```

---
## 採択されたパラメータ値の軌跡

尤度が高い方にただ向かうだけでなく、結構うろつく。<br>
通ったパラメータ値を集めるといい感じの分布が得られる。

```{r, metropolis-trajectory}
#| echo: false
#| fig.show: "animate"
#| animation.hook: "gifski"
#| interval: 0.2
#| fig.width: 12
#| fig.height: 6
mh_sample = function(n, p0, n_head, n_total, delta) {
  p = p0
  lp = dbinom(n_head, n_total, p, log = FALSE)
  posterior = p
  for (i in seq.int(2L, n)) {
    p_new = p + sample(c(-delta, delta), 1)
    lp_new = suppressWarnings(dbinom(n_head, n_total, p_new, log = FALSE))
    if (is.nan(lp_new)) next
    if (lp_new > lp) {
      p = p_new
      lp = lp_new
    } else {
      if (runif(1L) < (lp_new / lp)) {
        p = p_new
        lp = lp_new
      }
    }
    posterior = c(posterior, p)
  }
  tibble::tibble(p = round(posterior, 6)) |> tibble::rowid_to_column("t")
}
.n = 800
.dp = 0.04
df_trace = tibble::tibble(init = c(0.06, 0.5, 0.94)) |>
  dplyr::mutate(data = purrr::map(init, ~{mh_sample(.n, .x, n_head, n_total, delta = .dp)})) |>
  tidyr::unnest(data)

df_traj = df_trace |> dplyr::filter(init == min(init)) |> dplyr::select(!init)

p_traj = df_traj |>
  ggplot() + aes(t, p) +
  geom_line(linewidth = 0.8, alpha = 0.66) +
  coord_cartesian(xlim = c(0, .n), ylim = c(0, 1)) +
  labs(title = "traceplot", y = expression(theta), x = "iterations") +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank(), axis.ticks = element_blank())

p_hist = df_traj |>
  ggplot() + aes(p) +
  geom_bar() +
  coord_flip(xlim = c(0, 1)) +
  labs(title = "MCMC samples") +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank(), axis.ticks = element_blank(),
        axis.title.y = element_blank(), axis.text.y = element_blank())

ymax = max(ggplot_build(p_hist)$data[[1]]$count)

for (i in seq.int(40, .n, 40)) {
  df_traj_head = df_traj |> head(i)
  p1 = p_traj %+% df_traj_head
  p2 = p_hist %+% df_traj_head + ylim(c(0, ymax))
  p = cowplot::plot_grid(p1, p2, nrow = 1L, rel_widths = c(4, 1))
  print(p)
}
```


---
## 尤度に比例する事後分布からサンプルしたのと等価

全体にばら撒く棄却サンプリングよりも効率よく集められる。<br>
が、パラメータ1つの1次元ではご利益はわかりにくい。

```{r, propto-lik}
#| include: false
#| fig.width: 3.5
#| fig.height: 3.5
.theme = theme_bw(base_size = 20) +
  theme(panel.grid.minor.y = element_blank(), axis.ticks = element_blank(),
        panel.grid.major.y = element_blank(), panel.border = element_blank())

p_lik = tibble::tibble(p = seq(0, 1, 0.01), Lik = dbinom(n_head, n_total, p, log = FALSE)) |>
  ggplot() + aes(p, Lik) +
  geom_hline(yintercept = 0) +
  geom_line(linewidth = 2) +
  scale_x_continuous(breaks = c(0, 0.5, 1)) +
  labs(title = "Likelihood", x = expression(theta)) +
  .theme

p_dens = tibble::tibble(p = seq(0, 1, 0.01), Density = dbeta(p, n_head, n_total - n_head)) |>
  ggplot() + aes(p, Density) +
  geom_hline(yintercept = 0) +
  geom_area(alpha = 0.5) +
  scale_x_continuous(breaks = c(0, 0.5, 1)) +
  labs(title = "Posterior", x = expression(theta)) +
  .theme

p_hist = df_traj |> tail(-100) |>
  ggplot() + aes(p) +
  geom_hline(yintercept = 0) +
  geom_bar() +
  scale_x_continuous(breaks = c(0, 0.5, 1)) +
  coord_cartesian(xlim = c(0, 1)) +
  labs(title = "MCMC samples", x = expression(theta), y = "Count") +
  .theme

print(p_hist)
print(p_dens)
print(p_lik)
```

<div>
<img `r src_alt_fig_chunk("propto-lik")` style="vertical-align: middle;">
$\;\sim\;$
<img `r src_alt_fig_chunk("propto-lik", number = 2)` style="vertical-align: middle;">
$\;\propto\;$
<img `r src_alt_fig_chunk("propto-lik", number = 3)` style="vertical-align: middle;">
</div>

パラメータが複数ある場合は？


---
## Gibbs Sampling

パラメータが複数の場合「ほかを固定してひとつ更新」を繰り返す。

e.g., 二次元正規分布。(-2, 2) からスタート。

```{r, gibbs}
#| echo: false
#| fig.show: "animate"
#| animation.hook: "gifski"
#| interval: 0.1
#| fig.width: 5
#| fig.height: 5
gibbs_sample = function(n, rho) {
  x = double(n)
  y = double(n)
  x[1] = -2
  y[1] = 2
  for (i in seq.int(2, n)) {
    x[i] = rnorm(1, rho * y[i - 1], sqrt(1 - rho ** 2))
    y[i] = rnorm(1, rho * x[i], sqrt(1 - rho ** 2))
  }
  x = rep(x, each = 2)
  y = rep(y, each = 2)
  tibble::tibble(x = x[-1], y = y[-2 * n])
}

set.seed(19937)
rho = 0.8
df_gibbs = gibbs_sample(40, rho)

p_tile = tidyr::crossing(x = seq(-3, 3, 0.05), y = x) |>
  dplyr::mutate(z = x^2 + y^2 - 2 * rho * x * y,
                d = (1 / (2 * pi * sqrt(1 - rho ** 2))) * exp(-0.5 * z / (1 - rho ** 2))) |>
  ggplot() + aes(x, y) +
  geom_tile(aes(fill = d)) +
  scale_fill_gradient(low = "#f8f8f8", high = "black") +
  coord_fixed(expand = FALSE) +
  theme_void() + theme(legend.position = "none")

for (i in seq.int(2L, nrow(df_gibbs), 2L)) {
  df_i = head(df_gibbs, i)
  p = p_tile +
    geom_path(data = df_i, color = "#56B4E9", alpha = 0.66, linewidth = 1) +
    geom_point(data = df_i, color = "#56B4E9", alpha = 0.66, shape = 16, size = 2)
  print(p)
}
```


---
## 何回やっても似たような結果になってほしい

乱数や初期値によって偶々、じゃないことを確認したい。

e.g., `chains = 3` 。ほぼ同じところをうろうろ:

```{r, chains}
#| echo: false
#| fig.height: 5
#| fig.width: 12
t_warmup = 200
p_trace = ggplot(df_trace) + aes(t, p, group = init) +
  geom_path(aes(color = as.factor(init)), linewidth = 0.8) +
  scale_color_discrete(guide = NULL) +
  labs(title = "traceplot", y = expression(theta), x = "iterations") +
  coord_cartesian(ylim = c(0, 1)) +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank(), axis.ticks = element_blank())

p_hist = df_trace |>
  dplyr::mutate(init = as.factor(init)) |>
  ggplot() + aes(p) +
  geom_bar(aes(fill = init), position = position_stack(reverse = TRUE)) +
  coord_flip(xlim = c(0, 1)) +
  labs(title = "MCMC samples") +
  theme_bw(base_size = 20) +
  theme(panel.grid.minor = element_blank(), axis.ticks = element_blank(),
        axis.title.y = element_blank(), axis.text.y = element_blank(),
        legend.position = "none")
cowplot::plot_grid(p_trace, p_hist, nrow = 1L, rel_widths = c(4, 1))
```

収束(convergence)の判定については後ほど。

---
## 初期値の影響が消えるまでウォーミングアップ

定常分布の山に到達してからが本番。

e.g., `iter_warmup = 200, iter_sampling = 600` で灰色の部分を捨てる:

```{r, warmup}
#| echo: false
#| fig.height: 5
#| fig.width: 12
cowplot::plot_grid(
  p_trace + annotate("ribbon", x = c(0, t_warmup), ymin = Inf, ymax = -Inf, alpha = 0.3),
  p_hist %+% (df_trace |> dplyr::mutate(init = as.factor(ifelse(t < t_warmup, NA, init)))),
  nrow = 1L, rel_widths = c(4, 1)
)
```

どれくらい長く捨てるべきかは場合による。


---
## 適度に間引いて自己相関を軽減したい

直前の値と似すぎていたら独立サンプルとして扱えないので。

e.g., `thin = 5` で5回に1回だけサンプルする:

```{r, thin}
#| echo: false
#| fig.height: 5
#| fig.width: 7
p_trace +
  coord_cartesian(ylim = c(0, 1), xlim = c(200, 260)) +
  geom_point(data = \(.x) {dplyr::filter(.x, t %% 5 == 0)}, alpha = 0.6, size = 3, shape = 16)
```

間引かなくても大丈夫な場合も、間引いても解決しない場合もある。



---
## 収束判定

- 複数chainsで異なる初期値から実行し、軌跡を可視化(traceplot)
- Gelman-Rubin統計量 $\hat R < 1.05$
- Effective Sample Size (ESS) $N_\text{eff} > 100$ per chain

```{stan, converge-yes}
#| cache_stan: true
#| echo: false
data {
  int<lower=0> N;
  array[N] int x;
}

parameters {
  real<lower=0> lambda;
}

model {
  x ~ poisson(lambda);
}
```
```{stan, converge-no}
#| cache_stan: true
#| echo: false
data {
  int<lower=0> N;
  array[N] int x;
}

parameters {
  real lambda;
  real jammer;
}

model {
  x ~ poisson(lambda + jammer);
}
```

```{r, converge-template}
#| include: false
conv_data = tibble::lst(N = 10L, x = rep(10L, N))
myplot_trace = function(fit) {
  s = fit$summary(variables = "lambda")
  stats = sprintf("Rhat = %.4f, N_eff = %.1f", s[["rhat"]], s[["ess_bulk"]])
  bayesplot::mcmc_trace(fit$draws("lambda")) +
    scale_color_discrete(guide = "none") +
    labs(title = ifelse(s[["rhat"]] < 1.05, "Good", "Bad"), subtitle = stats) +
    theme_bw(base_size = 20) +
    theme(panel.grid.minor = element_blank(), axis.ticks = element_blank(),
      axis.title.y = element_blank(), axis.text.y = element_blank())
}
```
```{r, converge-yes-plot}
#| include: false
#| cache_stan: "converge-yes"
#| stan_save_output_files: "fit_yes"
mod_yes = cmdstanr::cmdstan_model("stan/converge-yes.stan")
fit_yes = mod_yes$sample(data = conv_data, seed = 24601L, refresh = 0)
p_yes = myplot_trace(fit_yes)
```
```{r, converge-no-plot}
#| include: false
#| cache_stan: "converge-no"
#| stan_save_output_files: "fit_no"
mod_no = cmdstanr::cmdstan_model("stan/converge-no.stan")
fit_no = mod_no$sample(data = conv_data, seed = 24601L, refresh = 0, show_messages = FALSE)
p_no = myplot_trace(fit_no)
```
```{r, convergence}
#| echo: false
#| fig.height: 4
#| fig.width: 12
cowplot::plot_grid(p_yes, p_no, nrow = 1L)
```

[`diagnose()`](https://mc-stan.org/docs/cmdstan-guide/diagnose_utility.html)
みたいな機能が提供されていれば利用する。

実行時に[警告してもらえること](https://mc-stan.org/misc/warnings.html)もある。

???
https://ill-identified.hatenablog.com/entry/2020/05/21/001158


---
## 収束・自己相関が悪い場合にどう改善するか

- 小手先の対処
    - iteration (warmup + sampling) をもっと長く
    - thinを大きくして間引く
- ちょっと大掛かり
    - プログラムの書き方を改善する
    - モデルの構造を見直す
    - アルゴリズム・ソフトウェアを変える


---
## 似て非なる: MCMCサンプル増やす vs データ増やす

<div>
<img `r src_alt_fig_chunk("propto-lik")` style="vertical-align: middle;">
$\;\sim\;$
<img `r src_alt_fig_chunk("propto-lik", number = 2)` style="vertical-align: middle;">
$\;\propto\;$
<img `r src_alt_fig_chunk("propto-lik", number = 3)` style="vertical-align: middle;">
</div>

- MCMCサンプルを増やす → 事後分布・尤度関数をより良く近似
- データを増やす → 分布の裾野が狭まり、確信が強まる

<img `r src_alt_fig_chunk("coin-bayesian")`>


---
##  MCMCの方法いろいろ

採択率を高め、早く収束するように改良されてきている。

- Metropolis--Hastings法
    - Gibbs Sampling
    - Hamiltonian Monte Carlo (HMC)
        - No-U-Turn Sampler (NUTS)


---
## MCMCソフトウェア

- [BUGS](https://www.mrc-bsu.cam.ac.uk/software/)
    - クローズドソースで、ほぼWindows専用。
- [JAGS](https://mcmc-jags.sourceforge.io/)
    - オープンソースで、さまざまなOS・言語から利用可能。
    - マニュアルや用例が不足。
- [**Stan**](https://mc-stan.org/) 👈
    - オープンソースで、さまざまなOS・言語から利用可能。
    - 開発も利用も活発。マニュアルや用例も充実。
    - HMC/NUTSにより早く収束。
- [PyMC3](https://docs.pymc.io/)
- [NumPyro](https://num.pyro.ai/)
- [TensorFlow Probability](https://www.tensorflow.org/probability/)


---
## Stan

<a href="https://mc-stan.org/">
<img src="/slides/image/stan/logo_name.png" width="180" align="right">
</a>

- Stan言語で**モデルを柔軟に記述**できる。
- C++で書かれていて**高速に動作**。
- RやPythonなどから呼び出して使うのが便利。

## Python Interface

[PyStan](https://pystan.readthedocs.io)
: WindowsやJupyterで使うには難あり。

[CmdStanPy](https://cmdstanpy.readthedocs.io) 👈 今後の主流
: [CmdStan](https://mc-stan.org/users/interfaces/cmdstan)
  を呼び出し、書き出されたCSVを読み取る。



---
## 参考文献

- [データ解析のための統計モデリング入門](https://amzn.to/33suMIZ) 久保拓弥 2012
- [StanとRでベイズ統計モデリング](https://amzn.to/3uwx7Pb) 松浦健太郎 2016
- [RとStanではじめる ベイズ統計モデリングによるデータ分析入門](https://amzn.to/3o1eCzP) 馬場真哉 2019
- [データ分析のための数理モデル入門](https://amzn.to/3uCxTKo) 江崎貴裕 2020
- [分析者のためのデータ解釈学入門](https://amzn.to/3uznzCK) 江崎貴裕 2020
- [統計学を哲学する](https://amzn.to/3ty80Kv) 大塚淳 2020

`r .meta$next_link`
