+++
url = "tmd2022stats/3-likelihood.html"
title = "3. 尤度、最尤推定 — 統計モデリング実習 2022 TMDU"
linktitle = "尤度、最尤推定"
date = 2023-03-18T13:00:00+09:00
type = "reveal"
draft = true
+++

<link rel="stylesheet" href="style.css">

# [統計モデリング実習 2022 TMDU](.)

<div class="author">
岩嵜 航 (Watal M. Iwasaki, PhD)
</div>

<div class="affiliation">
東北大学 生命科学研究科 進化ゲノミクス分野 特任助教<br>
(Graduate School of Life Sciences, Tohoku University)
</div>

<ol>
<li><a href="1-introduction.html">導入、直線回帰</a>
<li><a href="2-distribution.html">確率分布、擬似乱数生成</a>
<li class="current-deck"><a href="3-likelihood.html">尤度、最尤推定</a>
<li><a href="4-glm.html">一般化線形モデル (GLM)</a>
<li><a href="5-glmm.html">個体差、一般化線形混合モデル (GLMM)</a>
<li><a href="6-bayesian.html">ベイズ推定とMCMC</a>
<li><a href="7-stan.html">StanでGLM</a>
<li><a href="8-hbm.html">階層ベイズモデル (HBM)</a>
</ol>

<div class="footnote">
2023-03-18 東京医科歯科大学
<a href="https://heavywatal.github.io/slides/tmd2022stats/">https://heavywatal.github.io/slides/tmd2022stats/</a>
</div>

```{r setup-global, include=FALSE, file = "setup.R"}
```

```{r setup-local, include=FALSE}
library(ggplot2)
library(tibble)
library(dplyr)
library(tidyr)
knitr::opts_chunk$set(cache = TRUE)
```

---
## データに分布をあてはめたい

ある植物を50個体調べて、それぞれの種子数Xを数えた。

```{r poisson-seed, echo = FALSE, fig.height = 4, fig.width = 4}
df_rpois = tibble::tibble(X = rpois(50L, 3))
ggplot(df_rpois) +
  aes(X) +
  geom_bar() +
  theme_bw(base_size = 18) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.major.x = element_blank(),
    axis.ticks = element_blank()
  )
```

カウントデータだからポアソン分布っぽい。<br>
ポアソン分布のパラメータ $\lambda$ はどう決める？


---
## データに分布をあてはめたい

ある植物を50個体調べて、それぞれの種子数Xを数えた。

```{r poisson-seed-lambda, echo = FALSE, fig.height = 4, fig.width = 11}
df_dpois = purrr::map_dfr(c(1, 3, 5), ~ {
  tibble(lambda = .x, X = seq(0, 11), Prob = dpois(X, lambda))
})
p_pois = ggplot(df_rpois) +
  aes(X) +
  geom_bar(aes(y = after_stat(prop)), width = 0.4) +
  geom_col(data = df_dpois, aes(y = Prob), alpha = 0.5, fill = "#3366ff") +
  facet_wrap(vars(lambda), nrow = 1L, labeller = label_both) +
  theme_bw(base_size = 18) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(), axis.ticks = element_blank()
  )
p_pois
```

カウントデータだからポアソン分布っぽい。<br>
ポアソン分布のパラメータ $\lambda$ はどう決める？<br>
(黒が観察データ。<span style="color: #3366ff;">青がポアソン分布</span>。よく重なるのは？)


---
## <ruby>尤<rt>ゆう</rt>度</ruby> (likelihood)

<ruby>尤<rt>もっと</rt></ruby>もらしさ。
モデルのあてはまりの良さの尺度のひとつ。

**あるモデル$M$の下でそのデータ$D$が観察される確率**。<br>
定義通り素直に書くと<br>
$\text{Prob}(D \mid M)$

データ$D$を固定し、モデル$M$の関数とみなしたものが**尤度関数**:<br>
$L(M \mid D)$

モデルの構造も固定してパラメータ$\theta$だけ動かす場合はこう書く:<br>
$L(\theta \mid D)$ とか $L(\theta)$ とか


---
## 尤度を手計算できる例

コインを5枚投げた結果 $D$: 表 4, 裏 1

表が出る確率 $p = 0.5$ と仮定:
<div>\[\begin{split}
L(0.5 \mid D)
  &= \binom 5 1 \times \text{Prob}(表 \mid 0.5) ^ 4 \times \text{Prob}(裏 \mid 0.5) ^ 1 \\
  &= 5 \times 0.5 ^ 4 \times 0.5 ^ 1 = 0.15625
\end{split}\]</div>

表が出る確率 $p = 0.8$ と仮定:
<div>\[\begin{split}
L(0.8 \mid D)
  &= \binom 5 1 \times \text{Prob}(表 \mid 0.8) ^ 4 \times \text{Prob}(裏 \mid 0.8) ^ 1 \\
  &= 5 \times 0.8 ^ 4 \times 0.2 ^ 1 = 0.4096
\end{split}\]</div>

$L(0.8 \mid D) > L(0.5 \mid D)$

$p = 0.8$ のほうがより尤もらしい。



---
## 種子数ポアソン分布の例でも尤度を計算してみる

ある植物が作った種子を数える。$n = 50$個体ぶん。

<div>\[\begin{split}
L(\lambda \mid D)
  = \prod _i ^n \text{Prob}(X_i \mid \lambda)
  = \prod _i ^n \frac {\lambda ^ {X_i} e ^ {-\lambda}} {X_i !}
\end{split}\]</div>

```{r poisson-seed-likelihood, echo = FALSE, fig.height = 4, fig.width = 11}
df_likelihood = df_rpois |>
  dplyr::left_join(df_dpois, by = "X") |>
  dplyr::group_by(lambda) |>
  dplyr::summarize(L = prod(Prob)) |>
  dplyr::mutate(logL = log(L), label = sprintf("L(%.0f|D) = %.1e", lambda, L))
p_pois +
  geom_text(data = df_likelihood, aes(label = label), x = Inf, y = Inf, hjust = 1.1, vjust = 1.3, size = 6, color = "#3366ff")
```

この中では $\lambda = 3$ がいいけど、より尤もらしい値を求めたい。

---
## 最尤推定 <u>M</u>aximum <u>L</u>ikelihood <u>E</u>stimation

扱いやすい **対数尤度** (log likelihood) にしてから計算する。<br>
一階微分が0になる $\lambda$ を求めると...**標本平均**と一致。

<div>\[\begin{split}
\log L(\lambda \mid D)
  &= \sum _i ^n \left[ X_i \log (\lambda) - \lambda - \log (X_i !) \right] \\
\frac {\mathrm d \log L(\lambda \mid D)} {\mathrm d \lambda}
  &= \frac 1 \lambda \sum _i ^n X_i - n = 0 \\
\hat \lambda &= \frac 1 n \sum _i ^n X_i
\end{split}\]</div>


```{r poisson-mle, echo = FALSE, fig.height = 3, fig.width = 10}
count_rpois = df_rpois |> dplyr::count(X)
calc_likelihood_rpois = function(lambda) {
  prod(dpois(count_rpois[["X"]], lambda)**count_rpois[["n"]])
}
X_mle = mean(df_rpois[["X"]])
L_mle = calc_likelihood_rpois(X_mle)
p_mle = tibble::tibble(lambda = seq(1, 5, 0.1), L = purrr::map_dbl(lambda, calc_likelihood_rpois)) |>
  dplyr::mutate(logL = log(L)) |>
  ggplot() +
  aes(lambda, logL) +
  geom_line() +
  geom_vline(xintercept = X_mle, color = "#3366ff") +
  annotate("point", x = X_mle, y = log(L_mle), size = 3, color = "#3366ff") +
  annotate("text", x = Inf, y = Inf, hjust = 1.1, vjust = 1.2, size = 5, color = "#3366ff", label = sprintf("lambda = %.2f", X_mle)) +
  labs(y = "log L") +
  theme_bw(base_size = 18) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    axis.ticks = element_blank()
  )

df_dpois = tibble(lambda = X_mle, X = seq(0, 11), Prob = dpois(X, lambda))
p_pois = ggplot(df_rpois) +
  aes(X) +
  geom_bar(aes(y = after_stat(prop)), width = 0.4) +
  geom_col(data = df_dpois, aes(y = Prob), alpha = 0.5, fill = "#3366ff") +
  theme_bw(base_size = 18) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(), axis.ticks = element_blank()
  )

cowplot::plot_grid(p_mle, p_pois, nrow = 1L, rel_widths = c(2, 1))
```

---
## 最尤推定を使っても“真のλ”は得られない

今回のデータは真の生成ルール“$X \sim \text{Poisson}(\lambda = 3.0)$”で作った。<br>
「50個体サンプル→最尤推定」を1,000回繰り返してみると:

```{r poisson-mle-repl, echo = FALSE, fig.height = 5, fig.width = 11}
nrep = 1000L
df_repl = tibble::tibble(X = rpois(50L * nrep, 3), repl = rep(seq_len(nrep), each = 50L))
df_sum = df_repl |>
  dplyr::group_by(repl) |>
  dplyr::summarize(lambda = mean(X))
df_minmax = dplyr::bind_rows(dplyr::slice_max(df_sum, lambda), dplyr::slice_min(df_sum, lambda))

p_repl = df_sum |>
  ggplot() +
  aes(lambda) +
  geom_histogram(bins = 25, center = 3) +
  annotate("point", x = df_minmax$lambda, y = 0, color = "#3366ff", size = 8, alpha = 0.5) +
  labs(x = "estimated_lambda") +
  theme_bw(base_size = 18) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    axis.ticks = element_blank()
  )

df_dpois = tidyr::crossing(lambda = df_minmax$lambda, X = seq(0, 11)) |>
  dplyr::mutate(Prob = dpois(X, lambda))
p_minmax = df_repl |>
  dplyr::filter(repl %in% df_minmax$repl) |>
  dplyr::left_join(df_minmax, by = "repl") |>
  ggplot() +
  aes(X) +
  geom_bar(aes(y = after_stat(prop)), width = 0.4) +
  geom_col(data = df_dpois, aes(y = Prob), alpha = 0.5, fill = "#3366ff") +
  facet_wrap(vars(lambda), ncol = 1L, labeller = label_both) +
  theme_bw(base_size = 18) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(), axis.ticks = element_blank()
  )

cowplot::plot_grid(p_repl, p_minmax, nrow = 1L, rel_widths = c(2, 1))
```

サンプルの取れ方によってはかなりズレた推定をしてしまう。<br>
(標本データへのあてはまりはかなり良く見えるのに！)


---
## サンプルサイズを増やすほどマシにはなる

“$X \sim \text{Poisson}(\lambda = 3.0)$”からnサンプル→最尤推定を1,000回繰り返す:

```{r poisson-mle-nsam, echo = FALSE, fig.height = 4, fig.width = 11}
nrep = 1000L
purrr::map_dfr(c(5, 50, 500, 5000), ~ {
  tibble::tibble(X = rpois(.x * nrep, 3), repl = rep(seq_len(nrep), each = .x)) |>
    dplyr::group_by(repl) |>
    dplyr::summarize(estimated_lambda = mean(X)) |>
    dplyr::mutate(n = .x)
}) |>
  ggplot() +
  aes(estimated_lambda) +
  geom_histogram(bins = 25, center = 3) +
  facet_wrap(vars(n), nrow = 1L, labeller = label_both) +
  theme_bw(base_size = 18) +
  theme(
    panel.grid.minor.x = element_blank(), panel.grid.minor.y = element_blank(),
    axis.ticks = element_blank()
  )
```

Q. じゃあどれくらいのサンプル数nを確保すればいいのか？<br>
A. 推定したい統計量とか、許容できる誤差とかによる。


---
## すべてのモデルは間違っている

確率分布がいい感じに最尤推定できたとしても、<br>
それはあくまでモデル。仮定。近似。

> All models are wrong, but some are useful. --- George E. P. Box

<figure>
<img src="../tokiomarine2021/math-model.drawio.svg" width="600"><br>
<figcaption><cite>「データ分析のための数理モデル入門」江崎貴裕 2020 より改変</cite></figcaption>
</figure>


---
## 統計モデリングの道具 --- まとめ

- **確率変数** $X$
- **確率分布** $X \sim f(\theta)$
    - **少ないパラメータ** $\theta$ でばらつきの様子を表現
    - **この現象はこの分布を作りがち(〜に従う)** という知見がある
- **尤度**
    - あるモデルでこのデータになる確率 $\text{Prob}(D \mid M)$
    - データ固定でモデル探索 → **尤度関数** $L(M \mid D),~L(\theta \mid D)$
    - 対数を取ったほうが扱いやすい → **対数尤度** $\log L(M \mid D)$
    - これを最大化するようなパラメータ $\hat \theta$ 探し ＝ **最尤法**


---
## 🔰 尤度の練習問題

サイコロを10回振ったら6の目が3回出た。

1. 6の目の出る確率が1/6だとした場合の尤度は?
1. 6の目の出る確率が0.2だとした場合の尤度は?
1. 横軸を6の目の出る確率、縦軸を対数尤度とするグラフを描こう。
1. このサイコロで6の目が出る確率を最尤推定しよう。<br>
   数学で解ければ**優**。Rで見つければ**良**。目分量・勘で**可**。

ヒント
: 確率pで当たるクジをn回引いてk回当たる確率、と同じ計算を使う。


```{r day3-2, include = FALSE}
get_likelihood = function(p, k = 3, n = 10) {
  choose(n, k) * p**k * (1 - p)**(n - k)
  # dbinom(k, n, p)
}

get_likelihood(0.2)
```

---
<a href="4-glm.html" rel="next" class="readmore">
4. 一般化線形モデルGLM
</a>
