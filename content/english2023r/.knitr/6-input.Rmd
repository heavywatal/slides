```{r, setup-common}
#| file: "setup.R"
#| echo: false
#| results: "asis"
```
```{r, setup-local}
#| include: false
#| cache: false
```

---
## Outline of data analysis

1. Setup computer environment âœ…
1. Get and read input data â¬œ day 6 ğŸ‘ˆ
1. Exploratory data analysis
    - **Preparation** (harder than it seems) âœ… day 3--5
    - **Visualization**, generating hypotheses (fun!) âœ… day 2
    - **Statistical analysis**, testing hypotheses â¬œ day 7--8
1. Report âœ… day 2

<figure>
<a href="https://r4ds.hadley.nz/intro">
<img src="/slides/image/r4ds/data-science.png" width="720">
<figcaption class="url">https://r4ds.hadley.nz/intro</figcaption>
</a>
</figure>


---
## Read/write data.frame

<a href="https://readr.tidyverse.org/">
<img src="/_img/hex-stickers/readr.webp" width="180" align="right">
</a>

- `readxl` package helps reading `.xlsx`, but...
- Prefer CSV (Comma-separated values) and TSV (Tab-).
- Use `readr` package instead of base R functions.
- Specify a file with the **relative path** from **working directory**.

    ```r
    readr::write_tsv(iris, "data/iris.tsv")
    iris2 = readr::read_tsv("data/iris.tsv")
    ```

Oops, an error occurred:

```{r, cannot-open}
#| error: true
#| echo: false
readr::write_tsv(iris, "data/iris.tsv")
```

---
## Common errors when reading/writing files

- Wrong file names
- Wrong directory
- Have not created the output directory.

See [ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼é›† (çŸ³å·ç”±å¸Œã•ã‚“@åå¤å±‹å¤§)](https://comicalcommet.github.io/r-training-2023/R_training_2023_7.html).

<hr>

Check your current directory and its content:
```r
getwd()                 # GET Working Directory
fs::dir_ls(".")         # List files in "." (here)
fs::dir_ls("data")      # List files in "./data"
fs::dir_create("data")  # Create directory
```

ğŸ”° Write some data.frames to `data/` directory.

ğŸ”° Read them and create objects with different names.

---
## ğŸ”° æœ€çµ‚èª²é¡Œäºˆå‘Š

<iframe width="1200" height="810" src="./8-glm.html#/51"></iframe>

èª­ã¿è¾¼ã¿ â†’ å‰å‡¦ç† â†’ å¯è¦–åŒ– â†’ ä½™è£•ã§ã‚¯ãƒªã‚¢ã€ã€ã€ã¨ãªã‚‹ã‹ï¼Ÿ

---
## å®Ÿæ¼”: [e-Stat å›½å‹¢èª¿æŸ»](https://www.e-stat.go.jp/gis/statmap-search?page=1&type=1&toukeiCode=00200521) CSV

2020å¹´ â†’ å°åœ°åŸŸ â†’ å¹´é½¢ï¼ˆï¼•æ­³éšç´šã€ï¼”åŒºåˆ†ï¼‰åˆ¥ã€ç”·å¥³åˆ¥äººå£ â†’ å®®åŸçœŒ

ã†ã¾ãã™ã‚Œã°æ¬¡ã®ã‚ˆã†ãªäººå£ãƒ”ãƒ©ãƒŸãƒƒãƒ‰ã‚’æã‘ã‚‹ã¯ãšã®ãƒ•ã‚¡ã‚¤ãƒ«ã ãŒ...

<img `r src_alt_fig_chunk("estat-plot")`>

---
## Rare to read public data effortlessly

First trial, an error:
```{r, estat-read-error}
#| error: true
infile = "tblT001082C04.txt"
readr::read_csv(infile)
```

View this file with RStudio as a plain text.
Decoding fails:
```{r, estat-as-text}
#| echo: false
readLines(infile, 5L) |> t() |> t() |>
  prmatrix(rowlab = rep("", 5), collab = "", quote = FALSE)
```

Select "File â†’ **Reopen with Encoding...**".<br>
Modern, decent text files should be encoded in **UTF-8**.<br>
Old Japanese text tend to be encoded in **SHIFT-JIS** (or EUC-JP).

---
## Open a file with a different encoding

Next problem: the second row also has column names:
```{r, estat-sjis}
sjis = readr::locale(encoding = "SHIFT-JIS")
readr::read_csv(infile, locale = sjis)
```

---
## Bind the left and right halves after cleaning each

Numeric columns have non-numeric characters like `-` and `X`:
```{r, estat-lr}
dfL = readr::read_csv(infile, locale = sjis, col_select = seq(1, 7)) |>
  dplyr::slice(-1)
dfR = readr::read_csv(infile, locale = sjis, col_select = -seq(1, 7),
  skip = 1L)
raw_miyagi = dplyr::bind_cols(dfL, dfR) |> print()
```

---
## Read non-empty "missing" values as `NA`

OK, now we got to the starting point...
```{r, estat-lr-na}
dfL = readr::read_csv(infile, locale = sjis, col_select = seq(1, 7)) |>
  dplyr::slice(-1)
dfR = readr::read_csv(infile, locale = sjis, col_select = -seq(1, 7),
  skip = 1L, na = c("-", "X"))
raw_miyagi = dplyr::bind_cols(dfL, dfR) |> print()
```

<!-- dfR = readr::read_csv(infile, locale = sjis, col_select = -seq(1, 7),
  skip = 1L, na = c("-", "X"), name_repair = "minimal") -->

---
## Then, tidy it with dplyr and tidyr

Still many traps: leading/trailing whitespace, full-width numbers, etc.

```{r, estat-tidy}
tidy_miyagi = raw_miyagi |>
  dplyr::rename_with(stringr::str_trim) |>
  dplyr::filter(HYOSYO == 1) |>
  dplyr::select(CITYNAME, matches("[ç”·å¥³].+æ­³")) |>
  tidyr::pivot_longer(!CITYNAME, names_to = "category", values_to = "count") |>
  tidyr::separate(category, c("sex", "age"), 1) |>
  dplyr::mutate(age = stringi::stri_trans_nfkc(age)) |>
  tidyr::separate(age, c("lower", "upper"), "ã€œ", fill = "right") |>
  dplyr::mutate(lower = readr::parse_number(lower),
                upper = readr::parse_number(upper)) |>
  dplyr::filter((upper - lower) < 5 | lower == 75) |>
  dplyr::mutate(age = (lower + upper) / 2) |>
  print()
```

---
## Plotting is easy once tidy data is ready

```{r, estat-factor}
#| include: false
total_miyagi = tidy_miyagi |>
  dplyr::count(CITYNAME, wt = count, name = "count", sort = TRUE)
tidy_miyagi = tidy_miyagi |>
  dplyr::mutate(CITYNAME = factor(CITYNAME, levels = total_miyagi$CITYNAME))
```

```{r, estat-plot}
#| fig.height: 5.5
#| fig.width: 12
tidy_miyagi |>
  dplyr::mutate(count = ifelse(sex == "ç”·", -1, 1) * count) |>
  ggplot() +
  geom_col(aes(age, count, fill = sex)) +
  facet_wrap(vars(CITYNAME), nrow = 4L) +
  coord_flip() + theme_minimal(base_size = 15)
```

---
## Datasets in the wild require prep for prep

Now we have great skills for data preparation with R âœ¨<br>
Not scared of messy data!

that being said,

- Data files must be readable at least.
- The more irregularity, the more workload.

What should we care about when we are the primary data source?

<br>

ç·å‹™çœãŒ2020å¹´ã«ç™ºè¡¨ã—ã¦ã€Œå…¨å›½æ°‘ãŒè¦‹ã‚‹ã¹ãã€ã¨è©±é¡Œã«ãªã£ãŸ<br>
[ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€](https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html)
ã‹ã‚‰æŠœç²‹ã€‚

---
## Rule 1. One value in one cell

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-2-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`tidyr::separate()`, `stringr::str_split()`, `stringr::str_extract()`

---
## Rule 1. One value in one cell

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-2-2.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`tidyr::separate()`, `stringr::str_split()`, `stringr::str_extract()`

---
## Rule 2. Leave numbers purely numeric

No unit, no comma, no space should be included in a cell.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-3-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`readr::parse_number()`, `stringr::str_remove()`, `stringr::str_replace()`

---
## Rule 2. Leave numbers purely numeric

No unit, no comma, no space should be included in a cell.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-3-2.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`readr::parse_number()`, `stringr::str_remove()`, `stringr::str_replace()`

---
## Rule 2. Leave numbers purely numeric

No footnote should be included in a table.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-3-3.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`readr::parse_number()`, `stringr::str_remove()`, `stringr::str_replace()`

---
## Rule 3. Don't align/justify text with space characters

`"A"`, `"ã€€A"`, and `"  A"` are different for machines.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-5-2.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`stringr::str_trim()`, `stringr::str_remove()`, `stringr::str_replace()`

---
## Rule 3. Don't align/justify text with space characters

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-5-3.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`stringr::str_trim()`, `stringr::str_remove()`, `stringr::str_replace()`

---
## Rule 4. Never merge cells, ever

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-4-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`tidyr::fill()`

---
## Rule 4. Never merge cells, ever

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-4-2.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`tidyr::fill()`

---
## Rule 5. Don't omit repeated words

They are not recognized automatically.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-6-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`tidyr::fill()`, `tidyr::separate()`, `stringr::str_replace()`

---
## Rule 6. Avoid platform-dependent characters

Stick to only ASCII characters whenever possible.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-10-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`stringi::stri_trans_nfkc()`

---
## Rule 7. One table in one sheet

For that matter, one sheet in one file.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-2-2-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

---
## Rule 8. Miscellaneous

- First row is column names (or first record).
  - No meaning less blank lines.
  - No nameless columns.
  - Columns names should be valid object names in a program.
    - contains only normal word characters `\w+`.
    - **not starts with numbers**.
- Save as plain text, not Excel (`.xlsx`).
    - Tab-separated values (`.tsv`) or Comma- (`.csv`)
    - Files and directories should be named systematically too.

See
[ç†Šè°·ç›´å–œã•ã‚“ã®ãƒ–ãƒ­ã‚°ã€ŒRè§£æç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã€](http://nhkuma.blogspot.com/2012/12/r_5.html)

---
## Data input rules

1. One value in one cell.
1. Leave numbers purely numeric.
1. Don't align/justify text with space characters.
1. Never merge cells, ever.
1. Don't omit repeated words.
1. Avoid platform-dependent characters.
1. One table in one sheet.
1. First row is column names.

In other words, think about the future you analyze it.


---
## Be aware of Excel's kindness/betrayal

è¡¨å½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–²è¦§ãƒ»ä½œæˆã™ã‚‹ã‚½ãƒ•ãƒˆã¨ã—ã¦ã‚ˆãæ™®åŠã€‚<br>
ã—ã‹ã—**è¦ªåˆ‡è¨­è¨ˆãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç‰™ã‚’å‰¥ã**ï¼

- Some strings are converted to dates: `22-4`, `4-14`
- Some gene names are converted to date: `MARCH1`, `SEPT1`<br>
  ([Scientists renamed them because of this.](https://www.theverge.com/2020/8/6/21355674/human-genes-rename-microsoft-excel-misreading-dates))

ğŸ”° Experience the fear:

```
gene,label
MARCH1,22-4
SEPT1,4-14
```
1.  Copy-and-paste the text above to a plaintext named `excel.csv`.
1.  Open it with Excel, and check the content.
1.  Save it as another CSV, `excel2.csv`.
1.  Open it as plaintext, and check the content.

---
## ä»Šå›ã®ãŠå“æ›¸ã

âœ… Data input
- Difficulty in reading data in the wild
- What you should care about when you are the data source.

â¬œ ãƒ‡ãƒ¼ã‚¿è§£é‡ˆã®å¿ƒå¾— (ç†è«–ã‚„æ‰‹æ³•ã®è©³ç´°ã«ã¯è§¦ã‚Œãªã„)
- èª¤å·® (ãƒã‚¤ã‚¢ã‚¹ã€ã°ã‚‰ã¤ã)
- çµ±è¨ˆçš„ä»®èª¬æ¤œå®š
- å› æœé–¢ä¿‚ã¨ç›¸é–¢é–¢ä¿‚



---
## Garbage in, garbage out

no matter how fantastic your statistical analysis is.

<figure>
<img src="../tohoku2022r/image/garbage-in-garbage-out.drawio.svg" width="1200">
</figure>

- ç›®çš„ã«å¿œã˜ã¦ã¡ã‚ƒã‚“ã¨ãƒ‡ãƒ¼ã‚¿ã‚’æ¡ã‚‹ã“ã¨ãŒé‡è¦ï¼
- ä½•ãŒãƒ‡ãƒ¼ã‚¿ã‚’æ‚ªãã—ã¦ã—ã¾ã†ã®ã‹ã€è¦‹ã¦ã„ã“ã†


---
## Observation/sampling involves distortion inevitably

Whole population and phenomena themselves cannot be observed.
: Only their subsets are sampled.
: Only measurable aspects are measured.

<figure>
<img src="../tohoku2022r/image/math-model-biased.drawio.svg" width="1080"><br>
<figcaption><cite>ã€Œãƒ‡ãƒ¼ã‚¿åˆ†æã®ãŸã‚ã®æ•°ç†ãƒ¢ãƒ‡ãƒ«å…¥é–€ã€æ±Ÿå´è²´è£• 2020 ã‚ˆã‚Šæ”¹å¤‰</cite></figcaption>
</figure>


---
## Two types of errors

Systematic errors / bias
: consistent differences between the observed and true values.

Random errors
: inconsistent and unpredictable differences between observations.

e.g., Weigh yourself 10 times with your clothes on.

<figure>
<img src="../tohoku2022r/image/error-random-systematic.drawio.svg" width="640"><br>
<figcaption><cite>ã€Œåˆ†æè€…ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿è§£é‡ˆå­¦å…¥é–€ã€æ±Ÿå´è²´è£• 2020 ã‚ˆã‚Šæ”¹å¤‰</cite></figcaption>
</figure>


---
## Selection bias

<figure style="position: absolute; top: 40px; right: 40px;"><a href="https://en.wikipedia.org/wiki/Survivorship_bias">
<img src="/slides/image/free/Survivorship-bias.svg" width="400"><br>
<figcaption class="url">https://en.wikipedia.org/wiki/Survivorship_bias</figcaption>
</a></figure>

ãƒ‡ãƒ¼ã‚¿ã®æ¡ã‚Œã‹ãŸãŒçµæœã«å‚¾å‘ã‚’ã‚‚ãŸã‚‰ã—ã¦ã—ã¾ã†ã€‚

Survivorship bias
: ç”Ÿãæ®‹ã£ãŸã‚‚ã®ã ã‘ãŒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦è¦³æ¸¬ã•ã‚Œã‚‹ã€‚
: e.g., Damage distribution of surviving aircraft âœˆï¸âœˆï¸<br>
  being shot â†’ **<span style="color: #bb0000;">survived â†’ observed</span>**<br>
  being shot â†’ **crashed â†’ not observed**<br>
  æå‚·ãŒè¦³å¯Ÿã•ã‚Œãªã‹ã£ãŸå ´æ‰€ã‚’ã‚€ã—ã‚è£œå¼·ã™ã¹ãã€‚

Sampling bias
: ã‚µãƒ³ãƒ—ãƒ«å¯¾è±¡ã‚’æ±ºã‚ãŸæ™‚ç‚¹ã§åã£ã¦ã„ã‚‹ã€‚
: ğŸ“é›»è©±ã§ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆèª¿æŸ» â†’
  é›»è©±æ©Ÿã‚’æŒã¦ã‚‹è£•ç¦ãªäººã€ãã®æ™‚é–“ã«é€šè©±ã§ãã‚‹äººã€
  çŸ¥ã‚‰ãªã„ç•ªå·ã‹ã‚‰ã§ã‚‚å‡ºã‚‹äººã€èª¿æŸ»ã—ã¦ã„ã‚‹æ–°èç¤¾ã«å…±æ„Ÿã—ã¦ã„ã‚‹äººã€‚

ğŸ”° ç”Ÿç‰©å­¦ç ”ç©¶ã«ãŠã‘ã‚‹é¸æŠãƒã‚¤ã‚¢ã‚¹ã«ã¯ã©ã†ã„ã†ã‚‚ã®ãŒã‚ã‚Šãã†ï¼Ÿ

---
## æ¸¬å®šåŸºæº–ã«é–¢ã™ã‚‹ãƒã‚¤ã‚¢ã‚¹ã®ä¾‹

åŸºæº–ãŒæƒã£ã¦ã„ãªã„
: å›½æ°‘1äººã‚ãŸã‚Šã®å¼è­·å£«æ•°ã‚’å›½éš›æ¯”è¼ƒã™ã‚‹ã¨æ—¥æœ¬ãŒå°‘ãªã„ã€‚<br>
  è«¸å¤–å›½ã§ã¯ç¨ç†å£«ã‚„å¸æ³•æ›¸å£«ã‚’å¼è­·å£«ã«å«ã‚ã¦é›†è¨ˆã—ã¦ã„ã‚‹ã€‚

åŸºæº–ãŒæ™‚é–“ã¨ã¨ã‚‚ã«å¤‰åŒ–
: è‡ªé–‰ç—‡ã¨è¨ºæ–­ã•ã‚ŒãŸå…ç«¥ã®æ•°ã¯**è¦‹ã‹ã‘ä¸Š**å¹´ã€…å¢—ãˆã¦ã„ã‚‹ã€‚<br>
  è¨ºæ–­åŸºæº–ã®å¤‰æ›´ã€ç—…æ°—ã®çŸ¥ååº¦å‘ä¸ŠãŒä¸»ãªåŸå› ã€‚<br>
  (è¦ªã®é«˜é½¢åŒ–ã®å¯„ä¸ã‚’ç¤ºå”†ã™ã‚‹ç ”ç©¶ã‚‚ã‚ã‚‹ã‚‰ã—ã„)

---
## ãƒ‡ãƒ¼ã‚¿ã®æ‰±ã„ã«èµ·å› ã™ã‚‹ãƒã‚¤ã‚¢ã‚¹

Cherry picking ğŸ’
: to collect information that confirm/support a hypothesis<br>
  while ignoring the others that contradict it.

Confirmation bias
: innate and unconscious tendency to cherry-pick.

Each card has a number on one side and an alphabet on the other.<br>
"If a card has an even number, then it has A on the other side."<br>
To test this statement, which cards should be turned over?

```{r, four-cards}
#| echo: false
#| fig.width: 6
#| fig.height: 2
n = 20
g = (1 + sqrt(5)) / 2
card = tibble::tibble(x = c(0, 1, 1, 0), y = c(0, 0, g, g))
dplyr::bind_rows(
  card |> dplyr::mutate(id = 0),
  card |> dplyr::mutate(id = 1, x = x + 1.1),
  card |> dplyr::mutate(id = 2, x = x + 2.2),
  card |> dplyr::mutate(id = 3, x = x + 3.3)
) |>
  ggplot() + aes(x, y) +
  geom_polygon(aes(group = id), fill = NA, color = "#333333") +
  scale_fill_identity() +
  annotate("text", x = c(0.5, 1.6, 2.7, 3.8), y = g / 2, label = c("1", "2", "A", "B"), size = 20) +
  coord_fixed() +
  theme_void()
```

???
è«–ç†å­¦çš„ãªæ­£è§£ã¯2, Bã€‚



---
## Tendency to perceive patterns in random information

*Post hoc* (*ergo propter hoc*) fallacy
: *A* occurred, then *B* occurred; therefore *A* caused *B*.

Gambler's fallacy
: Tossed *N* heads in a row; the next is likely to come up tails.

```{r, random-pattern}
#| echo: false
#| fig.width: 4
#| fig.height: 4
set.seed(19937)
n = 20
tibble::tibble(x = runif(n), y = runif(n)) |>
  ggplot() + aes(x, y) +
  geom_point(shape = 16, size = 3, alpha = 0.66) +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1), expand = FALSE) +
  theme_minimal()
```

---
## Cognitive bias related to data interpretation

Availability heuristic
: æ€ã„æµ®ã‹ã³ã‚„ã™ã„ã‚‚ã®ã»ã©éå¤§è©•ä¾¡ã—ãŒã¡
: e.g., 1æ–‡å­—ç›®ãŒkã®å˜èªã€3æ–‡å­—ç›®ãŒkã®å˜èªã€å¤šã„ã®ã¯ã©ã£ã¡ï¼Ÿ

Representativeness heuristic
: ã‚¹ãƒ†ãƒ¬ã‚ªã‚¿ã‚¤ãƒ—ã‚’éå¤§è©•ä¾¡ã—ãŒã¡
: e.g., ãƒªãƒ³ãƒ€ã¯31æ­³ã®ç‹¬èº«å¥³æ€§ã€‚ç‡ç›´ã§è¡æ˜ã€‚å¤§å­¦ã§ã¯å“²å­¦å°‚æ”»ã€‚
  äººç¨®å·®åˆ¥ã‚„ç¤¾ä¼šæ­£ç¾©ãªã©ã«æ·±ãé–¢å¿ƒã‚’æŒã¡ã€å­¦ç”Ÿæ™‚ä»£ã«ã¯åæ ¸ãƒ‡ãƒ¢ã«ã‚‚å‚åŠ ã€‚<br>
  ç¾åœ¨ã®ãƒªãƒ³ãƒ€ã¯æ¬¡ã®ã©ã¡ã‚‰ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã‹ï¼Ÿ
  1. ãƒªãƒ³ãƒ€ã¯éŠ€è¡Œå“¡ã¨ã—ã¦åƒã„ã¦ã„ã‚‹ã€‚
  1. ãƒªãƒ³ãƒ€ã¯éŠ€è¡Œå“¡ã¨ã—ã¦åƒããªãŒã‚‰ã€ãƒ•ã‚§ãƒŸãƒ‹ã‚¹ãƒˆé‹å‹•ã«å‚åŠ ã—ã¦ã„ã‚‹ã€‚

èªçŸ¥ãƒã‚¤ã‚¢ã‚¹ãƒ»èª¤è¬¬ã¯ã»ã‹ã«ã‚‚ã„ã‚ã„ã‚ã‚ã‚‹ã€‚<br>
ãƒ‡ãƒ¼ã‚¿è§£æã¨ã¯é–¢ä¿‚ãªãã€çŸ¥ã£ã¦ãŠãã®ã¯æ‚ªããªã„ã€‚

???

https://lambtani.hatenablog.jp/entry/2017/05/18/032108



---
## å¶ç„¶èª¤å·®ã«ã‚ˆã‚‹ã°ã‚‰ã¤ãæ–¹ = Probability distribution

We will learn it [next time](7-distribution.html).

èƒŒå¾Œã«ã‚ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ã‚ˆã£ã¦ã„ã‚ã‚“ãªå½¢ã«ãªã‚‹ã€‚

<iframe width="600" height="450" src="./7-distribution.html#/33"></iframe>


---
## Central tendency of a distribution

<div class="column-container">
  <div class="column" style="flex-shrink: 1.6;">

mean
: sum divided by count

median
: 50th percentile

mode
: the most frequent value

  </div>
  <div class="column">
  <a href="https://www.mhlw.go.jp/toukei/list/20-21.html">
  <img src="../tohoku2022r/image/hist-income-japan-2019.png" width="100%" style="">
  <figcaption><cite>æ‰€å¾—é‡‘é¡éšç´šåˆ¥ä¸–å¸¯æ•°ã®é »åº¦åˆ†å¸ƒ åšç”ŸåŠ´åƒçœ å›½æ°‘ç”Ÿæ´»åŸºç¤èª¿æŸ» 2019</cite></figcaption>
  </a>
  </div>
</div>

ç›®çš„ã‚„çŠ¶æ³ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘ã‚ˆã†ã€‚

å¤–ã‚Œå€¤ã«å¯¾ã™ã‚‹å¿œç­”
: ã‚‚ã—ç·è³‡ç”£é¡20å…†å††ã®å¤§å¯Œè±ªãŒé³¥å–çœŒã«å¼•ã£è¶Šã—ã¦ããŸã‚‰<br>
  â†’ çœŒæ°‘ã®**å¹³å‡**è³‡ç”£ã¯4000ä¸‡å††ä¸Šæ˜‡ã€‚**ä¸­å¤®å€¤**ãƒ»**æœ€é »å€¤**ã¯ã»ã¼ãã®ã¾ã¾ã€‚

---
## Summary statistics to describe variability/dispersion

Variance
: mean squared deviations from the average: $\frac 1 n \sum _i ^n (X_i - \bar X)^2$
: Its square root is **standard deviation**.

Percentile, Quantile
: What percentage of values are smaller than this?
: median = 50th percentile = second quantile (Q2)

```{r, quantile}
#| fig.width: 10
#| fig.height: 4
#| echo: false
set.seed(24601)
df = tibble::tibble(x = rnorm(200)) |>
  dplyr::filter(abs(x) < 2) |>
  dplyr::mutate(x = x + 3)
probs = c(min = 0, Q1 = 0.25, Q2 = 0.5, Q3 = 0.75, max = 1)
dfq = df |>
  dplyr::reframe(x = quantile(x, probs)) |>
  dplyr::mutate(name = names(probs), percent = sprintf("%d%%", 100 * probs))

p_hist = ggplot(df) + aes(x) +
  geom_histogram(bins = 30) +
  theme_void()
built = ggplot_build(p_hist)
bdata = built$data[[1]]
xlim = bdata |> dplyr::select(xmin, xmax) |> range()
p_box = ggplot(df) + aes(x) +
  geom_boxplot() +
  geom_rug(sides = "t", length = unit(0.06, "npc"), alpha = 0.66) +
  geom_point(data = dfq, aes(y = -0.6), shape = 17, size = 4) +
  geom_text(data = dfq, aes(y = -0.75, label = name), size = 5) +
  geom_text(data = dfq, aes(y = -0.95, label = percent), size = 5) +
  coord_cartesian(xlim = xlim, ylim = c(-1.2, 0.5)) +
  theme_void()
cowplot::plot_grid(p_hist, p_box, ncol = 1L)
```



---
## Many ways to visualize 1D data distribution

Impression and information amount vary by graph.

```{r, visualize-distribution}
#| echo: false
#| fig.width: 9
#| fig.height: 6
df = mpg |> dplyr::mutate(y = hwy)
df_mean = df |> dplyr::summarize(y = mean(y))
p0 = ggplot(df) + aes(y = y) +
  theme_classic() +
  theme(axis.title = element_blank(), axis.text.x = element_blank(), axis.ticks = element_blank())

ylim = c(0, max(df$y))
coord_y = coord_cartesian(ylim = ylim)
coord_one = coord_cartesian(ylim = ylim, xlim = c(-1, 1))

pcol = p0 + aes(x = 0) +
  geom_col(data = df_mean, fill = "#999999") +
  stat_summary(fun.data = wtl::mean_sd, geom = "linerange")

set.seed(1)
cowplot::plot_grid(nrow = 2L,
  pcol + coord_one,
  p0 + geom_boxplot() + coord_one,
  p0 + geom_density(fill = "#999999", color = NA) + coord_y,
  p0 + geom_histogram(fill = "#999999", bins = 30L) + coord_y,
  p0 + geom_jitter(aes(x = 0), height = 0, shape = 16, alpha = 0.3, stroke = 0) + coord_one,
  p0 + geom_violin(aes(x = 0), fill = "#999999", color = NA) + coord_one,
  p0 + geom_dotplot(aes(x = 0), binaxis = "y", binwidth = 1, stackratio = 0.8,
    stroke = 0, alpha = 0.66, stackdir = "center") + coord_y,
  p0 + geom_dotplot(aes(x = 0), binaxis = "y", binwidth = 1, stackratio = 0.8,
    stroke = 0, alpha = 0.66) + coord_y
)
```


---
## Comparing two variables: is *A* smaller than *B*?

considering dispersion as well as central tendency.

<div class="column-container" style="padding-left: 10px;">
<div class="column" style="flex-shrink: 1.1;">
Only 1 obs.<br>
Cannot conclude.
</div>
<div class="column" style="flex-shrink: 1;">
Large dispersion.<br>
<em>A</em> tend to be smaller...?
</div>
<div class="column" style="flex-shrink: 1;">
Small dispersion.<br>
Sure <em>A</em> is smaller.
</div>
</div>

```{r, comparison}
#| fig.width: 11
#| fig.height: 4
#| echo: false
set.seed(19937)
n = 20
df1 = tibble::tibble(x = c("A", "B"), y = c(42, 51))
df2 = dplyr::bind_rows(
  tibble::tibble(x = "A", y = runif(n, 42 - 20, 42 + 20)),
  tibble::tibble(x = "B", y = runif(n, 51 - 20, 51 + 20)))
df3 = dplyr::bind_rows(
  tibble::tibble(x = "A", y = rnorm(n, 42, 1)),
  tibble::tibble(x = "B", y = rnorm(n, 51, 1)))
.lim = c(0, max(df2$y, df3$y))
.th = list(coord_cartesian(ylim = .lim),
  theme_classic(base_size = 20),
  theme(legend.position = "none", axis.title = element_blank()))

p1 = ggplot(df1) + aes(x, y, color = x) +
  geom_point(shape = 16, size = 5) +
  .th
p2 = ggplot(df2) + aes(x, y, color = x) +
  geom_jitter(height = 0, width = 0.2, shape = 16, size = 4, alpha = 0.66) +
  .th
cowplot::plot_grid(p1, p2, p2 %+% df3, nrow = 1)
```

"The probability to observe this difference by chance is very low."<br>
A method to show this is called **statistical hypothesis testing**.


---
## Statistical hypothesis testing

ğŸ² Out of **10 rolls** of a dice, 6 appeared **9 times**. Is this dice unfair?

Null hypothesis, $H_0$
: The probability that 6 comes up = 1/6. The dice is fair.

Alternative hypothesis, $H_1$
: The probability that 6 comes up â‰  1/6. The dice is unfair.

<div>\[\begin{split}
p = \binom {10} {9} \times {\frac 1 6} ^ {9} \times {\frac 5 6} ^ 1 + {\frac 1 6} ^ {10}
  = 8.43 \times 10 ^ {-7}
\end{split}\]</div>

1. Calc the probability *p* to get the observed or more extreme values under $H_0$.
1. Reject $H_0$ if $p < \alpha$, significance level, the probability of type 1 error.<br>
   ($\alpha$ should be set before testing, e.g., to 0.05 or 0.01.)
1. Otherwise accept $H_1$. The probability to roll a 6 is different from 1/6.

```{r, test-dice-hidden}
#| include: false
n = 10
k = 9
p = 1 / 6
pbinom(k - 1, n, p, lower.tail = FALSE)
x = seq(k, n)
stopifnot(all.equal(dbinom(x, n, p), choose(n, x) * p ** x * (1 - p) ** (n - x)))
stopifnot(all.equal(sum(dbinom(x, n, p)), pbinom(k - 1, n, p, lower.tail = FALSE)))
```

---
## Statistical hypothesis testing

ğŸ² Out of **12 rolls** of a dice, 6 appeared **4 times**. Is this dice unfair?

<span style="color: #990000;">Probability to roll 4 or more sixes out of 12 under $H_0$: $p = 0.125 > \alpha$</span><br>

Failed to reject $H_0$ this time.<br>
The probability to roll a 6 is **not significantly different** from 1/6.

```{r, test-dice}
#| echo: false
#| fig.height: 4
#| fig.width: 6
X = 4L
n = 12L
tibble::tibble(x = seq.int(0L, n), Probability = dbinom(x, n, 1 / 6)) |>
  dplyr::mutate(color = ifelse(x >= X, "#990000", "#666666")) |>
  ggplot() + aes(x, Probability, fill = color) +
  geom_col() +
  scale_fill_identity() +
  theme_classic(base_size = 20)
# pbinom(X - 1L, n, 1 / 6, lower.tail = FALSE)
# sum(dbinom(seq(X, n), n, 1 / 6))
```

Note: **NOT** accepting $H_0$. **NOT** saying the probability **is equal to** 1/6.


---
## Multiple testing increases the risk of false positive

A test with $\alpha=0.05$ mistakenly rejects true $H_0$ with the probability of â‰¤5%.<br>
By repeating such test 10 times, the probability to get at least one false positive (family-wise error rate, FWER) is up to
$1 - (1 - 0.05)^{10} \approx 0.40$

```{r, multiple-tests}
#| fig.width: 11
#| fig.height: 4.2
#| echo: false
# 1 - (1 - 0.05) ** 10
set.seed(1279)
nsam = 10L
nrep = 20L
y = split(rnorm(nsam * nrep * 2), ceiling(seq_len(nsam * nrep * 2) / nsam))
df = tidyr::crossing(repl = seq_len(nrep), x = c("A", "B")) |>
  dplyr::mutate(y = y) |>
  tidyr::unnest(y)
dfp = df |>
  tidyr::nest(data = !repl) |>
  dplyr::mutate(p = purrr::map_dbl(data, ~ t.test(y ~ x, data = .x)$p.value)) |>
  dplyr::select(!data) |>
  dplyr::mutate(x = 1.5, y = Inf, label = ifelse(p < 0.05, sprintf("p = %.3f", p), ""))
df |>
  ggplot() + aes(x, y) +
  geom_boxplot(aes(fill = x)) +
  geom_text(data = dfp, aes(label = label), hjust = 0.5, vjust = 1.2) +
  facet_wrap(vars(repl), nrow = 2L) +
  theme_bw() +
  theme(legend.position = "none")
```

Multiple testing correction
: making statistical tests more stringent to counteract the problem.
: e.g., Bonferroni, Holm, Benjamini and Hochberg, etc.



<!--  -->


---
## Comparing two variables: correlation and causation

<style>
.spurious {color: #fde725;}
.correlation {color: #35B779;}
.causality-wrong {color: #31688e;}
.causality {color: #440154;}
</style>

<div class="column-container">
<div class="column" style="flex-shrink: 1;">

<span class="correlation">(Linear) Correlation</span>
: degree and direction to which two variables vary together.
: e.g., math scores and physics scores.

<span class="causality">Causation</span>
: ã‚ã‚‹äº‹è±¡ãŒåˆ¥ã®äº‹è±¡ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹ã€‚
: e.g., 1æ™‚é–“å‹‰å¼·ã™ã‚‹ã”ã¨ã«æˆç¸¾ãŒ3ç‚¹ä¼¸ã³ã‚‹ã€‚

</div>
<div class="column" style="flex-shrink: 1.8;">

```{r, causal-relationship}
#| echo: false
#| fig.width: 3.2
#| fig.height: 3.2
set.seed(19937)
n = 40L
tibble::tibble(
  study_time = runif(n, 0, 40),
  score = pmin(rnorm(n, 3 * study_time, 10), 100)) |>
  ggplot() +
  aes(study_time, score) +
  geom_point(shape = 16, alpha = 0.66, size = 3) +
  stat_smooth(method = lm, formula = y ~ x + 0, se = FALSE, color = "#440154", size = 2, alpha = 0.7) +
  theme_classic(base_size = 20) +
  theme(axis.text = element_blank(), axis.ticks = element_blank())
```

</div>
</div>


<hr>

- <span class="causality">Causation</span> often leads to <span class="correlation">correlation</span>.
- <strong><span class="correlation">Correlation</span> does not imply <span class="causality">causation</span></strong> â†’


---
## å› æœãƒ»ç›¸é–¢ã‚’è¦‹èª¤ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³1: confounding factor

**èª¤:** Increasing ğŸ¦icecream sales causes increasing ğŸºbeer sales.

**æ­£:** Both ğŸ¦icecream and ğŸºbeer sell better when it is ğŸŒ **hot**.

<div class="column-container">
  <div class="column" style="flex-shrink: 1.2;">

```{r, confounding-factor}
#| echo: false
#| fig.width: 4
#| fig.height: 4
set.seed(19937)
n = 40L
tibble::tibble(
  temperature = runif(n, 0, 40),
  beer_sales = rpois(n, temperature * 1.3),
  icecream_sales = rpois(n, temperature)) |>
  ggplot() +
  aes(icecream_sales, beer_sales) +
  geom_point(shape = 16, alpha = 0.66, size = 3) +
  stat_smooth(method = lm, formula = y ~ x, se = FALSE, color = "#358779", size = 2, alpha = 0.7) +
  theme_classic(base_size = 20) +
  theme(axis.text = element_blank(), axis.ticks = element_blank())
```

</div>
<div class="column" style="flex-shrink: 1;">

<figure>
<img src="../tohoku2022r/image/hermeneutics-4-1-3.drawio.svg" width="750">
</figure>

</div>
</div>


---
## å› æœãƒ»ç›¸é–¢ã‚’è¦‹èª¤ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³2: reverse causation

**èª¤:** <span class="causality-wrong">Increasing police officer causes increase in crimes.</span>

**æ­£:** <span class="causality">The more crime leads to more police deployment.</span>

<br>

## å› æœãƒ»ç›¸é–¢ã‚’è¦‹èª¤ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³3: selection bias

Collecting (x + y) pairs that fall within a specific range.

```{r, spurious-correlation-selection-bias}
#| echo: false
#| fig.width: 4
#| fig.height: 4
set.seed(19937)
n = 256
tibble::tibble(x = runif(n), y = runif(n)) |>
  dplyr::mutate(sampled = abs(x + y - 1) < 0.2) |>
  dplyr::mutate(color = ifelse(sampled, "#fde725", "#aaaaaa")) |>
  ggplot() +
  aes(x, y) +
  geom_point(aes(color = color), shape = 16, size = 3, alpha = 1) +
  scale_color_identity() +
  coord_fixed() +
  theme_classic(base_size = 20) +
  theme(axis.text = element_blank(), axis.ticks = element_blank())
```


---
## å› æœãƒ»ç›¸é–¢ã‚’è¦‹èª¤ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³4: Outliers, group structures

Correlation coefficient can jump by **a few outliers** and **group structures**.

```{r, correlation-lies}
#| echo: false
#| fig.width: 11
#| fig.height: 3.6
set.seed(19937)
n = 32
df = tibble::tibble(x = rnorm(n), y = rnorm(n))
df_outlier = df |> dplyr::bind_rows(data.frame(x = 10, y = 10))
df_subgroups = df |> dplyr::bind_rows(df + 8)
.lim = range(df_outlier, df_subgroups)

.make_label_cor = function(df) {
  r = cor(df[["x"]], df[["y"]])
  sprintf("r = %.2f", r)
}
# .make_label_cor(df_usbb)

.plot_cor = function(df) {
  ggplot(df) + aes(x, y) +
    geom_point(shape = 16, size = 3, alpha = 0.66) +
    stat_smooth(method = lm, formula = y ~ x, se = FALSE, size = 3, color = "#fde725") +
    annotate("text", x = -Inf, y = Inf, hjust = -0.1, vjust = 2, size = 8, label = .make_label_cor(df)) +
    coord_fixed(xlim = .lim, ylim = .lim) +
    theme_classic(base_size = 20) +
    theme(axis.text = element_blank(), axis.ticks = element_blank())
}

cowplot::plot_grid(
  .plot_cor(df),
  .plot_cor(df_outlier),
  .plot_cor(df_subgroups),
  nrow = 1L
)
```


---
## å› æœãƒ»ç›¸é–¢ã‚’è¦‹èª¤ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³5: by chance

Number of drowned people and the films in which Nicolas Cage appeared.

<figure>
<img src="../tohoku2022r/image/nicholas-cage-drowned.svg" width="1200">
<figcaption><cite>
<a href="https://www.tylervigen.com/spurious-correlations">https://www.tylervigen.com/spurious-correlations</a>
</cite></figcaption>
</figure>


---
## å¤‰æ•°é–“ã®é–¢ä¿‚æ€§ã¾ã¨ã‚

<figure>
<img src="../tohoku2022r/image/hermeneutics-4-1-5.drawio.svg" width="1200">
<figcaption><cite>
<a href="https://amzn.to/3uznzCK">ã€Œåˆ†æè€…ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿è§£é‡ˆå­¦å…¥é–€ã€æ±Ÿå´è²´è£• 2020</a>ã‚ˆã‚Šæ”¹å¤‰
</cite></figcaption>
</figure>

<hr>

- **<span class="correlation">ç›¸é–¢é–¢ä¿‚</span>ãŒã‚ã‚‹ã‹ã‚‰ã¨ã„ã£ã¦<span class="causality">å› æœé–¢ä¿‚</span>ã‚‚ã‚ã‚‹ã¨ã¯é™ã‚‰ãªã„**ã€‚
- <span class="causality-wrong">é€†ã®å› æœé–¢ä¿‚</span>ã‚„<span class="spurious">è¦‹ã›ã‹ã‘ã®ç›¸é–¢</span>ã«ã‚‚è¦æ³¨æ„ã€‚

ğŸ”° ã“ã‚Œã‚‰4ã¤ã®é–¢ä¿‚æ€§ã«è©²å½“ã™ã‚‹äº‹ä¾‹ã‚’ãã‚Œãã‚Œ1ã¤ä»¥ä¸Šæ¢ã—ã¦ã¿ã‚ˆã†ã€‚

???
16--17ä¸–ç´€ã€æ€ªæˆ‘ã‚’ã—ãŸã‚‰æ­¦å™¨ã«è»Ÿè†ã‚’å¡—ã‚‹ã¨æ—©ãæ²»ã‚‹ã¨ã„ã†è¿·ä¿¡ã€‚
è³ªã®ä½ã„è»Ÿè†ã‚’å‚·å£ã«å¡—ã‚‰ãªã„ã“ã¨ãŒãƒ—ãƒ©ã‚¹ã«åƒã„ãŸã¨ã„ã†ã®ãŒçœŸç›¸ã€‚


---
## å‚è€ƒæ–‡çŒ®

- ã€Œ[Rã‚’ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿è§£æã®åŸºç¤ã¨å¿œç”¨](https://comicalcommet.github.io/r-training-2023/)ã€
   çŸ³å·ç”±å¸Œ 2023 åå¤å±‹å¤§å­¦
- [ãƒ‡ãƒ¼ã‚¿è§£æã®ãŸã‚ã®çµ±è¨ˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°å…¥é–€](https://amzn.to/33suMIZ) ä¹…ä¿æ‹“å¼¥ 2012
- [åˆ†æè€…ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿è§£é‡ˆå­¦å…¥é–€](https://amzn.to/3uznzCK) æ±Ÿå´è²´è£• 2020
- [ãƒ‡ãƒ¼ã‚¿åˆ†æã®ãŸã‚ã®æ•°ç†ãƒ¢ãƒ‡ãƒ«å…¥é–€](https://amzn.to/3uCxTKo) æ±Ÿå´è²´è£• 2020
- [çµ±è¨ˆå­¦ã‚’å“²å­¦ã™ã‚‹](https://amzn.to/3ty80Kv) å¤§å¡šæ·³ 2020
- [çµ±è¨ˆæ€è€ƒã®ä¸–ç•Œ](https://amzn.to/3urpls1) ä¸‰ä¸­ä¿¡å® 2018
- Quarto / R Markdown
  - [R for Data Science --- Quarto](https://r4ds.hadley.nz/quarto)
  - [R Markdown: The Definitive Guide](https://bookdown.org/yihui/rmarkdown/)

`r .meta$next_link`
