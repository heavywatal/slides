```{r, setup-common}
#| file: "setup.R"
#| echo: false
#| results: "asis"
```
```{r, setup-local}
#| include: false
#| cache: false
```

---
## Outline of data analysis

1. Setup computer environment âœ…
1. Get and read input data â¬œ day 6 ğŸ‘ˆ
1. Exploratory data analysis
    - **Preparation** (harder than it seems) âœ… day 3--5
    - **Visualization**, generating hypotheses (fun!) âœ… day 2
    - **Statistical analysis**, testing hypotheses â¬œ day 7--8
1. Report âœ… day 2

<figure>
<a href="https://r4ds.hadley.nz/intro">
<img src="/slides/image/r4ds/data-science.png" width="720">
<figcaption class="url">https://r4ds.hadley.nz/intro</figcaption>
</a>
</figure>


---
## Read/write data.frame

<a href="https://readr.tidyverse.org/">
<img src="/_img/hex-stickers/readr.webp" width="180" align="right">
</a>

- `readxl` package helps reading `.xlsx`, but...
- Prefer CSV (Comma-separated values) and TSV (Tab-).
- Use `readr` package instead of base R functions.
- Specify a file with the **relative path** from **working directory**.

    ```r
    readr::write_tsv(iris, "data/iris.tsv")
    iris2 = readr::read_tsv("data/iris.tsv")
    ```

Oops, an error occurred:

```{r, cannot-open}
#| error: true
#| echo: false
readr::write_tsv(iris, "data/iris.tsv")
```

---
## Common errors when reading/writing files

- Wrong file names
- Wrong directory
- Have not created the output directory.

See [ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼é›† (çŸ³å·ç”±å¸Œã•ã‚“@åå¤å±‹å¤§)](https://comicalcommet.github.io/r-training-2023/R_training_2023_7.html).

<hr>

Check your current directory and its content:
```r
getwd()                 # GET Working Directory
fs::dir_ls(".")         # List files in "." (here)
fs::dir_ls("data")      # List files in "./data"
fs::dir_create("data")  # Create directory
```

ğŸ”° Write some data.frames to `data/` directory.

ğŸ”° Read them and create objects with different names.

---
## ğŸ”° Reporting assignment for Tohoku Univ. students

<iframe width="1200" height="810" src="./8-glm.html#/50"></iframe>

Read â†’ Prepare â†’ Visualize â†’ a piece of cake ... hopefully?

---
## Demo: [e-Stat national population census](https://www.e-stat.go.jp/gis/statmap-search?page=1&type=1&toukeiCode=00200521) CSV

2020å¹´ â†’ å°åœ°åŸŸ â†’ å¹´é½¢ï¼ˆï¼•æ­³éšç´šã€ï¼”åŒºåˆ†ï¼‰åˆ¥ã€ç”·å¥³åˆ¥äººå£ â†’ å®®åŸçœŒ

Population pyramids as follows can be drawn from this CSV file, but...

<img `r src_alt_fig_chunk("estat-plot")`>

---
## Rare to read public data effortlessly

First trial, an error:
```{r, estat-read-error}
#| error: true
infile = "tblT001082C04.txt"
readr::read_csv(infile)
```

View this file with RStudio as a plain text.
Decoding fails:
```{r, estat-as-text}
#| echo: false
readLines(infile, 5L) |> t() |> t() |>
  prmatrix(rowlab = rep("", 5), collab = "", quote = FALSE)
```

Select "File â†’ **Reopen with Encoding...**".<br>
Modern, decent text files should be encoded in **UTF-8**.<br>
Old Japanese text tend to be encoded in **SHIFT-JIS** (or EUC-JP).

---
## Open a file with a different encoding

Next problem: the second row also has column names:
```{r, estat-sjis}
sjis = readr::locale(encoding = "SHIFT-JIS")
readr::read_csv(infile, locale = sjis)
```

---
## Bind the left and right halves after cleaning each

Numeric columns have non-numeric characters like `-` and `X`:
```{r, estat-lr}
dfL = readr::read_csv(infile, locale = sjis, col_select = seq(1, 7)) |>
  dplyr::slice(-1)
dfR = readr::read_csv(infile, locale = sjis, col_select = -seq(1, 7),
  skip = 1L)
raw_miyagi = dplyr::bind_cols(dfL, dfR) |> print()
```

---
## Read non-empty "missing" values as `NA`

OK, now we got to the starting point...
```{r, estat-lr-na}
dfL = readr::read_csv(infile, locale = sjis, col_select = seq(1, 7)) |>
  dplyr::slice(-1)
dfR = readr::read_csv(infile, locale = sjis, col_select = -seq(1, 7),
  skip = 1L, na = c("-", "X"))
raw_miyagi = dplyr::bind_cols(dfL, dfR) |> print()
```

<!-- dfR = readr::read_csv(infile, locale = sjis, col_select = -seq(1, 7),
  skip = 1L, na = c("-", "X"), name_repair = "minimal") -->

---
## Then, tidy it with dplyr and tidyr

Still many traps: leading/trailing whitespace, full-width numbers, etc.

```{r, estat-tidy}
tidy_miyagi = raw_miyagi |>
  dplyr::rename_with(stringr::str_trim) |>
  dplyr::filter(HYOSYO == 1) |>
  dplyr::select(CITYNAME, matches("[ç”·å¥³].+æ­³")) |>
  tidyr::pivot_longer(!CITYNAME, names_to = "category", values_to = "count") |>
  tidyr::separate(category, c("sex", "age"), 1) |>
  dplyr::mutate(age = stringi::stri_trans_nfkc(age)) |>
  tidyr::separate(age, c("lower", "upper"), "ã€œ", fill = "right") |>
  dplyr::mutate(lower = readr::parse_number(lower),
                upper = readr::parse_number(upper)) |>
  dplyr::filter((upper - lower) < 5 | lower == 75) |>
  dplyr::mutate(age = (lower + upper) / 2) |>
  print()
```

---
## Plotting is easy once tidy data is ready

```{r, estat-factor}
#| include: false
total_miyagi = tidy_miyagi |>
  dplyr::count(CITYNAME, wt = count, name = "count", sort = TRUE)
tidy_miyagi = tidy_miyagi |>
  dplyr::mutate(CITYNAME = factor(CITYNAME, levels = total_miyagi$CITYNAME))
```

```{r, estat-plot}
#| fig.height: 5.5
#| fig.width: 12
tidy_miyagi |>
  dplyr::mutate(count = ifelse(sex == "ç”·", -1, 1) * count) |>
  ggplot() +
  geom_col(aes(age, count, fill = sex)) +
  facet_wrap(vars(CITYNAME), nrow = 4L) +
  coord_flip() + theme_minimal(base_size = 15)
```

---
## Datasets in the wild require prep for prep

Now we have great skills for data preparation with R âœ¨<br>
Not scared of messy data!

that being said,

- Data files must be readable at least.
- The more irregularity, the more workload.

What should we care about when we are the primary data source?

<br>

Ministry of Internal affairs and Communication published a document in 2020.<br>
[ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€](https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html)

---
## Rule 1. One value in one cell

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-2-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`tidyr::separate()`, `stringr::str_split()`, `stringr::str_extract()`

---
## Rule 1. One value in one cell

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-2-2.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`tidyr::separate()`, `stringr::str_split()`, `stringr::str_extract()`

---
## Rule 2. Leave numbers purely numeric

No unit, no comma, no space should be included in a cell.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-3-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`readr::parse_number()`, `stringr::str_remove()`, `stringr::str_replace()`

---
## Rule 2. Leave numbers purely numeric

No unit, no comma, no space should be included in a cell.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-3-2.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`readr::parse_number()`, `stringr::str_remove()`, `stringr::str_replace()`

---
## Rule 2. Leave numbers purely numeric

No footnote should be included in a table.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-3-3.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`readr::parse_number()`, `stringr::str_remove()`, `stringr::str_replace()`

---
## Rule 3. Don't align/justify text with space characters

`"A"`, `"ã€€A"`, and `"  A"` are different for machines.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-5-2.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`stringr::str_trim()`, `stringr::str_remove()`, `stringr::str_replace()`

---
## Rule 3. Don't align/justify text with space characters

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-5-3.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`stringr::str_trim()`, `stringr::str_remove()`, `stringr::str_replace()`

---
## Rule 4. Never merge cells, ever

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-4-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`tidyr::fill()`

---
## Rule 4. Never merge cells, ever

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-4-2.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`tidyr::fill()`

---
## Rule 5. Don't omit repeated words

They are not recognized automatically.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-6-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`tidyr::fill()`, `tidyr::separate()`, `stringr::str_replace()`

---
## Rule 6. Avoid platform-dependent characters

Stick to only ASCII characters whenever possible.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-1-10-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

Useful functions to handle bad forms:
`stringi::stri_trans_nfkc()`

---
## Rule 7. One table in one sheet

For that matter, one sheet in one file.

<figure><a href="https://www.soumu.go.jp/menu_news/s-news/01toukatsu01_02000186.html">
<img src="/slides/image/soumu_go_jp/soumu_data-2-2-1.webp" width = 80%>
<figcaption><cite>ç·å‹™çœ 2020ã€Œçµ±è¨ˆè¡¨ã«ãŠã‘ã‚‹æ©Ÿæ¢°åˆ¤èª­å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã®è¡¨è¨˜æ–¹æ³•ã®çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã€ã‚ˆã‚Š</cite></figcaption>
</a></figure>

---
## Rule 8. Miscellaneous

- First row is column names (or first record).
  - No meaning less blank lines.
  - No nameless columns.
  - Columns names should be valid object names in a program.
    - contains only normal word characters `\w+`.
    - **not starts with numbers**.
- Save as plain text, not Excel (`.xlsx`).
    - Tab-separated values (`.tsv`) or Comma- (`.csv`)
    - Files and directories should be named systematically too.

See
[ç†Šè°·ç›´å–œã•ã‚“ã®ãƒ–ãƒ­ã‚°ã€ŒRè§£æç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹ã€](http://nhkuma.blogspot.com/2012/12/r_5.html)

---
## Data input rules

1. One value in one cell.
1. Leave numbers purely numeric.
1. Don't align/justify text with space characters.
1. Never merge cells, ever.
1. Don't omit repeated words.
1. Avoid platform-dependent characters.
1. One table in one sheet.
1. First row is column names.

In other words, think about the future you analyze it.


---
## Be aware of Excel's kindness/betrayal

Widely used as a software to view and edit table format data.<br>
It has many nice features, but often brings chaos.

- Some strings are converted to dates: `22-4`, `4-14`
- Some gene names are converted to date: `MARCH1`, `SEPT1`<br>
  ([Scientists renamed them because of this.](https://www.theverge.com/2020/8/6/21355674/human-genes-rename-microsoft-excel-misreading-dates))

ğŸ”° Experience the fear:

```
gene,label
MARCH1,22-4
SEPT1,4-14
```
1.  Copy-and-paste the text above to a plaintext named `excel.csv`.
1.  Open it with Excel, and check the content.
1.  Save it as another CSV, `excel2.csv`.
1.  Open it as plaintext, and check the content.

---
## Today's lesson

âœ… Data input
- Difficulty in reading data in the wild
- What you should care about when you are the data source.

â¬œ Data interpretation (very basic introduction)
- Errors (bias and dispersion)
- Statistical hypothesis testing
- Correlation and causation



---
## Garbage in, garbage out

no matter how fantastic your statistical analysis is.

<figure>
<img src="../english2023r/image/garbage-in-garbage-out.drawio.svg" width="1200">
</figure>

What impairs data input?


---
## Observation/sampling involves distortion inevitably

Whole population and phenomena themselves cannot be observed.
: Only their subsets are sampled.
: Only measurable aspects are measured.

<figure>
<img src="../english2023r/image/math-model-biased.drawio.svg" width="1080"><br>
<figcaption><cite>ã€Œãƒ‡ãƒ¼ã‚¿åˆ†æã®ãŸã‚ã®æ•°ç†ãƒ¢ãƒ‡ãƒ«å…¥é–€ã€æ±Ÿå´è²´è£• 2020 ã‚ˆã‚Šæ”¹å¤‰</cite></figcaption>
</figure>


---
## Two types of errors

Systematic errors / bias
: consistent differences between the observed and true values.

Random errors
: inconsistent and unpredictable differences between observations.

e.g., Weigh yourself 10 times with your clothes on.

<figure>
<img src="../english2023r/image/error-random-systematic.drawio.svg" width="640"><br>
<figcaption><cite>ã€Œåˆ†æè€…ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿è§£é‡ˆå­¦å…¥é–€ã€æ±Ÿå´è²´è£• 2020 ã‚ˆã‚Šæ”¹å¤‰</cite></figcaption>
</figure>


---
## Selection bias

<figure style="position: absolute; top: 40px; right: 40px;"><a href="https://en.wikipedia.org/wiki/Survivorship_bias">
<img src="/slides/image/free/Survivorship-bias.svg" width="400"><br>
<figcaption class="url">https://en.wikipedia.org/wiki/Survivorship_bias</figcaption>
</a></figure>

Survivorship bias
: A kind of logical error based on incomplete data.
: e.g., Damage distribution of surviving aircraft âœˆï¸âœˆï¸<br>
  being shot â†’ **<span style="color: #bb0000;">survived â†’ observed</span>**<br>
  being shot â†’ **crashed â†’ not observed**<br>
  Add armor to the {least or most} damaged areas?

Sampling bias
: Targets are already biased, not representing the population.
: ğŸ“ Phone survey by newspaper â†’
  afford phones, has spare time,
  answers an anonymous caller,
  subscribing the newspaper.

ğŸ”° Selection bias in biological research?

---
## Biased data collection + interpretation

Cherry picking ğŸ’
: to collect information that confirm/support a hypothesis<br>
  while ignoring the others that contradict it.

Confirmation bias
: innate and unconscious tendency to cherry-pick.

Each card has a number on one side and an alphabet on the other.<br>
"If a card has an even number, then it has A on the other side."<br>
To test this statement, which cards should be turned over?

```{r, four-cards}
#| echo: false
#| fig.width: 6
#| fig.height: 2
n = 20
g = (1 + sqrt(5)) / 2
card = tibble::tibble(x = c(0, 1, 1, 0), y = c(0, 0, g, g))
dplyr::bind_rows(
  card |> dplyr::mutate(id = 0),
  card |> dplyr::mutate(id = 1, x = x + 1.1),
  card |> dplyr::mutate(id = 2, x = x + 2.2),
  card |> dplyr::mutate(id = 3, x = x + 3.3)
) |>
  ggplot() + aes(x, y) +
  geom_polygon(aes(group = id), fill = NA, color = "#333333") +
  scale_fill_identity() +
  annotate("text", x = c(0.5, 1.6, 2.7, 3.8), y = g / 2, label = c("1", "2", "A", "B"), size = 20) +
  coord_fixed() +
  theme_void()
```

???
è«–ç†å­¦çš„ãªæ­£è§£ã¯2, Bã€‚



---
## Tendency to perceive patterns in random information

*Post hoc* (*ergo propter hoc*) fallacy
: *A* occurred, then *B* occurred; therefore *A* caused *B*.

Gambler's fallacy
: Tossed *N* heads in a row; the next is likely to come up tails.

```{r, random-pattern}
#| echo: false
#| fig.width: 4
#| fig.height: 4
set.seed(19937)
n = 20
tibble::tibble(x = runif(n), y = runif(n)) |>
  ggplot() + aes(x, y) +
  geom_point(shape = 16, size = 3, alpha = 0.66) +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1), expand = FALSE) +
  theme_minimal()
```

---
## Cognitive bias related to data interpretation

Availability heuristic
: overrating an immediate example that came to mind
: e.g., words with leading "k" vs words with "k" at third; which exist more?

Representativeness heuristic
: overrating stereotypes.
: e.g., Linda is a 31 year-old single woman. Honest and smart. Majors in philosophy.
  Interested in racial discrimination and justice. Attended anti-nuclear demonstration as a student.<br>
  Which is more likely as current Linda?
  1. Linda is a bank teller.
  1. Linda is a bank teller and being feminist.

There are many other cognitive bias and errors.<br>

???

https://lambtani.hatenablog.jp/entry/2017/05/18/032108



---
## Variations by random errors â†’ probability distribution

We will learn it [next time](7-distribution.html).

Various shapes depending on underlying mechanisms.

<iframe width="720" height="540" src="./7-distribution.html#/34"></iframe>


---
## Central tendency of a distribution

<div class="column-container">
  <div class="column" style="flex-shrink: 1.6;">

mean
: sum divided by count

median
: 50th percentile

mode
: the most frequent value

  </div>
  <div class="column">
  <a href="https://www.mhlw.go.jp/toukei/list/20-21.html">
  <img src="../tohoku2022r/image/hist-income-japan-2019.png" width="100%" style="">
  <figcaption><cite>æ‰€å¾—é‡‘é¡éšç´šåˆ¥ä¸–å¸¯æ•°ã®é »åº¦åˆ†å¸ƒ åšç”ŸåŠ´åƒçœ å›½æ°‘ç”Ÿæ´»åŸºç¤èª¿æŸ» 2019</cite></figcaption>
  </a>
  </div>
</div>

Responses to outliers
: Suppose a trillionaire with 20 trillion yen assets moved into Tottori pref..<br>
  â†’ **Mean** assets increases by 40M yen while **median** and **mode** remain.

---
## Summary statistics to describe variability/dispersion

Variance
: mean squared deviations from the average: $\frac 1 n \sum _i ^n (X_i - \bar X)^2$
: Its square root is **standard deviation**.

Percentile, Quantile
: What percentage of values are smaller than this?
: median = 50th percentile = second quantile (Q2)

```{r, quantile}
#| fig.width: 10
#| fig.height: 4
#| echo: false
set.seed(24601)
df = tibble::tibble(x = rnorm(200)) |>
  dplyr::filter(abs(x) < 2) |>
  dplyr::mutate(x = x + 3)
probs = c(min = 0, Q1 = 0.25, Q2 = 0.5, Q3 = 0.75, max = 1)
dfq = df |>
  dplyr::reframe(x = quantile(x, probs)) |>
  dplyr::mutate(name = names(probs), percent = sprintf("%d%%", 100 * probs))

p_hist = ggplot(df) + aes(x) +
  geom_histogram(bins = 30) +
  theme_void()
built = ggplot_build(p_hist)
bdata = built$data[[1]]
xlim = bdata |> dplyr::select(xmin, xmax) |> range()
p_box = ggplot(df) + aes(x) +
  geom_boxplot() +
  geom_rug(sides = "t", length = unit(0.06, "npc"), alpha = 0.66) +
  geom_point(data = dfq, aes(y = -0.6), shape = 17, size = 4) +
  geom_text(data = dfq, aes(y = -0.75, label = name), size = 5) +
  geom_text(data = dfq, aes(y = -0.95, label = percent), size = 5) +
  coord_cartesian(xlim = xlim, ylim = c(-1.2, 0.5)) +
  theme_void()
cowplot::plot_grid(p_hist, p_box, ncol = 1L)
```



---
## Many ways to visualize 1D data distribution

Impression and information amount vary by graph.

```{r, visualize-distribution}
#| echo: false
#| fig.width: 9
#| fig.height: 6
df = mpg |> dplyr::mutate(y = hwy)
df_mean = df |> dplyr::summarize(y = mean(y))
p0 = ggplot(df) + aes(y = y) +
  theme_classic() +
  theme(axis.title = element_blank(), axis.text.x = element_blank(), axis.ticks = element_blank())

ylim = c(0, max(df$y))
coord_y = coord_cartesian(ylim = ylim)
coord_one = coord_cartesian(ylim = ylim, xlim = c(-1, 1))

pcol = p0 + aes(x = 0) +
  geom_col(data = df_mean, fill = "#999999") +
  stat_summary(fun.data = wtl::mean_sd, geom = "linerange")

set.seed(1)
cowplot::plot_grid(nrow = 2L,
  pcol + coord_one,
  p0 + geom_boxplot() + coord_one,
  p0 + geom_density(fill = "#999999", color = NA) + coord_y,
  p0 + geom_histogram(fill = "#999999", bins = 30L) + coord_y,
  p0 + geom_jitter(aes(x = 0), height = 0, shape = 16, alpha = 0.3, stroke = 0) + coord_one,
  p0 + geom_violin(aes(x = 0), fill = "#999999", color = NA) + coord_one,
  p0 + geom_dotplot(aes(x = 0), binaxis = "y", binwidth = 1, stackratio = 0.8,
    stroke = 0, alpha = 0.66, stackdir = "center") + coord_y,
  p0 + geom_dotplot(aes(x = 0), binaxis = "y", binwidth = 1, stackratio = 0.8,
    stroke = 0, alpha = 0.66) + coord_y
)
```


---
## Comparing two variables: is *A* smaller than *B*?

considering dispersion as well as central tendency.

<div class="column-container" style="padding-left: 10px;">
<div class="column" style="flex-shrink: 1.1;">
Only 1 obs.<br>
Cannot conclude.
</div>
<div class="column" style="flex-shrink: 1;">
Large dispersion.<br>
<em>A</em> tend to be smaller...?
</div>
<div class="column" style="flex-shrink: 1;">
Small dispersion.<br>
Sure <em>A</em> is smaller.
</div>
</div>

```{r, comparison}
#| fig.width: 11
#| fig.height: 4
#| echo: false
set.seed(19937)
n = 20
df1 = tibble::tibble(x = c("A", "B"), y = c(42, 51))
df2 = dplyr::bind_rows(
  tibble::tibble(x = "A", y = runif(n, 42 - 20, 42 + 20)),
  tibble::tibble(x = "B", y = runif(n, 51 - 20, 51 + 20)))
df3 = dplyr::bind_rows(
  tibble::tibble(x = "A", y = rnorm(n, 42, 1)),
  tibble::tibble(x = "B", y = rnorm(n, 51, 1)))
.lim = c(0, max(df2$y, df3$y))
.th = list(coord_cartesian(ylim = .lim),
  theme_classic(base_size = 20),
  theme(legend.position = "none", axis.title = element_blank()))

p1 = ggplot(df1) + aes(x, y, color = x) +
  geom_point(shape = 16, size = 5) +
  .th
p2 = ggplot(df2) + aes(x, y, color = x) +
  geom_jitter(height = 0, width = 0.2, shape = 16, size = 4, alpha = 0.66) +
  .th
cowplot::plot_grid(p1, p2, p2 %+% df3, nrow = 1)
```

"The probability to observe this difference by chance is very low."<br>
A method to show this is called **statistical hypothesis testing**.


---
## Statistical hypothesis testing

ğŸ² Out of **10 rolls** of a dice, 6 appeared **9 times**. Is this dice unfair?

Null hypothesis, $H_0$
: The probability that 6 comes up = 1/6. The dice is fair.

Alternative hypothesis, $H_1$
: The probability that 6 comes up â‰  1/6. The dice is unfair.

<div>\[\begin{split}
p = \binom {10} {9} \times {\frac 1 6} ^ {9} \times {\frac 5 6} ^ 1 + {\frac 1 6} ^ {10}
  = 8.43 \times 10 ^ {-7}
\end{split}\]</div>

1. Calc the probability *p* to get the observed or more extreme values under $H_0$.
1. Reject $H_0$ if $p < \alpha$, significance level, the probability of type 1 error.<br>
   ($\alpha$ should be set before testing, e.g., to 0.05 or 0.01.)
1. Otherwise accept $H_1$. The probability to roll a 6 is different from 1/6.

```{r, test-dice-hidden}
#| include: false
n = 10
k = 9
p = 1 / 6
pbinom(k - 1, n, p, lower.tail = FALSE)
x = seq(k, n)
stopifnot(all.equal(dbinom(x, n, p), choose(n, x) * p ** x * (1 - p) ** (n - x)))
stopifnot(all.equal(sum(dbinom(x, n, p)), pbinom(k - 1, n, p, lower.tail = FALSE)))
```

---
## Statistical hypothesis testing

ğŸ² Out of **12 rolls** of a dice, 6 appeared **4 times**. Is this dice unfair?

<span style="color: #990000;">Probability to roll 4 or more sixes out of 12 under $H_0$: $p = 0.125 > \alpha$</span><br>

Failed to reject $H_0$ this time.<br>
The probability to roll a 6 is **not significantly different** from 1/6.

```{r, test-dice}
#| echo: false
#| fig.height: 4
#| fig.width: 6
X = 4L
n = 12L
tibble::tibble(x = seq.int(0L, n), Probability = dbinom(x, n, 1 / 6)) |>
  dplyr::mutate(color = ifelse(x >= X, "#990000", "#666666")) |>
  ggplot() + aes(x, Probability, fill = color) +
  geom_col() +
  scale_fill_identity() +
  theme_classic(base_size = 20)
# pbinom(X - 1L, n, 1 / 6, lower.tail = FALSE)
# sum(dbinom(seq(X, n), n, 1 / 6))
```

Note: **NOT** accepting $H_0$. **NOT** saying the probability **is equal to** 1/6.


---
## Multiple testing increases the risk of false positive

A test with $\alpha=0.05$ mistakenly rejects true $H_0$ with the probability of â‰¤5%.<br>
By repeating such test 10 times, the probability to get at least one false positive (family-wise error rate, FWER) is up to
$1 - (1 - 0.05)^{10} \approx 0.40$

```{r, multiple-tests}
#| fig.width: 11
#| fig.height: 4.2
#| echo: false
# 1 - (1 - 0.05) ** 10
set.seed(1279)
nsam = 10L
nrep = 20L
y = split(rnorm(nsam * nrep * 2), ceiling(seq_len(nsam * nrep * 2) / nsam))
df = tidyr::crossing(repl = seq_len(nrep), x = c("A", "B")) |>
  dplyr::mutate(y = y) |>
  tidyr::unnest(y)
dfp = df |>
  tidyr::nest(data = !repl) |>
  dplyr::mutate(p = purrr::map_dbl(data, ~ t.test(y ~ x, data = .x)$p.value)) |>
  dplyr::select(!data) |>
  dplyr::mutate(x = 1.5, y = Inf, label = ifelse(p < 0.05, sprintf("p = %.3f", p), ""))
df |>
  ggplot() + aes(x, y) +
  geom_boxplot(aes(fill = x)) +
  geom_text(data = dfp, aes(label = label), hjust = 0.5, vjust = 1.2) +
  facet_wrap(vars(repl), nrow = 2L) +
  theme_bw() +
  theme(legend.position = "none")
```

Multiple testing correction
: making statistical tests more stringent to counteract the problem.
: e.g., Bonferroni, Holm, Benjamini and Hochberg, etc.



<!--  -->


---
## Comparing two variables: correlation and causation

<style>
.spurious {color: #fde725;}
.correlation {color: #35B779;}
.causality-wrong {color: #31688e;}
.causality {color: #440154;}
</style>

<div class="column-container">
<div class="column" style="flex-shrink: 1;">

<span class="correlation">(Linear) Correlation</span>
: degree and direction to which two variables vary together.
: e.g., math scores and physics scores.

<span class="causality">Causation</span>
: one phenomenon affects another.
: e.g., studying 1 hour longer leads to scoring 3 points more.

</div>
<div class="column" style="flex-shrink: 1.8;">

```{r, causal-relationship}
#| echo: false
#| fig.width: 3.2
#| fig.height: 3.2
set.seed(19937)
n = 40L
tibble::tibble(
  study_time = runif(n, 0, 40),
  score = pmin(rnorm(n, 3 * study_time, 10), 100)) |>
  ggplot() +
  aes(study_time, score) +
  geom_point(shape = 16, alpha = 0.66, size = 3) +
  stat_smooth(method = lm, formula = y ~ x + 0, se = FALSE, color = "#440154", size = 2, alpha = 0.7) +
  theme_classic(base_size = 20) +
  theme(axis.text = element_blank(), axis.ticks = element_blank())
```

</div>
</div>


<hr>

- <span class="causality">Causation</span> often leads to <span class="correlation">correlation</span>.
- <strong><span class="correlation">Correlation</span> does not imply <span class="causality">causation</span></strong> â†’


---
## Misjudgment 1: confounding factor

**èª¤:** Increasing ğŸ¦icecream sales causes increasing ğŸºbeer sales.

**æ­£:** Both ğŸ¦icecream and ğŸºbeer sell better when it is ğŸŒ **hot**.

<div class="column-container">
  <div class="column" style="flex-shrink: 1.2;">

```{r, confounding-factor}
#| echo: false
#| fig.width: 4
#| fig.height: 4
set.seed(19937)
n = 40L
tibble::tibble(
  temperature = runif(n, 0, 40),
  beer_sales = rpois(n, temperature * 1.3),
  icecream_sales = rpois(n, temperature)) |>
  ggplot() +
  aes(icecream_sales, beer_sales) +
  geom_point(shape = 16, alpha = 0.66, size = 3) +
  stat_smooth(method = lm, formula = y ~ x, se = FALSE, color = "#358779", size = 2, alpha = 0.7) +
  theme_classic(base_size = 20) +
  theme(axis.text = element_blank(), axis.ticks = element_blank())
```

</div>
<div class="column" style="flex-shrink: 1;">

<figure>
<img src="../tohoku2022r/image/hermeneutics-4-1-3.drawio.svg" width="750">
</figure>

</div>
</div>


---
## Misjudgment 2: reverse causation

**èª¤:** <span class="causality-wrong">Increasing police officer causes increase in crimes.</span>

**æ­£:** <span class="causality">The more crime leads to more police deployment.</span>

<br>

## Misjudgment 3: selection bias

Collecting (x + y) pairs that fall within a specific range.

```{r, spurious-correlation-selection-bias}
#| echo: false
#| fig.width: 4
#| fig.height: 4
set.seed(19937)
n = 256
tibble::tibble(x = runif(n), y = runif(n)) |>
  dplyr::mutate(sampled = abs(x + y - 1) < 0.2) |>
  dplyr::mutate(color = ifelse(sampled, "#fde725", "#aaaaaa")) |>
  ggplot() +
  aes(x, y) +
  geom_point(aes(color = color), shape = 16, size = 3, alpha = 1) +
  scale_color_identity() +
  coord_fixed() +
  theme_classic(base_size = 20) +
  theme(axis.text = element_blank(), axis.ticks = element_blank())
```


---
## Misjudgment 4: Outliers and group structures

Correlation coefficient can jump by **a few outliers** and **group structures**.

```{r, correlation-lies}
#| echo: false
#| fig.width: 11
#| fig.height: 3.6
set.seed(19937)
n = 32
df = tibble::tibble(x = rnorm(n), y = rnorm(n))
df_outlier = df |> dplyr::bind_rows(data.frame(x = 10, y = 10))
df_subgroups = df |> dplyr::bind_rows(df + 8)
.lim = range(df_outlier, df_subgroups)

.make_label_cor = function(df) {
  r = cor(df[["x"]], df[["y"]])
  sprintf("r = %.2f", r)
}
# .make_label_cor(df_usbb)

.plot_cor = function(df) {
  ggplot(df) + aes(x, y) +
    geom_point(shape = 16, size = 3, alpha = 0.66) +
    stat_smooth(method = lm, formula = y ~ x, se = FALSE, size = 3, color = "#fde725") +
    annotate("text", x = -Inf, y = Inf, hjust = -0.1, vjust = 2, size = 8, label = .make_label_cor(df)) +
    coord_fixed(xlim = .lim, ylim = .lim) +
    theme_classic(base_size = 20) +
    theme(axis.text = element_blank(), axis.ticks = element_blank())
}

cowplot::plot_grid(
  .plot_cor(df),
  .plot_cor(df_outlier),
  .plot_cor(df_subgroups),
  nrow = 1L
)
```


---
## Misjudgment 5: by chance

Number of drowned people and the films in which Nicolas Cage appeared.

<figure>
<img src="../tohoku2022r/image/nicholas-cage-drowned.svg" width="1200">
<figcaption><cite>
<a href="https://www.tylervigen.com/spurious-correlations">https://www.tylervigen.com/spurious-correlations</a>
</cite></figcaption>
</figure>


---
## Relationship between variables

<figure>
<img src="../tohoku2022r/image/hermeneutics-4-1-5.drawio.svg" width="1200">
<figcaption><cite>
<a href="https://amzn.to/3uznzCK">ã€Œåˆ†æè€…ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿è§£é‡ˆå­¦å…¥é–€ã€æ±Ÿå´è²´è£• 2020</a>ã‚ˆã‚Šæ”¹å¤‰
</cite></figcaption>
</figure>

<hr>

- **<span class="correlation">Correlation</span> does not imply <span class="causality">causation</span>**.
- Be aware of <span class="causality-wrong">reverse causation</span> and <span class="spurious">spurious correlation</span>.

ğŸ”° Find examples of these four types of relationships.

???
16--17ä¸–ç´€ã€æ€ªæˆ‘ã‚’ã—ãŸã‚‰æ­¦å™¨ã«è»Ÿè†ã‚’å¡—ã‚‹ã¨æ—©ãæ²»ã‚‹ã¨ã„ã†è¿·ä¿¡ã€‚
è³ªã®ä½ã„è»Ÿè†ã‚’å‚·å£ã«å¡—ã‚‰ãªã„ã“ã¨ãŒãƒ—ãƒ©ã‚¹ã«åƒã„ãŸã¨ã„ã†ã®ãŒçœŸç›¸ã€‚


---
## Reference

- ã€Œ[Rã‚’ç”¨ã„ãŸãƒ‡ãƒ¼ã‚¿è§£æã®åŸºç¤ã¨å¿œç”¨](https://comicalcommet.github.io/r-training-2023/)ã€
   çŸ³å·ç”±å¸Œ 2023 åå¤å±‹å¤§å­¦
- [ãƒ‡ãƒ¼ã‚¿è§£æã®ãŸã‚ã®çµ±è¨ˆãƒ¢ãƒ‡ãƒªãƒ³ã‚°å…¥é–€](https://amzn.to/33suMIZ) ä¹…ä¿æ‹“å¼¥ 2012
- [åˆ†æè€…ã®ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿è§£é‡ˆå­¦å…¥é–€](https://amzn.to/3uznzCK) æ±Ÿå´è²´è£• 2020
- [ãƒ‡ãƒ¼ã‚¿åˆ†æã®ãŸã‚ã®æ•°ç†ãƒ¢ãƒ‡ãƒ«å…¥é–€](https://amzn.to/3uCxTKo) æ±Ÿå´è²´è£• 2020
- [çµ±è¨ˆå­¦ã‚’å“²å­¦ã™ã‚‹](https://amzn.to/3ty80Kv) å¤§å¡šæ·³ 2020
- [çµ±è¨ˆæ€è€ƒã®ä¸–ç•Œ](https://amzn.to/3urpls1) ä¸‰ä¸­ä¿¡å® 2018
- Quarto / R Markdown
  - [R for Data Science --- Quarto](https://r4ds.hadley.nz/quarto)
  - [R Markdown: The Definitive Guide](https://bookdown.org/yihui/rmarkdown/)

`r .meta$next_link`
