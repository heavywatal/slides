<!DOCTYPE html>
<html>
<head prefix="og: http://ogp.me/ns#">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<title>4. ベイズ推定とMCMC — 統計モデリング概論 DSHC 2022</title>
<link rel="stylesheet" href="/slides/lib/reveal.js/reveal.css">
<link rel="stylesheet" href="/slides/css/theme-reveal.css">
<meta name="author" content="Watal M. Iwasaki">
<meta property="og:title" content="4. ベイズ推定とMCMC — 統計モデリング概論 DSHC 2022">
<meta property="og:type" content="article">
<meta property="og:url" content="https://heavywatal.github.io/slides/tokiomarine2022/4-bayesian.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/heavywatal">
<meta property="og:description" content="">
<meta property="og:site_name" content="Slide decks — Heavy Watal">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@heavywatal">
<meta name="twitter:creator" content="@heavywatal">
<meta name="generator" content="Hugo 0.101.0" />
<link rel="stylesheet" href="/lib/katex/katex.min.css">
<script defer src="/lib/katex/katex.min.js"></script>
<script defer src="/lib/katex/contrib/auto-render.min.js"></script>
<script>
document.addEventListener("DOMContentLoaded", function() {
  renderMathInElement(document.body, {
    delimiters: [
      {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false}
    ]
  });
});
</script>
<style>
.katex {
  font-size: 1.12em;
}

.katex-display > .katex {
  text-align: left;
  padding-left: 2rem;
}
</style>

<script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin="anonymous"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-V60H2JH0G6"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-V60H2JH0G6', { 'anonymize_ip': false });
}
</script>

</head>
<body>
<div class="reveal">
<div class="slides">
<section>
<link rel="stylesheet" href="style.css">
<h1 id="統計モデリング概論-dshc-2022"><a href=".">統計モデリング概論 DSHC 2022</a></h1>
<div class="author">
岩嵜 航 (Watal M. Iwasaki, PhD)
</div>
<div class="affiliation">
東北大学 生命科学研究科 進化ゲノミクス分野 特任助教<br>
(Graduate School of Life Sciences, Tohoku University)
</div>
<ol>
<li><a href="1-introduction.html">導入</a>
<li><a href="2-stats-model.html">統計モデルの基本: 確率分布、尤度</a>
<li><a href="3-glm.html">一般化線形モデル、混合モデル</a>
<li class="current-deck"><a href="4-bayesian.html">ベイズ推定とMCMC</a>
<li><a href="5-stan-glm.html">StanでGLM</a>
<li><a href="6-stan-hbm.html">Stanで階層ベイズモデル</a>
</ol>
<div class="footnote">
2022-08-24 東京海上 Data Science Hill Climb
<a href="https://heavywatal.github.io/slides/tokiomarine2022/">https://heavywatal.github.io/slides/tokiomarine2022/</a>
</div>

</section>
<section>
<h2 id="コイントス4回たまたま表が1回だったら">コイントス4回、たまたま表が1回だったら</h2>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">
<dl>
<dt>最尤推定</dt>
<dd>推定結果は最も尤もらしい1点。</dd>
<dd>データが少ないとき過剰適合気味。</dd>
<dd>表が出る確率 p = 0.25 のコインだろう。<br>
(信じ難いけどデータはこう言っている)</dd>
</dl>
<br>
<dl>
<dt>ベイズ推定</dt>
<dd>推定結果は確率分布そのもの。</dd>
<dd>データが少ないなりの不確実さも表現。</dd>
<dd>p = 0.25 らへんである確率は高いが、<br>
p = 0.6 とかである可能性もまあある。
</div>
<div class="column" style="flex-shrink: 1.4;">
</dd>
</dl>
<p><img src="figure/freq-vs-bayes-1.png" alt="plot of chunk freq-vs-bayes"><img src="figure/freq-vs-bayes-2.png" alt="plot of chunk freq-vs-bayes"></p>
  </div>
</div>

</section>
<section>
<h2 id="コイントスの回数が増えていったら">コイントスの回数が増えていったら</h2>
<p><strong>最尤推定</strong>: 推定値が真の値に近づいていく</p>
<p><img src="figure/coin-frequentist-1.png" alt="plot of chunk coin-frequentist"></p>
<p><strong>ベイズ推定</strong>: 確率分布がどんどん尖り、確信が強まる</p>
<p><img src="figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian"></p>

</section>
<section>
<h2 id="確率おさらい">確率おさらい</h2>
<dl>
<dt>同時分布/結合確率: <span style="font-weight: normal;"> <span style="color: #E69F00;">A</span>かつ<span style="color: #0072B2;">B</span>の確率</span></dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#E69F00}{A} \cap \textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#E69F00}{A}) \text{Prob}(\textcolor{#0072B2}{B})$</dd>
<dt>周辺確率: <span style="font-weight: normal;"> <span style="color: #0072B2;">B</span>によらず<span style="color: #E69F00;">A</span>になる確率</span></dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A}) = \sum_{\textcolor{#0072B2}{B}} \text{Prob}(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B})$</dd>
<dt>条件付き確率: <span style="font-weight: normal;"> <span style="color: #0072B2;">B</span>である条件の下で<span style="color: #E69F00;">A</span>になる確率。重要。</span></dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B}) = \frac {\text{Prob}(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B})} {\text{Prob}(\textcolor{#0072B2}{B})}$</dd>
</dl>
<p><img src="figure/venn-1.png" alt="plot of chunk venn">
</section>
<section>
<h2 id="条件付き確率がよくわかる具体例">条件付き確率がよくわかる具体例</h2>
<dl>
<dt><span style="color: #0072B2;">B Brewery</span>のビールが<span style="color: #E69F00;">Awesome</span>な確率</dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{\text{Awesome}} \mid \textcolor{#0072B2}{\text{B Brewery}}) = \frac {\text{Prob}(\textcolor{#E69F00}{\text{Awesome}},~\textcolor{#0072B2}{\text{B Brewery}})} {\text{Prob}(\textcolor{#0072B2}{\text{B Brewery}})}$</dd>
<dd>かなり高い確率。良い醸造所。</dd>
<dt><span style="color: #E69F00;">Awesome</span>なビールが<span style="color: #0072B2;">B Brewery</span>のものである確率</dt>
<dd>$\text{Prob}(\textcolor{#0072B2}{\text{B Brewery}} \mid \textcolor{#E69F00}{\text{Awesome}}) = \frac {\text{Prob}(\textcolor{#E69F00}{\text{Awesome}},~\textcolor{#0072B2}{\text{B Brewery}})} {\text{Prob}(\textcolor{#E69F00}{\text{Awesome}})}$</dd>
<dd>かなり低い確率。Awesomeなビールはほかにもたっくさんある。</dd>
</dl>
<img src="figure/venn-1.png" alt="plot of chunk venn">

</section>
<section>
<h2 id="ベイズの定理">ベイズの定理</h2>
<dl>
<dt>乗法定理</dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A},~\textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B})~\text{Prob}(\textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A})~\text{Prob}(\textcolor{#E69F00}{A})$</dd>
</dl>
<a href="https://en.wikipedia.org/wiki/Thomas_Bayes">
<img src="../tokiomarine2021/image/Thomas_Bayes.gif" height="150" align="right"></a>
<p>移項するだけで<strong>ベイズの定理</strong>:
<img src="../tokiomarine2021/bayes.drawio.svg" style="padding-left: 1rem;"></p>
<p>宴会場にビールが運ばれてきた。これはどこのブルワリーの？</p>
<dl>
<dt>事前確率: $\text{Prob}(\textcolor{#0072B2}{B})$</dt>
<dd>飲む前、手元のビールが<span style="color: #0072B2;">B Brewery</span>のである確率。</dd>
<dd>↓ 🍻 飲んでみて更新</dd>
<dt>事後確率: $\text{Prob}(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A})$</dt>
<dd>飲んでみて<span style="color: #E69F00;">Awesome</span>だったビールが
<span style="color: #0072B2;">B Brewery</span>のである確率。</dd>
</dl>

</section>
<section>
<h2 id="ベイズの定理-in-感染症検査">ベイズの定理 in 感染症検査</h2>
<ul>
<li>有病率 $\text{Prob}(M)$ : 0.3% (この地域の感染者の割合; 事前確率)</li>
<li>感度 $\text{Prob}(P \mid M)$ : 90% (感染してる人に陽性判定が出る)</li>
<li>特異度 $\text{Prob}(N \mid \overline{M})$: 99% (感染してない人に陰性判定が出る)</li>
</ul>
<p>$\text{Prob}(M \mid P)$ 真陽性率(検査陽性の人が実際に感染者である確率)は？</p>
<div>\[\begin{split}
\text{Prob}(M \mid P)
  &= \frac {\text{Prob}(P \mid M)~\text{Prob}(M)} {\text{Prob}(P)} \\
  &= \frac {\text{Prob}(P \mid M)~\text{Prob}(M)}
           {\text{Prob}(P \mid M)~\text{Prob}(M) + (1 - \text{Prob}(N \mid \overline{M}))~\text{Prob}(\overline{M})} \\
  &= \frac {0.9 \times 0.003} {0.9 \times 0.003 + 0.01 \times 0.997} \approx 0.21
\end{split}\]</div>
<p>感染者を隔離するスクリーニング目的では使いものにならない性能。</p>
<p>🔰 同様に $\text{Prob}(\overline{M} \mid N)$ 真陰性率を計算してみよう<br>
🔰 計算結果が検査性能だけでなく有病率にも依存することを確認しよう</p>

</section>
<section>
<h2 id="ベイズの定理-in-統計モデリング">ベイズの定理 in 統計モデリング</h2>
<p>
<img src="../tokiomarine2021/bayesian.drawio.svg">
</p>
<p>モデル$M$に対する確信度合いをデータ$D$に基づいて更新する。<br>
モデル$M$を仮説$H$やパラメータ$\theta$に置き換えてもいい。</p>
<p><strong>周辺尤度</strong>は「確率分布の積分は1」を満たすための正規化定数とみなせる。<br>
比例関係だけ抜き出してこう書くことが多い:</p>
<div>\[\begin{split}
\text{Prob}(M \mid D) &\propto \text{Prob}(D \mid M)~\text{Prob}(M) \\
\text{Prob}(H \mid D) &\propto \text{Prob}(D \mid H)~\text{Prob}(H) \\
\text{Prob}(\theta \mid D) &\propto \text{Prob}(D \mid \theta)~\text{Prob}(\theta)
\end{split}\]</div>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-1-事前分布">表が出る確率のベイズ推定: 1. 事前分布</h2>
<p>コイントスを繰り返して、表が出る確率pをベイズ推定したい。</p>
<p>事前分布には<strong>ベータ分布</strong>を採用(理由は後で分かる):</p>
<div>\[\begin{split}
\text{Beta}(p \mid a, b) =
   \frac{\Gamma(a + b)}{\Gamma(a) \Gamma(b)} p^{a-1} (1 - p)^{b-1}
\end{split}\]</div>
<p>分布の形は $a,~b$ によって決まる。<br>
ガンマ関数の部分は厳つく見えるけどただの正規化定数。<br>
投げる前なのでとりあえず真っ平らを仮定 $\text{Beta}(p \mid a = 1, b = 1)$:</p>
<p><img src="figure/prior-beta-1.png" alt="plot of chunk prior-beta"></p>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-2-尤度関数">表が出る確率のベイズ推定: 2. 尤度関数</h2>
<p>4回投げて表が1回だった、というデータで<strong>尤度</strong>を計算(<strong>二項分布</strong>):</p>
<div>\[\begin{split}
\text{Binom}(1 \mid 4,~p) = \binom {1} {4} p^{1} (1 - p)^{3}
\end{split}\]</div>
<p>これに事前分布を掛けて正規化したら事後分布になるはず。</p>
<div class="column-container">
  <div class="column" style="flex-shrink: 2.0;">
<p><img src="figure/likelihood-binom-1.png" alt="plot of chunk likelihood-binom"></p>
  </div>
  <div class="column" style="flex-shrink: 4.0; padding-top: 3rem;">
  ⨉
  </div>
  <div class="column" style="flex-shrink: 1.0;">
<p>
<img src="figure/prior-beta-1.png" alt="plot of chunk prior-beta">
</p>
  </div>
</div>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-3-事後分布">表が出る確率のベイズ推定: 3. 事後分布</h2>
<p>なんと、事後分布もベータ分布になる。</p>
<div>\[\begin{split}
\text{Posterior}
  &\propto \text{Binom}(1 \mid 4,~p) \times \text{Beta}(p \mid  1, 1)\\
  &= \binom {1} {4} p^{1} (1 - p)^{3} \times
     \frac{\Gamma(1 + 1)}{\Gamma(1) \Gamma(1)} p^{1-1} (1 - p)^{1-1} \\
  &= C p^{2-1} (1 - p)^{4-1} \\
  &= \text{Beta}(p \mid 2, 4)
\end{split}\]</div>
<p>ベータ分布の形パラメータ$a$が表、$b$が裏の回数分だけ増加。</p>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">
<p><img src="figure/posterior-beta-1.png" alt="plot of chunk posterior-beta"></p>
  </div>
  <div class="column" style="flex-shrink: 4.0; padding-top: 3rem;">
  $\propto$
  </div>
  <div class="column" style="flex-shrink: 1.0">
<p>
<img src="figure/likelihood-binom-1.png" alt="plot of chunk likelihood-binom">
</p>
  </div>
  <div class="column" style="flex-shrink: 4.0; padding-top: 3rem;">
  ⨉
  </div>
  <div class="column" style="flex-shrink: 1.0;">
<p>
<img src="figure/prior-beta-1.png" alt="plot of chunk prior-beta">
</p>
  </div>
</div>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-4-逐次学習">表が出る確率のベイズ推定: 4. 逐次学習</h2>
<p>さっきの事後分布を事前分布として、さらにデータを集める。</p>
<p>コイントス4回のうち表1回、に基づく<strong>事前分布</strong>: $\text{Beta}(p \mid 2,~4)$</p>
<p>さらに16回投げたら表が7回、の<strong>尤度</strong>: $\text{Binomial}(7 \mid 16,~p)$</p>
<p><strong>事後分布</strong>はまた事前分布と同じ形になる:</p>
<div>\[\begin{split}
\text{Beta}(p \mid 9, 13) \propto
  \text{Binomial}(7 \mid 16,~p) \times \text{Beta}(p \mid 2, 4)
\end{split}\]</div>
<p>データを加えるたびに更新していける:</p>
<img src="figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian">

</section>
<section>
<h2 id="共役事前分布">共役事前分布</h2>
<p>事後分布が事前分布と同じ形なので計算しやすい、という組み合わせ。</p>
<table>
<thead>
<tr>
<th>尤度関数</th>
<th>共役事前分布</th>
</tr>
</thead>
<tbody>
<tr>
<td>二項分布</td>
<td>ベータ分布</td>
</tr>
<tr>
<td>ポアソン分布</td>
<td>ガンマ分布</td>
</tr>
<tr>
<td>正規分布</td>
<td>ガンマ分布</td>
</tr>
<tr>
<td>正規分布 (分散既知)</td>
<td>正規分布</td>
</tr>
</tbody>
</table>
<p>共役事前分布を使うことが常に正しいとも限らない。<br>
計算コストがかかっても<strong>無情報事前分布</strong>を使う風潮。</p>

</section>
<section>
<h2 id="事後分布を用いた推定">事後分布を用いた推定</h2>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">
<dl>
<dt>区間推定</dt>
<dd>幅のある推定値を提示</dd>
<dd>e.g., 95%ベイズ確信区間<br>
(等裾事後信用区間, 最高密度区間)</dd>
<dt>点推定</dt>
<dd>値を1点だけ提示</dd>
<dd>e.g., MAP, MED, EAP
</div>
<div class="column" style="flex-shrink: 1.3;">
</dd>
</dl>
<p><img src="figure/integrate-1.png" alt="plot of chunk integrate"></p>
  </div>
</div>
<p>コイン投げモデルのベータ分布は美しい例。<br>
→ 解析的(数学的)に解ける。</p>
<p>実践的なモデル・事後分布はもっと複雑。<br>
→ コンピュータに頼って数値計算: MCMC</p>

</section>
<section>
<h2 id="mcmc-umuarcov-ucuhain-umuonte-ucuarlo">MCMC: <u>M</u>arcov <u>C</u>hain <u>M</u>onte <u>C</u>arlo</h2>
<a href="https://en.wikipedia.org/wiki/Andrey_Markov">
<img src="../tokiomarine2021/image/AAMarkov.jpg" height="180" align="right"></a>
<dl>
<dt>マルコフ連鎖</dt>
<dd>次の時点の挙動が現在の値だけで決定されるような確率過程。</dd>
<dd>$\ldots \to X_{t - 2} \to X_{t - 1} \to X_{t} \to X_{t + 1}$</dd>
<dd>$\text{Prob}(X_{t+1} \mid X_{t}, X_{t-1}, X_{t-2}, \ldots) = \text{Prob}(X_{t+1} \mid X_{t})$</dd>
<dd>e.g., すごろく</dd>
<dt>モンテカルロ法</dt>
<dd>乱数を用いた計算方法の総称。</dd>
<dd><a href="https://en.wikipedia.org/wiki/Monte_Carlo_Casino">
<img src="../tokiomarine2021/image/Real_Monte_Carlo_Casino.jpg" height="200"></a>
<a href="https://en.wikipedia.org/wiki/Stanislaw_Ulam">
<img src="../tokiomarine2021/image/Stanislaw_Ulam.jpg" height="200"></a>
<a href="https://en.wikipedia.org/wiki/John_von_Neumann">
<img src="../tokiomarine2021/image/John_von_Neumann.jpg" height="200"></a>
<a href="https://en.wikipedia.org/wiki/Nicholas_Metropolis">
<img src="../tokiomarine2021/image/Nicholas_Metropolis.png" height="200"></a>
</dd>
</dl>

</section>
<section>
<h2 id="モンテカルロ法は乱数を用いた計算方法">モンテカルロ法は乱数を用いた計算方法</h2>
<p>e.g., 半径1の円の面積</p>
<p>面積4の正方形に400個の一様乱数を打ち込んだら318個乗った:<br>
$4 \times \frac {318} {400} = 3.18$</p>
<p><img src="figure/circle-1.png" alt="plot of chunk circle"></p>
<p>数学を知っていれば $\pi r ^ 2 \approx 3.14$</p>

</section>
<section>
<h2 id="変な分布もモンテカルロ法で扱えそう">変な分布もモンテカルロ法で扱えそう</h2>
<p>e.g., 確率密度分布に従って変数Xを集める(棄却サンプリング)。</p>
<p><img src="figure/mcpdf-1.png" alt="plot of chunk mcpdf"></p>
<p>でも、ハズレの値もけっこう引いてしまう。</p>

</section>
<section>
<h2 id="次元の呪い-高次元になるほど当たりにくくなる">次元の呪い: 高次元になるほど当たりにくくなる</h2>
<p>(N次元球の体積 / N次元の立方体) はゼロに近づいていく。</p>
<img src="figure/circle-1.png" width="210" align="right">
<ul>
<li>2次元: $\frac {\pi r ^ 2} {(2r) ^ 2} = \frac \pi 4 \approx 0.79$</li>
<li>3次元: $\frac {\frac 4 3 \pi r ^ 3} {(2r) ^ 3} = \frac \pi 6 \approx 0.52$</li>
<li>N次元: $\frac {\frac {\pi ^ {N/2}} {\Gamma (N/2 + 1)} r ^ N} {(2r) ^ N} = \frac {\pi ^ {N/2}} {2^N \Gamma (N/2 + 1)} \to 0$</li>
</ul>
<p>パラメータが増えると計算量(≈乱数の無駄撃ち)が急増。</p>
<hr>
<p>密度の高い「当たり」付近を効率よく探索したい。<br>
「当たり」は「当たり」の近くにありがちだろう。<br>
→ マルコフ連鎖が使えそう</p>

</section>
<section>
<h2 id="metropolis--hastings法-mh法">Metropolis&ndash;Hastings法 (MH法)</h2>
<ol start="0">
<li>パラメータ $\theta$ の初期値を選ぶ</li>
<li>$\theta$ をちょっと増減させて $\theta_\text{new}$ を作る</li>
<li>それぞれ尤度を計算し、比較。
<ul>
<li>$L(\theta_\text{new}) \ge L(\theta)$ なら $\theta_\text{new}$ を即採択</li>
<li>$L(\theta_\text{new}) &lt; L(\theta)$ でも
確率 $r = \frac {L(\theta_\text{new})} {L(\theta)}$ で  $\theta_\text{new}$ を採択</li>
</ul>
</li>
<li>$\theta_\text{new}$ が採択されたら $\theta$ を更新。手順1に戻る。</li>
</ol>
<p><img src="figure/metropolis-1.png" alt="plot of chunk metropolis">
</section>
<section>
<h2 id="採択されたパラメータ値の軌跡">採択されたパラメータ値の軌跡</h2>
<p>尤度が高い方にただ向かうだけでなく、結構うろつく。<br>
通ったパラメータ値を集めるといい感じの分布が得られる。</p>
<p><img src="figure/metropolis-trajectory-.gif" alt="plot of chunk metropolis-trajectory"></p>

</section>
<section>
<h2 id="尤度に比例する事後分布からサンプルしたのと等価">尤度に比例する事後分布からサンプルしたのと等価</h2>
<p>全体にばら撒く棄却サンプリングよりも効率よく集められる。<br>
が、パラメータ1つの1次元ではご利益はわかりにくい。</p>
<p><img src="figure/propto-lik-1.png" alt="plot of chunk propto-lik"></p>
<p>パラメータが複数ある場合は？</p>

</section>
<section>
<h2 id="gibbs-sampling">Gibbs Sampling</h2>
<p>パラメータが複数の場合「ほかを固定してひとつ更新」を繰り返す。</p>
<p>e.g., 二次元正規分布。(-2, 2) からスタート。</p>
<p><img src="figure/gibbs-.gif" alt="plot of chunk gibbs"></p>

</section>
<section>
<h2 id="中間まとめ">中間まとめ</h2>
<ul>
<li>ベイズ推定では不確実性も表現できる。</li>
<li>コンピュータに頼った計算方法としてのモンテカルロ法。</li>
<li>多次元でも効率よくサンプルするためのMCMC。</li>
</ul>
<hr>
<p>ここから、実行するにあたっての注意点を見ていく。
</section>
<section>
<h2 id="何回やっても似たような結果になってほしい">何回やっても似たような結果になってほしい</h2>
<p>乱数や初期値によって偶々、じゃないことを確認したい。</p>
<p>e.g., <code>chains = 3, iter = 600</code> 。ほぼ同じところをうろうろ:</p>
<p><img src="figure/chains-1.png" alt="plot of chunk chains"></p>
<p>収束(convergence)の判定については後ほど。</p>

</section>
<section>
<h2 id="初期値の影響が消えるまでウォーミングアップ">初期値の影響が消えるまでウォーミングアップ</h2>
<p>定常分布の山に到達してからが本番。</p>
<p>e.g., <code>iter = 600, warmup = 200</code> で灰色の部分を捨てる:</p>
<p><img src="figure/warmup-1.png" alt="plot of chunk warmup"></p>
<p>どれくらい長く捨てるべきかは場合による。</p>

</section>
<section>
<h2 id="適度に間引いて自己相関を軽減したい">適度に間引いて自己相関を軽減したい</h2>
<p>直前の値と似すぎていたら独立サンプルとして扱えないので。</p>
<p>e.g., <code>thin = 5</code> で5回に1回だけサンプルする:</p>
<p><img src="figure/thin-1.png" alt="plot of chunk thin"></p>
<p>間引かなくても大丈夫な場合も、間引いても解決しない場合もある。</p>

</section>
<section>
<h2 id="収束判定">収束判定</h2>
<ul>
<li>複数chainsで異なる初期値から実行し、軌跡や分布を可視化</li>
<li>Gelman-Rubin統計量 $\hat R &lt; 1.05$</li>
<li>Effective Sample Size (ESS) $N_\text{eff} &gt; 100$ per chain</li>
</ul>
<p><img src="figure/convergence-1.png" alt="plot of chunk convergence"></p>
<pre tabindex="0"><code>Warning: The largest R-hat is ***, indicating chains have not mixed.
Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
http://mc-stan.org/misc/warnings.html
</code></pre>
</section>
<section>
<h2 id="収束自己相関が悪い場合にどう改善するか">収束・自己相関が悪い場合にどう改善するか</h2>
<ul>
<li>小手先の対処
<ul>
<li>warmupとiterをもっと長くする</li>
<li>thinを大きくして間引く</li>
</ul>
</li>
<li>ちょっと大掛かり
<ul>
<li>モデルを見直す</li>
<li>プログラムを見直す</li>
<li>アルゴリズム・ソフトウェアを変える</li>
</ul>
</li>
</ul>

</section>
<section>
<h2 id="mcmcの方法いろいろ">MCMCの方法いろいろ</h2>
<p>採択率を高め、早く収束するように改良されてきている。</p>
<ul>
<li>Metropolis&ndash;Hastings法
<ul>
<li>Gibbs Sampling</li>
<li>Hamiltonian Monte Carlo (HMC)
<ul>
<li>No-U-Turn Sampler (NUTS)</li>
</ul>
</li>
</ul>
</li>
</ul>

</section>
<section>
<h2 id="mcmcソフトウェア">MCMCソフトウェア</h2>
<ul>
<li><a href="https://www.mrc-bsu.cam.ac.uk/software/bugs/">BUGS</a>
<ul>
<li>クローズドソースで、ほぼWindows専用。</li>
</ul>
</li>
<li><a href="https://mcmc-jags.sourceforge.io/">JAGS</a>
<ul>
<li>オープンソースで、さまざまなOS・言語から利用可能。</li>
<li>マニュアルや用例が不足。</li>
</ul>
</li>
<li><a href="https://mc-stan.org/"><strong>Stan</strong></a> 👈
<ul>
<li>オープンソースで、さまざまなOS・言語から利用可能。</li>
<li>開発も利用も活発。マニュアルや用例も充実。</li>
<li>HMC/NUTSにより早く収束。</li>
</ul>
</li>
<li><a href="https://docs.pymc.io/">PyMC3</a></li>
<li><a href="https://num.pyro.ai/">NumPyro</a></li>
<li><a href="https://www.tensorflow.org/probability/">TensorFlow Probability</a></li>
</ul>

</section>
<section>
<h2 id="stan">Stan</h2>
<a href="https://mc-stan.org/">
<img src="/slides/image/stan/logo_name.png" width="120" align="right">
</a>
<ul>
<li>Stan言語でモデルを書く</li>
<li>C++を介して機械語に翻訳(コンパイル)するので高速</li>
<li>RやPythonなどから呼び出して使うのが便利</li>
</ul>

</section>
<section>
<h2 id="参考文献">参考文献</h2>
<ul>
<li><a href="https://amzn.to/33suMIZ">データ解析のための統計モデリング入門</a> 久保拓弥 2012</li>
<li><a href="https://amzn.to/3uwx7Pb">StanとRでベイズ統計モデリング</a> 松浦健太郎 2016</li>
<li><a href="https://amzn.to/3o1eCzP">RとStanではじめる ベイズ統計モデリングによるデータ分析入門</a> 馬場真哉 2019</li>
<li><a href="https://amzn.to/3uCxTKo">データ分析のための数理モデル入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3uznzCK">分析者のためのデータ解釈学入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3ty80Kv">統計学を哲学する</a> 大塚淳 2020</li>
</ul>
<a href="5-stan-glm.html" rel="next" class="readmore">
5. StanでGLM
</a>

</section>
</div>
</div>
<script src="/slides/lib/reveal.js/reveal.js"></script>
<script src="/slides/lib/reveal.js/plugin/notes.js"></script>
<script>
Reveal.initialize({
  width: 960,
  height: 720,
  margin: 0,
  controls: true,
  controlsLayout: 'bottom-right',
  controlsTutorial: false,
  controlsBackArrows: 'faded',
  progress: false,
  slideNumber: 'c/t',
  showSlideNumber: 'all',
  hashOneBasedIndex: true,
  hash: true,
  history: false,
  keyboard: true,
  overview: true,
  center: false,
  touch: true,
  loop: false,
  rtl: false,
  navigationMode: 'linear',
  shuffle: false,
  fragments: true,
  fragmentInURL: true,
  embedded: false,
  help: true,
  showNotes: false,
  autoPlayMedia: null,
  preloadIframes: null,
  mouseWheel: false,
  previewLinks: false,
  transition: 'none',
  transitionSpeed: 'fast',
  backgroundTransition: 'none',
  pdfMaxPagesPerSlide: 1,
  pdfSeparateFragments: false,
  viewDistance: 2,
  plugins: [ RevealNotes ]
});
</script>
<script>
{
const reload_all_img = function() {
  const imgs = document.getElementsByTagName("img");
  for (let i = 0; i < imgs.length; ++i) {
    const src = imgs[i].src;
    imgs[i].src += "?q";
    imgs[i].src = src;
  }
};
const reload_src_element = function(ev) {
  const original_src = ev.srcElement.src;
  ev.srcElement.src += "?q";
  ev.srcElement.src = original_src;
};
const reload_src = function(ev) {
  if (ev.shiftKey || ev.metaKey || ev.altKey) {
    reload_all_img();
  } else {
    reload_src_element(ev);
  }
};
const img_elements = document.getElementsByTagName("img");
for (let i = 0; i < img_elements.length; ++i) {
  img_elements[i].onclick = reload_src;
}
};
</script>
</body>
</html>
