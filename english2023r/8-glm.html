<!DOCTYPE html>
<html lang="ja">
<head prefix="og: http://ogp.me/ns#">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<title>8. Statistical modeling 2: linear regression — Hands-on Introduction to R 2023</title>
<meta name="author" content="Watal M. Iwasaki">
<meta property="og:title" content="8. Statistical modeling 2: linear regression — Hands-on Introduction to R 2023">
<meta property="og:type" content="article">
<meta property="og:url" content="https://heavywatal.github.io/slides/english2023r/8-glm.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/heavywatal">
<meta property="og:description" content="">
<meta property="og:site_name" content="Slide decks — Heavy Watal">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@heavywatal">
<meta name="twitter:creator" content="@heavywatal">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-V60H2JH0G6"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-V60H2JH0G6');
</script>
<link rel="stylesheet" href="/slides/lib/reveal.js/reveal.css">
<script type="module">
import { Reveal } from "/slides/lib/reveal.js/reveal.js";
window.addEventListener('DOMContentLoaded', function() {
  Reveal.configure({width: 1440, height: 1080});
  document.querySelector('html').style.fontSize = '240%';
})
</script>
<link rel="stylesheet" href="/slides/lib/katex/katex.min.css">
<script src="/slides/lib/katex/katex.min.js"></script>
<script src="/slides/lib/iconify.js"></script>
<script defer src="/slides/lib/reload-img-onclick.js"></script>
<link rel="stylesheet" href="/slides/css/style-reveal.css">
<link rel="stylesheet" href="style.css">
</head>
<body>
<div class="reveal">
<div class="slides">
<section>
<h1 id="hands-on-introduction-to-r-2023"><a href=".">Hands-on Introduction to R 2023</a></h1>
<div class="author">
岩嵜 航 (Watal M. Iwasaki, PhD)
</div>
<div class="affiliation">
Graduate School of Life Sciences, Tohoku University
</div>
<ol>
<li><a href="1-introduction.html">Introduction: what is data analysis and R basics</a>
<li><a href="2-visualization.html">Data visualization and reporting</a>
<li><a href="3-structure1.html">Data transformation 1: extract, summarize</a>
<li><a href="4-structure2.html">Data transformation 2: join, pivot</a>
<li><a href="5-content.html">Data cleansing and conversion: numbers, text</a>
<li><a href="6-input.html">Data input and interpretation</a>
<li><a href="7-distribution.html">Statistical modeling 1: probability distribution, likelihood</a>
<li class="current-deck"><a href="8-glm.html">Statistical modeling 2: linear regression</a>
</ol>
<div class="footnote">
2023-12-06 Tohoku University<br>
<a href="https://heavywatal.github.io/slides/english2023r/">https://heavywatal.github.io/slides/english2023r/</a>
</div>

</section>
<section>
<h2 id="extending-linear-regression">Extending linear regression</h2>
<figure style="float: right;">
<a href="https://kuboweb.github.io/-kubo/ce/IwanamiBook.html">
<img src="../tokiomarine2021/image/kubo-book.jpg" width="280" alt="データ解析のための統計モデリング入門 久保拓弥 2012">
</a>
</figure>
<p><strong>Linear Model (LM)</strong> <a href="7-distribution.html">&mdash; #7 yesterday</a></p>
<p><span style="color: #888888;">    ↓ probability distribution</span></p>
<p><strong>Generalized Linear Model (GLM)</strong> 👈 #8 today</p>
<p><span style="color: #888888;">    ↓ individual difference, random effect</span></p>
<p><strong>Generalized Linear Mixed Model (GLMM)</strong></p>
<p><span style="color: #888888;">    ↓ flexible modelling</span></p>
<p><strong>Hierarchical Bayesian Model (HBM)</strong></p>
<p><cite><a href="https://amzn.to/33suMIZ">データ解析のための統計モデリング入門</a> 久保拓弥 2012 より改変</cite></p>

</section>
<section>
<h2 id="straight-lm-does-not-fit-all">Straight LM does not fit all</h2>
<img src="figure/glm-better-1.png" alt="plot of chunk glm-better">
<ul>
<li>Prediction goes below zero whereas all the observations are <strong>positive</strong>.</li>
<li>Y values are <strong>integer</strong>. Their <strong>dispersion</strong> is larger when X is larger.</li>
<li>Let&rsquo;s learn statistical modelling for better fitting to the data.</li>
</ul>

</section>
<section>
<h2 id="statistical-modelling-in-the-previous-session">Statistical modelling in the previous session</h2>
<p>Random variable $X$ follows the probability distribution $f$ with parameters $\theta$.<br>
$X \sim f(\theta) $</p>
<p>e.g., Number of seeds $X$ follows Poisson distribution with mean $\lambda$:</p>
<div>\[\begin{split}
X \sim \text{Poisson}(\lambda)
\end{split}\]</div>
<p><img src="./figure/only-dist-1.png" alt="plot of chunk only-dist"></p>

</section>
<section>
<h2 id="viewing-the-same-model-as-glm">Viewing the same model as GLM</h2>
<p>The number of individual $i$&rsquo;s seeds $y_i$ follows Poisson distribution with mean $\lambda_i$.<br>
Mean $\lambda_i$ is <strong>common constant $\beta_0$</strong>.</p>
<div>\[\begin{split}
y_i &\sim \text{Poisson}(\lambda_i) \\
\lambda_i &= \beta_0
\end{split}\]</div>
<p><img src="./figure/glm-without-x-1.png" alt="plot of chunk glm-without-x"></p>
<p>Just separated the equation into two, and flipped X-Y axes&hellip;? Why?<br>
The reason may be clearer in a model with <strong>explanatory variables</strong>.</p>

</section>
<section>
<h2 id="glm-with-one-explanatory-variable">GLM with one explanatory variable</h2>
<p>The number of individual $i$&rsquo;s seeds $y_i$ follows Poisson distribution with mean $\lambda_i$.<br>
Mean $\lambda_i$ is <strong>a linear function of its body mass $x_i$</strong>.</p>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">
<figure style="margin-block: 1em 0;">
<img src="../english2023r/image/glm.drawio.svg" width="600"><br>
</figure>
  </div>
  <div class="column" style="flex-shrink: 1.0;">
<p><img src="./figure/glm-poisson-1.png" alt="plot of chunk glm-poisson"></p>
  </div>
</div>
<p><strong>simple linear regression</strong> with a single explanatory variable ↑ <br>
<strong>multiple linear regression</strong> with multiple explanatory variables →</p>

</section>
<section>
<h2 id="multiple-regression-with-multiple-expl-variables">Multiple regression with multiple expl. variables</h2>
<p>\[\begin{split}
y_i &\sim \text{Poisson}(\lambda_i) \\
\log(\lambda_i) &= \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots
\end{split}\]</p>
<p>🍺 Beer sells better on hot and humid days:</p>
<p><img src="./figure/multiple-regression-1.png" alt="plot of chunk multiple-regression"></p>
<p>Let&rsquo;s see other <strong>probability distributions</strong> and <strong>link functions</strong> →</p>

</section>
<section>
<h2 id="logistic-regression">Logistic regression</h2>
<ul>
<li>Probability distribution: <strong>binomial distribution</strong></li>
<li>Link function: $\operatorname{logit}(p) = \log \frac {p} {1 - p}$</li>
</ul>
<p>estimates the probability of event occurrence based on some variables.</p>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0; padding-top: 1rem;">
<p>$y_i$ in 10 customers ordered beer.<br>
$p_i$ varies by temperature $x_i$.</p>
<p>\[\begin{split}
y_i &\sim \text{Binomial}(n,~p_i) \\
\operatorname{logit}(p_i) &= \beta_0 + \beta_1 x_i \\
p_i &= \frac 1 {1 + e^{-(\beta_0 + \beta_1 x_i)}}
\end{split}\]</p>
<p>Logistic function ↑</p>
  </div>
  <div class="column" style="flex-shrink: 1.0;">
<p><img src="./figure/glm-logistic-1.png" alt="plot of chunk glm-logistic"></p>
  </div>
</div>

</section>
<section>
<h2 id="logistic-regression-narrow-sense">Logistic regression (narrow sense)</h2>
<ul>
<li>Probability distribution: <strong>Bernoulli distribution</strong> (binomial with $n = 1$)</li>
<li>Link function: $\operatorname{logit}(p) = \log \frac {p} {1 - p}$</li>
</ul>
<p>estimates the probability of event occurrence based on some variables.</p>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0; padding-top: 1rem;">
<p>Buckets sells better on windy days.</p>
<p>\[\begin{split}
y_i &\sim \text{Bernoulli}(p_i) \\
  &= \text{Binomial}(1,~p_i) \\
\operatorname{logit}(p_i) &= \beta_0 + \beta_1 x_i \\
p_i &= \frac 1 {1 + e^{-(\beta_0 + \beta_1 x_i)}}
\end{split}\]</p>
<p>Logistic function ↑</p>
  </div>
  <div class="column" style="flex-shrink: 1.0;">
<p><img src="./figure/wind-1.png" alt="plot of chunk wind"></p>
  </div>
</div>

</section>
<section>
<h2 id="lm-is-a-special-case-of-glm">LM is a special case of GLM</h2>
<ul>
<li>Probability distribution: <strong>Normal distribution</strong></li>
<li>Link function: <strong>identity</strong> (returns everything unchanged)</li>
</ul>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0; padding-top: 1rem;">
<p>\[\begin{split}
y_i &\sim \mathcal{N}(\mu_i,~\sigma^2) \\
\text{identity}(\mu_i) &= \beta_0 + \beta_1 x_i
\end{split}\]</p>
  </div>
  <div class="column" style="flex-shrink: 1.0;">
<p><img src="./figure/glm-weight-1.png" alt="plot of chunk glm-weight"></p>
  </div>
</div>
<p>resulting in the same regression line as OLS.</p>

</section>
<section>
<h2 id="uanualysis-uouf-uvauriance-anova-as-glm"><u>An</u>alysis <u>o</u>f <u>va</u>riance (ANOVA) as GLM</h2>
<p>with <strong>qualitative</strong> explanatory variables, <strong>normal</strong> distribution, <strong>identity</strong> link.<br>
needs conversion to <span title="a.k.a dummy variables"><strong>index variables</strong></span> (0 or 1).</p>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0; padding-top: 1rem;">
<table>
  <thead>
      <tr>
          <th>weather</th>
          <th style="text-align: center">→</th>
          <th style="text-align: center">$x_1$ ☀️ 晴</th>
          <th style="text-align: center">$x_2$ ☔️ 雨</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>☁️ cloudy</td>
          <td style="text-align: center"></td>
          <td style="text-align: center">0</td>
          <td style="text-align: center">0</td>
      </tr>
      <tr>
          <td>☀️ sunny</td>
          <td style="text-align: center"></td>
          <td style="text-align: center">1</td>
          <td style="text-align: center">0</td>
      </tr>
      <tr>
          <td>☔️ rainy</td>
          <td style="text-align: center"></td>
          <td style="text-align: center">0</td>
          <td style="text-align: center">1</td>
      </tr>
  </tbody>
</table>
<p>\[\begin{split}
y_i &\sim \mathcal{N}(\mu_i,\sigma^2) \\
\mu_i &= \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i}
\end{split}\]</p>
  </div>
  <div class="column" style="flex-shrink: 1.3;">
<p><img src="./figure/glm-anova-1.png" alt="plot of chunk glm-anova"></p>
  </div>
</div>
<p>The effects of sunny☀️ $\beta_1$ and rainy☔️ $\beta_2$ are relative to cloudy☁️ $\beta_0$.</p>
<p>GLM supports more flexible modelling with other distribution &amp; link.</p>

</section>
<section>
<h2 id="uanualysis-of-ucovauriance-ancova-as-glm"><u>An</u>alysis of <u>cova</u>riance (ANCOVA) as GLM</h2>
<p>with <strong>both qualitative and quantitative</strong> explanatory variables<br>
assuming <strong>normal</strong> distribution, <strong>homogeneity of variance</strong>, <strong>identity</strong> link.</p>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0; padding-top: 1rem;">
<table>
  <thead>
      <tr>
          <th>weather</th>
          <th style="text-align: center">→</th>
          <th style="text-align: center">$x_1$ ☀️ 晴</th>
          <th style="text-align: center">$x_2$ ☔️ 雨</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>☁️ cloudy</td>
          <td style="text-align: center"></td>
          <td style="text-align: center">0</td>
          <td style="text-align: center">0</td>
      </tr>
      <tr>
          <td>☀️ sunny</td>
          <td style="text-align: center"></td>
          <td style="text-align: center">1</td>
          <td style="text-align: center">0</td>
      </tr>
      <tr>
          <td>☔️ rainy</td>
          <td style="text-align: center"></td>
          <td style="text-align: center">0</td>
          <td style="text-align: center">1</td>
      </tr>
  </tbody>
</table>
<p>\[\begin{split}
y_i &\sim \mathcal{N}(\mu_i,\sigma^2) \\
\mu_i &= \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 x_{3i}
\end{split}\]</p>
  </div>
  <div class="column" style="flex-shrink: 1.3;">
<p><img src="./figure/glm-ancova-1.png" alt="plot of chunk glm-ancova"></p>
  </div>
</div>
<p>GLM supports more flexible modelling with other distribution &amp; link.</p>

</section>
<section>
<h2 id="interaction">Interaction</h2>
<p>The effects of two or more variables are not additive.<br>
e.g., The temperature dependency of beer sales differs by weather.</p>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0; padding-top: 0.1rem;">
<table>
  <thead>
      <tr>
          <th>weather</th>
          <th style="text-align: center">$x_1$</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>☀️ sunny</td>
          <td style="text-align: center">1</td>
      </tr>
      <tr>
          <td>☔️ rainy</td>
          <td style="text-align: center">0</td>
      </tr>
  </tbody>
</table>
<p>\[\begin{split}
y_i &\sim \mathcal{N}(\mu_i,\sigma^2) \\
\mu_i &= \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_{1,2} x_{1i} x_{2i}
\end{split}\]</p>
<p>☀️ all $\beta$<br>
☔️ only $\beta_0,~\beta_2$ because $x_{1i} = 0$.</p>
  </div>
  <div class="column" style="flex-shrink: 1.3;">
<p><img src="./figure/interaction-1.png" alt="plot of chunk interaction"></p>
  </div>
</div>
<p>Drawback: it makes interpretation difficult dramatically.</p>

</section>
<section>
<h2 id="roundup-generalized-linear-model-glm">Roundup: Generalized Linear Model (GLM)</h2>
<p>supports flexible modelling with various distribution &amp; link.<br>
There are some named (frequently used) combinations.</p>
<table>
  <thead>
      <tr>
          <th>Name</th>
          <th>Distribution</th>
          <th>Link</th>
          <th>expl. variables</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Poisson regression</td>
          <td>Poisson</td>
          <td>log</td>
          <td></td>
      </tr>
      <tr>
          <td>Logistic regression</td>
          <td>Binomial</td>
          <td>logit</td>
          <td></td>
      </tr>
      <tr>
          <td>LM</td>
          <td>Normal</td>
          <td>identity</td>
          <td></td>
      </tr>
      <tr>
          <td>ANOVA</td>
          <td>Normal</td>
          <td>identity</td>
          <td>qualitative</td>
      </tr>
      <tr>
          <td>ANCOVA</td>
          <td>Normal</td>
          <td>identity</td>
          <td>qualitative+quantitative</td>
      </tr>
  </tbody>
</table>
</section>
<section>
<h2 id="link-functions">Link functions</h2>
<dl>
<dt>$\text{identity}(\mu_i) = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots$</dt>
<dd>$\mu_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots$</dd>
<dd>The effects of expl. variables are <strong>additive</strong>.</dd>
<dt>$\log(\lambda_i) = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots$</dt>
<dd>$\lambda_i = e^{\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots} = e^{\beta_0} \times e^{\beta_1 x_{1i}} \times e^{\beta_2 x_{2i}} \times \ldots$</dd>
<dd>The effects of expl. variables are <strong>multiplicative</strong>.<br>
e.g., adding $\Delta x_1$ brings multiplying $e^{\beta_1 \Delta x_{1}}$.</dd>
<dt>$\operatorname{logit}(p_i) = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \ldots$</dt>
<dd>$p_i = \frac 1 {1 + e^{-(\beta_0 + \beta_1 x_i + \ldots)}} $ (logistic function)</dd>
<dd>The effects of expl. variables are <strong>plateaued</strong>.<br>
e.g., $\lim_{x \to -\infty} p = 0;~\lim_{x \to \infty} p = 1$</dd>
</dl>
<p><code>probit</code>, <code>inverse</code>, <code>sqrt</code>, etc. are not covered here.</p>
</section>
<section>
<h2 id="glm-in-r">GLM in R</h2>
<p>Almost the same way as with <code>lm</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">formula</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">~</span> <span class="n">height</span>
</span></span><span class="line"><span class="cl"><span class="n">fit</span> <span class="o">=</span> <span class="nf">glm</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">df_weight</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">coef</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>(Intercept)      height 
  -69.85222    78.63444 
</code></pre><p>Normal distribution and identity link is selected by default.<br>
Use <code>family=</code> option for modification:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="nf">glm</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="nf">gaussian</span><span class="p">(</span><span class="n">link</span> <span class="o">=</span> <span class="n">identity</span><span class="p">),</span> <span class="n">data</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">glm</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="nf">poisson</span><span class="p">(</span><span class="n">link</span> <span class="o">=</span> <span class="n">log</span><span class="p">),</span> <span class="n">data</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">glm</span><span class="p">(</span><span class="n">formula</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="nf">binomial</span><span class="p">(</span><span class="n">link</span> <span class="o">=</span> <span class="n">logit</span><span class="p">),</span> <span class="n">data</span> <span class="o">=</span> <span class="n">mydata</span><span class="p">)</span>
</span></span></code></pre></div><p>See <a href="https://stat.ethz.ch/R-manual/R-patched/library/stats/html/family.html"><code>?family</code></a> for more details.</p>

</section>
<section>
<h2 id="-practice-of-glm">🔰 Practice of <code>glm()</code></h2>
<p>Express weight as a linear function of height.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">n</span> <span class="o">=</span> <span class="m">50</span>
</span></span><span class="line"><span class="cl"><span class="n">df_weight</span> <span class="o">=</span> <span class="n">tibble</span><span class="o">::</span><span class="nf">tibble</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">height</span> <span class="o">=</span> <span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="m">1.70</span><span class="p">,</span> <span class="m">0.05</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">bmi</span> <span class="o">=</span> <span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="m">22</span><span class="p">,</span> <span class="m">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">weight</span> <span class="o">=</span> <span class="n">bmi</span> <span class="o">*</span> <span class="p">(</span><span class="n">height</span><span class="o">**</span><span class="m">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nf">print</span><span class="p">()</span>
</span></span></code></pre></div><pre tabindex="0"><code>     height      bmi   weight
 1 1.718019 21.55500 63.62151
 2 1.782862 22.83775 72.59199
 3 1.617464 22.43569 58.69604
 4 1.678291 23.37245 65.83231
--                           
47 1.762930 21.78337 67.70106
48 1.744133 21.47257 65.31960
49 1.730495 19.72866 59.07966
50 1.676496 22.85824 64.24627
</code></pre><p>Don&rsquo;t care about interpretation and goodness of fit for now.</p>

</section>
<section>
<h2 id="-practice-of-glm-example-solution">🔰 Practice of <code>glm()</code>, example solution</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">fit_wh</span> <span class="o">=</span> <span class="nf">glm</span><span class="p">(</span><span class="n">weight</span> <span class="o">~</span> <span class="n">height</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="nf">gaussian</span><span class="p">(</span><span class="n">link</span> <span class="o">=</span> <span class="n">identity</span><span class="p">),</span> <span class="n">data</span> <span class="o">=</span> <span class="n">df_weight</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">coef</span><span class="p">(</span><span class="n">fit_wh</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>(Intercept)      height 
  -69.85222    78.63444 
</code></pre><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">df_fit_wh</span> <span class="o">=</span> <span class="n">modelr</span><span class="o">::</span><span class="nf">add_predictions</span><span class="p">(</span><span class="n">df_weight</span><span class="p">,</span> <span class="n">fit_wh</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;response&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">ggplot</span><span class="p">(</span><span class="n">df_fit_wh</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">aes</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">geom_point</span><span class="p">()</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">geom_line</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">pred</span><span class="p">),</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;#3366ff&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="./figure/glm-df-weight-1.png" alt="plot of chunk glm-df-weight"></p>
</section>
<section>
<h2 id="-poisson-regression-">🔰 Poisson regression 🌱</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">n</span> <span class="o">=</span> <span class="m">300L</span>
</span></span><span class="line"><span class="cl"><span class="n">a</span> <span class="o">=</span> <span class="m">3</span>
</span></span><span class="line"><span class="cl"><span class="n">b</span> <span class="o">=</span> <span class="m">-3</span>
</span></span><span class="line"><span class="cl"><span class="n">df_seeds</span> <span class="o">=</span> <span class="n">tibble</span><span class="o">::</span><span class="nf">tibble</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">body_mass</span> <span class="o">=</span> <span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="m">0.4</span><span class="p">,</span> <span class="m">1.7</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">num_seeds</span> <span class="o">=</span> <span class="nf">rpois</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nf">exp</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">body_mass</span> <span class="o">+</span> <span class="n">b</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nf">print</span><span class="p">()</span>
</span></span></code></pre></div><pre tabindex="0"><code>    body_mass num_seeds
  1 0.9185923         1
  2 0.5154446         0
  3 1.3362802         4
  4 1.6858125        11
 --                    
297 1.3407210         3
298 1.3357421         1
299 0.8928759         0
300 0.4583795         0
</code></pre>
</section>
<section>
<h2 id="-multiple-regression-">🔰 Multiple regression 🍺</h2>
<p>It requires minor tricks with <code>add_predictions()</code> to draw regression lines.<br>
Compromise with &ldquo;regression points&rdquo; for now.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">n</span> <span class="o">=</span> <span class="m">200L</span>
</span></span><span class="line"><span class="cl"><span class="n">true_coef</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">3</span><span class="p">,</span> <span class="m">0.05</span><span class="p">,</span> <span class="m">0.006</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_beer</span> <span class="o">=</span> <span class="n">tibble</span><span class="o">::</span><span class="nf">tibble</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">temperature</span> <span class="o">=</span> <span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="m">8</span><span class="p">,</span> <span class="m">32</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">humidity</span> <span class="o">=</span> <span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="m">20</span><span class="p">,</span> <span class="m">80</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">beer_sales</span> <span class="o">=</span> <span class="nf">rpois</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nf">exp</span><span class="p">(</span><span class="n">true_coef[1]</span> <span class="o">+</span> <span class="n">true_coef[2]</span> <span class="o">*</span> <span class="n">temperature</span> <span class="o">+</span> <span class="n">true_coef[3]</span> <span class="o">*</span> <span class="n">humidity</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nf">print</span><span class="p">()</span>
</span></span></code></pre></div><pre tabindex="0"><code>    temperature humidity beer_sales
  1    17.57401 54.68339         67
  2    10.13129 67.34727         55
  3    25.28517 40.93855        104
  4    31.73808 32.14308        113
 --                                
197    26.28116 41.89173        105
198    23.53532 73.12257        113
199    13.87494 41.92560         51
200    31.60519 61.47984        140
</code></pre>
</section>
<section>
<h2 id="-logistic-regression-hint-on-the-next-page-">🔰 Logistic regression (hint on the next page →)</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">sigmoid</span> <span class="o">=</span> <span class="kr">function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">gain</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span> <span class="p">{</span><span class="m">1</span> <span class="o">/</span> <span class="p">(</span><span class="m">1</span> <span class="o">+</span> <span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">gain</span> <span class="o">*</span> <span class="n">x</span><span class="p">))}</span>
</span></span><span class="line"><span class="cl"><span class="n">nrep</span> <span class="o">=</span> <span class="m">200L</span>
</span></span><span class="line"><span class="cl"><span class="n">n</span> <span class="o">=</span> <span class="m">10L</span>
</span></span><span class="line"><span class="cl"><span class="n">df_logistic</span> <span class="o">=</span> <span class="n">tibble</span><span class="o">::</span><span class="nf">tibble</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">x</span> <span class="o">=</span> <span class="nf">runif</span><span class="p">(</span><span class="n">nrep</span><span class="p">,</span> <span class="m">-10</span><span class="p">,</span> <span class="m">35</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">logit_p</span> <span class="o">=</span> <span class="m">-3</span> <span class="o">+</span> <span class="m">0.3</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="n">p</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">logit_p</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">y</span> <span class="o">=</span> <span class="nf">rbinom</span><span class="p">(</span><span class="n">nrep</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">response</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="n">y</span><span class="p">),</span> <span class="n">ncol</span> <span class="o">=</span> <span class="m">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nf">print</span><span class="p">()</span>
</span></span></code></pre></div><pre tabindex="0"><code>            x    logit_p          p  y response[,1] [,2]
  1  7.951271 -0.6146188 0.35100632  4            4    6
  2 -6.003840 -4.8011520 0.00815325  0            0   10
  3 22.409698  3.7229095 0.97640654 10           10    0
  4 34.508895  7.3526686 0.99935953 10           10    0
 --                                                     
197 24.277180  4.2831541 0.98638875 10           10    0
198 19.128721  2.7386162 0.93926720  8            8    2
199  1.015520 -2.6953441 0.06324865  0            0   10
200 34.259733  7.2779199 0.99930986 10           10    0
</code></pre>
</section>
<section>
<h2 id="hint-for-logistic-regression">Hint for Logistic regression</h2>
<p>Two types of response variables can be given to a formula:</p>
<ul>
<li>Integer vector: success 1, failure 0 (logistic regression in narrow sense)</li>
<li>Integer matrix: # of successes in 1st column, # of failures in 2nd column</li>
</ul>
<p>i.e., giving only # of success (<code>y</code>) results in an error:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="nf">glm</span><span class="p">(</span><span class="n">y</span> <span class="o">~</span> <span class="n">x</span><span class="p">,</span> <span class="n">df_logistic</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="n">binomial</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>Error in eval(family$initialize): y values must be 0 &lt;= y &lt;= 1
</code></pre><p>instead, the formula should be <code>response ~ x</code> to include failures as well.</p>
<p>(It also means the number of trials does not have to be constant.)</p>

</section>
<section>
<h2 id="-ancova-glm-with-qualitative--quantitative-vars">🔰 ANCOVA: GLM with qualitative + quantitative vars</h2>
<p>First, try ANOVA with only weather, then ANCOVA with temperature.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">n</span> <span class="o">=</span> <span class="m">200L</span>
</span></span><span class="line"><span class="cl"><span class="n">b</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">70</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">20</span><span class="p">,</span> <span class="m">-20</span><span class="p">)</span>  <span class="c1"># true coef</span>
</span></span><span class="line"><span class="cl"><span class="n">weather_levels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;sunny&#34;</span><span class="p">,</span> <span class="s">&#34;cloudy&#34;</span><span class="p">,</span> <span class="s">&#34;rainy&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_ancova</span> <span class="o">=</span> <span class="n">tibble</span><span class="o">::</span><span class="nf">tibble</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">temperature</span> <span class="o">=</span> <span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="m">8</span><span class="p">,</span> <span class="m">32</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">weather</span> <span class="o">=</span> <span class="nf">factor</span><span class="p">(</span><span class="nf">sample</span><span class="p">(</span><span class="n">weather_levels</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="kc">TRUE</span><span class="p">),</span> <span class="n">levels</span> <span class="o">=</span> <span class="n">weather_levels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="n">dplyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">weather</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="m">1L</span><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="n">tidyr</span><span class="o">::</span><span class="nf">pivot_wider</span><span class="p">(</span><span class="n">values_fill</span> <span class="o">=</span> <span class="m">0L</span><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="n">dplyr</span><span class="o">::</span><span class="nf">select</span><span class="p">(</span><span class="o">!</span><span class="n">cloudy</span><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="n">dplyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">mu</span> <span class="o">=</span> <span class="n">b[1]</span> <span class="o">+</span> <span class="n">b[2]</span> <span class="o">*</span> <span class="n">temperature</span> <span class="o">+</span> <span class="n">b[3]</span> <span class="o">*</span> <span class="n">sunny</span> <span class="o">+</span> <span class="n">b[4]</span> <span class="o">*</span> <span class="n">rainy</span><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="n">dplyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">beer_sales</span> <span class="o">=</span> <span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="m">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nf">print</span><span class="p">()</span>
</span></span></code></pre></div><pre tabindex="0"><code>    temperature weather sunny rainy        mu beer_sales
  1   23.377217  cloudy     0     0 140.13165  129.36288
  2   26.043088  cloudy     0     0 148.12926  138.26966
  3   30.830351  cloudy     0     0 162.49105  141.46190
  4   15.022311  cloudy     0     0 115.06693  108.18593
 --                                                     
197    8.277514  cloudy     0     0  94.83254   74.38321
198   28.675228   rainy     0     1 136.02568  140.34777
199   27.310881   rainy     0     1 131.93264  122.31587
200   24.064285   sunny     1     0 162.19286  144.89368
</code></pre>
</section>
<section>
<h2 id="-interaction">🔰 Interaction</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">n</span> <span class="o">=</span> <span class="m">200L</span>
</span></span><span class="line"><span class="cl"><span class="n">b</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">70</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">100</span><span class="p">,</span> <span class="m">-2</span><span class="p">)</span>  <span class="c1"># true coef</span>
</span></span><span class="line"><span class="cl"><span class="n">weather_levels</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;sunny&#34;</span><span class="p">,</span> <span class="s">&#34;rainy&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_interact</span> <span class="o">=</span> <span class="n">tibble</span><span class="o">::</span><span class="nf">tibble</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">temperature</span> <span class="o">=</span> <span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="m">8</span><span class="p">,</span> <span class="m">32</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">    <span class="n">weather</span> <span class="o">=</span> <span class="nf">factor</span><span class="p">(</span><span class="nf">sample</span><span class="p">(</span><span class="n">weather_levels</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="kc">TRUE</span><span class="p">),</span> <span class="n">levels</span> <span class="o">=</span> <span class="n">weather_levels</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="n">dplyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">weather</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="m">1L</span><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="n">tidyr</span><span class="o">::</span><span class="nf">pivot_wider</span><span class="p">(</span><span class="n">values_fill</span> <span class="o">=</span> <span class="m">0L</span><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="n">dplyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">mu</span> <span class="o">=</span> <span class="n">b[1]</span> <span class="o">*</span> <span class="n">sunny</span> <span class="o">+</span> <span class="n">b[2]</span> <span class="o">*</span> <span class="n">temperature</span> <span class="o">+</span> <span class="n">b[3]</span> <span class="o">*</span> <span class="n">rainy</span> <span class="o">+</span> <span class="n">b[4]</span> <span class="o">*</span> <span class="n">temperature</span> <span class="o">*</span> <span class="n">rainy</span><span class="p">)</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="n">dplyr</span><span class="o">::</span><span class="nf">mutate</span><span class="p">(</span><span class="n">beer_sales</span> <span class="o">=</span> <span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="m">10</span><span class="p">))</span> <span class="o">|&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nf">print</span><span class="p">()</span>
</span></span></code></pre></div><pre tabindex="0"><code>    temperature weather rainy sunny        mu beer_sales
  1   23.377217   rainy     1     0 123.37722   116.2995
  2   26.043088   rainy     1     0 126.04309   133.9018
  3   30.830351   rainy     1     0 130.83035   130.6798
  4   15.022311   rainy     1     0 115.02231   117.5620
 --                                                     
197    8.277514   sunny     0     1  94.83254   104.2573
198   28.675228   sunny     0     1 156.02568   155.3134
199   27.310881   rainy     1     0 127.31088   131.0297
200   24.064285   sunny     0     1 142.19286   142.8241
</code></pre>
</section>
<section>
<h2 id="one-data-many-possible-models">One data, many possible models</h2>
<p>How can we choose?</p>
<ol>
<li>Based on underlying mechanisms
<ul>
<li>Poisson if <strong>count</strong> data, Gamma if <strong>interval</strong> data, from Poisson process.</li>
<li>Binomial if <strong>proportional count</strong> like &ldquo;k in n times&rdquo;.</li>
</ul>
</li>
<li>Visualize the data, and choose one with similar shape.
<ul>
<li>Normal distribution if <strong>symmetric</strong></li>
<li>Gamma if <strong>always positive</strong></li>
<li>straight, exponential, plateaued, etc.</li>
</ul>
</li>
</ol>
<p>There should be some measures for goodness-of-fit&hellip;</p>

</section>
<section>
<h2 id="likelihood-a-measure-for-goodness-of-fit">Likelihood: a measure for goodness-of-fit</h2>
<p>The probability to observe the data $D$ given the model $M$.<br>
$\Pr(D \mid M)$</p>
<p><strong>Likelihood function</strong> is the same probability from different viewpoints:</p>
<ul>
<li>as a function of model $M$ given the data $D$,<br>
$L(M \mid D)$<br></li>
<li>as a function of parameters $\theta$,<br>
$L(\theta \mid D)$ or $L(\theta)$</li>
</ul>
<hr>
<p>Compare maximum likelihood of competing models:<br>
$\log L^* (M_1) \text{ vs. } \log L^* (M_2) \text{ vs. } \log L^* (M_3) \ldots$</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">broom</span><span class="o">::</span><span class="nf">glance</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>  null.deviance df.null    logLik      AIC      BIC deviance df.residual nobs
1      1305.043      49 -124.9298 255.8597 261.5957 433.2606          48   50
</code></pre>
</section>
<section>
<h2 id="the-better-fit-the-higher-likelihood">The better fit, the higher likelihood</h2>
<p>OK, makes sense in this case:</p>
<p><img src="./figure/compare-loglik-1.png" alt="plot of chunk compare-loglik"></p>
<p>Should we continue searching for models with higher likelihood?</p>

</section>
<section>
<h2 id="higher-likelihood-by-adding-a-useless-parameter">Higher likelihood by adding a useless parameter</h2>
<p>The number of seeds $y$ increases with the increasing body mass $x$.<br>
Adding a variable $x_2$, sox color of the observer, improves likelihood&hellip;&hellip;?</p>
<p><img src="./figure/many-models-1.png" alt="plot of chunk many-models"></p>

</section>
<section>
<h2 id="best-fit-model-does-not-fit-for-our-purpose">Best fit model does not fit for our purpose</h2>
<dl>
<dt>Overfitting</dt>
<dd>Too many parameters leads to fitting too closely <strong>to the dataset</strong>.<br>
→ poor generalization on unseen data<br>
→ useless for prediction and understanding</dd>
</dl>
<p><img src="./figure/saturated-model-1.png" alt="plot of chunk saturated-model"></p>
<p><strong>null model</strong>: only intersect; without explanatory variable.<br>
<strong>saturated model</strong>: # parameters ≥ # data points; just like connecting points.</p>

</section>
<section>
<h2 id="aic-akaike-information-criterion">AIC: Akaike Information Criterion</h2>
<p>\[\begin{split}
\text{AIC} = -2 (\log L^* - k) = -2 \log L^* + 2k
\end{split}\]</p>
<ul>
<li><strong>The model with the minimum AIC is preferred</strong>
<ul>
<li>higher likelihood $L$.</li>
<li>smaller number of parameters $k$</li>
</ul>
</li>
<li>Goodness of fit to which data?
<ul>
<li>$\log L^*$ is for the given dataset.</li>
<li>$(\log L^* - k)$ is the unbiased estimate of mean log likelihood to the future data generated by true mechanism.
(derived from Kullback&ndash;Leibler divergence)</li>
</ul>
</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">broom</span><span class="o">::</span><span class="nf">glance</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>  null.deviance df.null    logLik      AIC      BIC deviance df.residual nobs
1      1305.043      49 -124.9298 255.8597 261.5957 433.2606          48   50
</code></pre>
</section>
<section>
<h2 id="higher-aic-by-adding-a-useless-parameter">Higher AIC by adding a useless parameter</h2>
<p>The number of seeds $y$ increases with the increasing body mass $x$.<br>
Adding a variable $x_2$, sox color of the observer, brings larger AIC.</p>
<p><img src="./figure/many-models-aic-1.png" alt="plot of chunk many-models-aic"></p>

</section>
<section>
<h2 id="other-information-criteria">Other information criteria</h2>
<ul>
<li>$\text{BIC} = -2 \log L^* + k \log n$
<ul>
<li>Similar to AIC: penalizes for parameters $k$.</li>
<li>Different from AIC: depends on sample size $n$.<br>
(AIC lacks penalty by sample size.)</li>
<li>(derived from maximization of marginal likelihood)</li>
</ul>
</li>
<li><a href="http://watanabe-www.math.dis.titech.ac.jp/users/swatanab/waicwbic_e.html">WAIC and WBIC</a>
<ul>
<li>Widely Applicable variants of AIC and BIC.</li>
<li>WAIC for better prediction. WBIC for identifying the true model.</li>
</ul>
</li>
</ul>

</section>
<section>
<h2 id="model-selection-by-information-criteria">Model selection by information criteria</h2>
<p>does not select the &ldquo;right&rdquo; one;<br>
selects useful one for prediction and understanding.</p>
<blockquote>
<p>All models are wrong, but some are useful. &mdash; George E. P. Box</p>
</blockquote>
<figure>
<img src="../english2023r/image/math-model.drawio.svg" width="900"><br>
<figcaption><cite>「データ分析のための数理モデル入門」江崎貴裕 2020 より改変</cite></figcaption>
</figure>

</section>
<section>
<h2 id="pitfalls-and-notes">Pitfalls and notes</h2>
<ul>
<li>Multicollinearity:
<ul>
<li>Correlated explanatory variables cause problems.</li>
</ul>
</li>
<li>Variable transformation should be avoided:
<ul>
<li>Log transformation is often useful, though.</li>
<li>Divided numbers are dangerous.</li>
</ul>
</li>
<li>Interaction makes interpretation difficult dramatically.</li>
</ul>

</section>
<section>
<h2 id="steps-to-generalized-linear-model-glm">Steps to Generalized Linear Model (GLM)</h2>
<ul>
<li>Above all, visualize the data to get a whole picture.</li>
<li>Select <strong>variables</strong>, probabitlity <strong>distribution</strong>, and <strong>link</strong> function.</li>
<li>Estimate parameters.</li>
<li>Compare models with information criteria.</li>
</ul>

</section>
<section>
<h2 id="penguins-dataset">penguins dataset</h2>
<a href="https://allisonhorst.github.io/palmerpenguins/">
<cite>https://allisonhorst.github.io/palmerpenguins/</cite><br>
<img src="/slides/image/rstats/lter_penguins.png" width="45%">
<img src="/slides/image/rstats/culmen_depth.png" width="45%">
</a>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="nf">install.packages</span><span class="p">(</span><span class="s">&#34;palmerpenguins&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">palmerpenguins</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">penguins_colors</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">Adelie</span> <span class="o">=</span> <span class="s">&#34;darkorange&#34;</span><span class="p">,</span> <span class="n">Chinstrap</span> <span class="o">=</span> <span class="s">&#34;purple&#34;</span><span class="p">,</span> <span class="n">Gentoo</span> <span class="o">=</span> <span class="s">&#34;cyan4&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">print</span><span class="p">(</span><span class="n">penguins</span><span class="p">)</span>
</span></span></code></pre></div>
</section>
<section>
<h2 id="penguins-dataset">penguins dataset</h2>
<a href="https://allisonhorst.github.io/palmerpenguins/">
<cite>https://allisonhorst.github.io/palmerpenguins/</cite><br>
<img src="/slides/image/rstats/lter_penguins.png" width="45%">
<img src="/slides/image/rstats/culmen_depth.png" width="45%">
</a>
<pre tabindex="0"><code>      species    island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g    sex year
  1    Adelie Torgersen           39.1          18.7               181        3750   male 2007
  2    Adelie Torgersen           39.5          17.4               186        3800 female 2007
  3    Adelie Torgersen           40.3          18.0               195        3250 female 2007
  4    Adelie Torgersen             NA            NA                NA          NA     NA 2007
 --                                                                                           
341 Chinstrap     Dream           43.5          18.1               202        3400 female 2009
342 Chinstrap     Dream           49.6          18.2               193        3775   male 2009
343 Chinstrap     Dream           50.8          19.0               210        4100   male 2009
344 Chinstrap     Dream           50.2          18.7               198        3775 female 2009
</code></pre>
</section>
<section>
<h2 id="remove-rows-with-missing-values-first">Remove rows with missing values first</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">penguins</span> <span class="o">|&gt;</span> <span class="n">dplyr</span><span class="o">::</span><span class="nf">filter</span><span class="p">(</span><span class="n">dplyr</span><span class="o">::</span><span class="nf">if_any</span><span class="p">(</span><span class="nf">everything</span><span class="p">(),</span> <span class="n">is.na</span><span class="p">))</span>
</span></span></code></pre></div><pre tabindex="0"><code>   species    island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex year
 1  Adelie Torgersen             NA            NA                NA          NA  NA 2007
 2  Adelie Torgersen           34.1          18.1               193        3475  NA 2007
 3  Adelie Torgersen           42.0          20.2               190        4250  NA 2007
 4  Adelie Torgersen           37.8          17.1               186        3300  NA 2007
--                                                                                      
 8  Gentoo    Biscoe           46.2          14.4               214        4650  NA 2008
 9  Gentoo    Biscoe           47.3          13.8               216        4725  NA 2009
10  Gentoo    Biscoe           44.5          15.7               217        4875  NA 2009
11  Gentoo    Biscoe             NA            NA                NA          NA  NA 2009
</code></pre><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">penguins_dropna</span> <span class="o">=</span> <span class="n">penguins</span> <span class="o">|&gt;</span> <span class="n">tidyr</span><span class="o">::</span><span class="nf">drop_na</span><span class="p">(</span><span class="n">body_mass_g</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">dim</span><span class="p">(</span><span class="n">penguins_dropna</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>[1] 342   8
</code></pre>
</section>
<section>
<h2 id="-practice-glm-with-penguins">🔰 Practice GLM with penguins</h2>
<p>Try doing by yourself first.
Example code follows.</p>
<ol>
<li>Plot with <code>x = body_mass_g</code>, <code>y = flipper_length_mm</code>.</li>
<li>Get the slope and intersect with simple linear regression, and plot it.</li>
<li>Color-code points with <code>species</code>.</li>
<li>Perform multiple regression with additional <code>species</code>, and plot it.</li>
<li>Apply the same analysis to bill shapes.</li>
</ol>
</section>
<section>
<h2 id="simple-regression-1-plot-data">Simple regression: 1. Plot data</h2>
<p>The heavier body, the longer flipper.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">p_penweight</span> <span class="o">=</span> <span class="nf">ggplot</span><span class="p">(</span><span class="n">penguins_dropna</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">aes</span><span class="p">(</span><span class="n">body_mass_g</span><span class="p">,</span> <span class="n">flipper_length_mm</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">geom_point</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="m">16</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="m">0.66</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">theme_bw</span><span class="p">(</span><span class="n">base_size</span> <span class="o">=</span> <span class="m">20</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">theme</span><span class="p">(</span><span class="n">panel.grid.minor</span> <span class="o">=</span> <span class="nf">element_blank</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="n">p_penweight</span>
</span></span></code></pre></div><p><img src="./figure/penguins-weight-1.png" alt="plot of chunk penguins-weight"></p>

</section>
<section>
<h2 id="simple-regression-2-fit">Simple regression: 2. Fit</h2>
<p>Use normal distribution and identity link by default.
$y = 136.7 + 0.0153 x$</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">fit1</span> <span class="o">=</span> <span class="nf">glm</span><span class="p">(</span><span class="n">flipper_length_mm</span> <span class="o">~</span> <span class="n">body_mass_g</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">penguins_dropna</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">broom</span><span class="o">::</span><span class="nf">tidy</span><span class="p">(</span><span class="n">fit1</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>         term     estimate   std.error statistic       p.value
1 (Intercept) 136.72955927 1.996835406  68.47312 5.712947e-201
2 body_mass_g   0.01527592 0.000466836  32.72223 4.370681e-107
</code></pre><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">broom</span><span class="o">::</span><span class="nf">glance</span><span class="p">(</span><span class="n">fit1</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>  null.deviance df.null    logLik      AIC     BIC deviance df.residual nobs
1      67426.54     341 -1145.518 2297.035 2308.54  16250.3         340  342
</code></pre>
</section>
<section>
<h2 id="simple-regression-3-plot-the-fitting-result">Simple regression: 3. Plot the fitting result</h2>
<p>Draw the regression line with the predicted values.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">added1</span> <span class="o">=</span> <span class="n">modelr</span><span class="o">::</span><span class="nf">add_predictions</span><span class="p">(</span><span class="n">penguins_dropna</span><span class="p">,</span> <span class="n">fit1</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;response&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p1</span> <span class="o">=</span> <span class="n">p_penweight</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">geom_line</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">pred</span><span class="p">),</span> <span class="n">data</span> <span class="o">=</span> <span class="n">added1</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;#3366ff&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p1</span>
</span></span></code></pre></div><p><img src="./figure/penguins-weight-glm-1.png" alt="plot of chunk penguins-weight-glm"></p>

</section>
<section>
<h2 id="multiple-regression-1-plot-data">Multiple regression: 1. Plot data</h2>
<p>Color-code points by species.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">p_penweight_color</span> <span class="o">=</span> <span class="n">p_penweight</span> <span class="o">+</span> <span class="nf">aes</span><span class="p">(</span><span class="n">color</span> <span class="o">=</span> <span class="n">species</span><span class="p">)</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">scale_color_manual</span><span class="p">(</span><span class="n">values</span> <span class="o">=</span> <span class="n">penguins_colors</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p_penweight_color</span>
</span></span></code></pre></div><p><img src="./figure/penguins-weight-sp-1.png" alt="plot of chunk penguins-weight-sp"></p>

</section>
<section>
<h2 id="multiple-regression-2-fit">Multiple regression: 2. Fit</h2>
<p>Chinstrap and Gentoo have longer flippers compared to Adelie.<br>
The effect of body mass is smaller than that of simple regression (0.0153).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">fit2</span> <span class="o">=</span> <span class="nf">glm</span><span class="p">(</span><span class="n">flipper_length_mm</span> <span class="o">~</span> <span class="n">body_mass_g</span> <span class="o">+</span> <span class="n">species</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">penguins_dropna</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">broom</span><span class="o">::</span><span class="nf">tidy</span><span class="p">(</span><span class="n">fit2</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>              term     estimate    std.error statistic       p.value
1      (Intercept) 1.588603e+02 2.3865766963 66.564071 2.450113e-196
2      body_mass_g 8.402113e-03 0.0006338976 13.254686  1.401600e-32
3 speciesChinstrap 5.597440e+00 0.7882166229  7.101398  7.334777e-12
4    speciesGentoo 1.567747e+01 1.0906590679 14.374308  6.800823e-37
</code></pre><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">broom</span><span class="o">::</span><span class="nf">glance</span><span class="p">(</span><span class="n">fit2</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>  null.deviance df.null    logLik      AIC      BIC deviance df.residual nobs
1      67426.54     341 -1059.718 2129.437 2148.611 9839.073         338  342
</code></pre>
</section>
<section>
<h2 id="multiple-regression-3-plot-the-fitting-result">Multiple regression: 3. Plot the fitting result</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">added2</span> <span class="o">=</span> <span class="n">modelr</span><span class="o">::</span><span class="nf">add_predictions</span><span class="p">(</span><span class="n">penguins_dropna</span><span class="p">,</span> <span class="n">fit2</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;response&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p2</span> <span class="o">=</span> <span class="n">p_penweight_color</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">geom_line</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">pred</span><span class="p">),</span> <span class="n">data</span> <span class="o">=</span> <span class="n">added2</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p2</span>
</span></span></code></pre></div><p><img src="./figure/penguins-weight-sp-glm-1.png" alt="plot of chunk penguins-weight-sp-glm"></p>
<p><strong>slope</strong> may vary by species. Let&rsquo;s try adding <strong>interaction</strong> to the model.</p>

</section>
<section>
<h2 id="interaction-fit">Interaction: Fit</h2>
<p>Chinstrap has larger slope than the others.<br>
Now it is difficult to interpret the difference in intersects.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">fit3</span> <span class="o">=</span> <span class="nf">glm</span><span class="p">(</span><span class="n">flipper_length_mm</span> <span class="o">~</span> <span class="n">body_mass_g</span> <span class="o">*</span> <span class="n">species</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">penguins_dropna</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">broom</span><span class="o">::</span><span class="nf">tidy</span><span class="p">(</span><span class="n">fit3</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>                          term      estimate    std.error statistic       p.value
1                  (Intercept) 165.244812649 3.5508916651 46.536146 1.561669e-148
2                  body_mass_g   0.006676867 0.0009522935  7.011354  1.301783e-11
3             speciesChinstrap -13.863939075 7.3012647809 -1.898841  5.844186e-02
4                speciesGentoo   6.059375933 6.0508813200  1.001404  3.173522e-01
5 body_mass_g:speciesChinstrap   0.005228197 0.0019486293  2.683013  7.657147e-03
6    body_mass_g:speciesGentoo   0.002362269 0.0013525781  1.746494  8.163897e-02
</code></pre><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">broom</span><span class="o">::</span><span class="nf">glance</span><span class="p">(</span><span class="n">fit3</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>  null.deviance df.null    logLik      AIC      BIC deviance df.residual nobs
1      67426.54     341 -1055.711 2125.422 2152.265 9611.166         336  342
</code></pre>
</section>
<section>
<h2 id="interaction-plot-the-fitting-result">Interaction: Plot the fitting result</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">added3</span> <span class="o">=</span> <span class="n">modelr</span><span class="o">::</span><span class="nf">add_predictions</span><span class="p">(</span><span class="n">penguins_dropna</span><span class="p">,</span> <span class="n">fit3</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;response&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p3</span> <span class="o">=</span> <span class="n">p_penweight_color</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">geom_line</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">pred</span><span class="p">),</span> <span class="n">data</span> <span class="o">=</span> <span class="n">added3</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p3</span>
</span></span></code></pre></div><p><img src="./figure/penguins-interaction-1.png" alt="plot of chunk penguins-interaction"></p>
</section>
<section>
<h2 id="which-is-the-best-of-three">Which is the best of three?</h2>
<p>According to AIC, &ldquo;multiple regression with interaction&rdquo; is the best.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">labels</span> <span class="o">=</span> <span class="nf">sprintf</span><span class="p">(</span><span class="s">&#34;AIC = %.1f&#34;</span><span class="p">,</span> <span class="nf">AIC</span><span class="p">(</span><span class="n">fit1</span><span class="p">,</span> <span class="n">fit2</span><span class="p">,</span> <span class="n">fit3</span><span class="p">)</span><span class="o">$</span><span class="n">AIC</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cowplot</span><span class="o">::</span><span class="nf">plot_grid</span><span class="p">(</span><span class="n">p1</span> <span class="o">+</span> <span class="nf">labs</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="n">labels[1]</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                   <span class="n">p2</span> <span class="o">+</span> <span class="nf">labs</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="n">labels[2]</span><span class="p">)</span> <span class="o">+</span> <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;none&#34;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                   <span class="n">p3</span> <span class="o">+</span> <span class="nf">labs</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="n">labels[3]</span><span class="p">)</span> <span class="o">+</span> <span class="nf">theme</span><span class="p">(</span><span class="n">legend.position</span> <span class="o">=</span> <span class="s">&#34;none&#34;</span><span class="p">),</span> <span class="n">nrow</span> <span class="o">=</span> <span class="m">1L</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="./figure/penguins-aic-1.png" alt="plot of chunk penguins-aic"></p>

</section>
<section>
<h2 id="additional-practice">Additional practice</h2>
<p>🔰 Repeat the same steps with different data: bill length and depth.</p>
<p><img src="./figure/penguins-bill-1.png" alt="plot of chunk penguins-bill"></p>

</section>
<section>
<h2 id="-final-challenge-analyze-public-datasets">🔰 Final challenge: Analyze public datasets</h2>
<ul>
<li><a href="https://www.e-stat.go.jp/">e-Stat</a>: 政府統計の総合窓口</li>
<li><a href="https://www.data.go.jp/data/dataset?res_format=CSV">data.go.jp データカタログサイト</a>: 中央省庁</li>
<li><a href="https://odcs.bodik.jp/">BODIKオープンデータカタログサイト</a>: 地方自治体</li>
<li><a href="https://www.data.jma.go.jp/gmd/risk/obsdl/index.php">気象庁</a></li>
<li><a href="https://www.data.gov/">DATA.GOV</a>: U.S. Government’s open data</li>
<li>anything else.</li>
</ul>

</section>
<section>
<h2 id="you-have-developed-skills-for-data-analysis">You have developed skills for data analysis</h2>
<ol>
<li>Setup computer environment ✅ day 1</li>
<li>Get and read input data ✅ day 6</li>
<li>Exploratory data analysis
<ul>
<li><strong>Preparation</strong> (harder than it seems) ✅ day 3&ndash;5</li>
<li><strong>Visualization</strong>, generating hypotheses (fun!) ✅ day 2</li>
<li><strong>Statistical analysis</strong>, testing hypotheses ✅ day 7&ndash;8</li>
</ul>
</li>
<li>Report ✅ day 2</li>
</ol>
<figure>
<a href="https://r4ds.hadley.nz/intro">
<img src="/slides/image/r4ds/data-science.png" width="720">
<figcaption class="url">https://r4ds.hadley.nz/intro</figcaption>
</a>
</figure>

</section>
<section>
<h2 id="purposes-of-this-hands-on-lectures">Purposes of this hands-on lectures</h2>
<h3 id="-every-biological-research-involves-data-and-models">✅ Every biological research involves data and models</h3>
<h3 id="-you-want-to-do-reproducible-analysis">✅ You want to do reproducible analysis</h3>
<h3 id="-learn-how-to-do-it-and-how-to-learn-more">✅ Learn how to do it and how to learn more</h3>
<h3 id="-glance-at-the-basics-of-data-analysis">✅ Glance at the basics of data analysis</h3>
<hr>
<p>You don&rsquo;t have to remember every command.<br>
Just repeat forgetting and searching.</p>
</section>
<section>
<h2 id="reference">Reference</h2>
<dl>
<dt>R for Data Science &mdash; Hadley Wickham et al.</dt>
<dd><a href="https://r4ds.hadley.nz">https://r4ds.hadley.nz</a>,
<a href="https://amzn.to/4cpL6w8">Paperback</a>,
<a href="https://amzn.to/2yyFRKt">日本語版書籍</a></dd>
<dt>Official documents:</dt>
<dd><a href="https://www.tidyverse.org/">tidyverse</a>,
<a href="https://ggplot2.tidyverse.org/">ggplot2</a>,
<a href="https://dplyr.tidyverse.org/">dplyr</a>,
<a href="https://tidyr.tidyverse.org/">tidyr</a>,
<a href="https://stringr.tidyverse.org/">stringr</a>,
<a href="https://readr.tidyverse.org/">readr</a></dd>
</dl>
<ul>
<li><a href="https://amzn.to/33suMIZ">データ解析のための統計モデリング入門</a> 久保拓弥 2012</li>
<li><a href="https://amzn.to/3uCxTKo">データ分析のための数理モデル入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3uznzCK">分析者のためのデータ解釈学入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3ty80Kv">統計学を哲学する</a> 大塚淳 2020</li>
<li><a href="https://amzn.to/2Q0f6JQ">科学とモデル&mdash;シミュレーションの哲学 入門</a> Michael Weisberg 2017<br>
(原著: <a href="https://amzn.to/3bdvhuI">Simulation and Similarity</a> 2013)</li>
</ul>
<a href="." class="readmore">
Go back to index
</a>

</section>
</div>
</div>
</body>
</html>
