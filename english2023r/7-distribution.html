<!DOCTYPE html>
<html>
<head prefix="og: http://ogp.me/ns#">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<title>7. Statistical modeling 1: probability distribution, likelihood — Hands-on Introduction to R 2023</title>
<meta name="author" content="Watal M. Iwasaki">
<meta property="og:title" content="7. Statistical modeling 1: probability distribution, likelihood — Hands-on Introduction to R 2023">
<meta property="og:type" content="article">
<meta property="og:url" content="https://heavywatal.github.io/slides/english2023r/7-distribution.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/heavywatal">
<meta property="og:description" content="">
<meta property="og:site_name" content="Slide decks — Heavy Watal">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@heavywatal">
<meta name="twitter:creator" content="@heavywatal">
<link rel="stylesheet" href="/lib/katex/katex.min.css">
<script defer src="/lib/katex/katex.min.js"></script>
<script defer src="/lib/katex/contrib/auto-render.min.js"></script>
<script>
document.addEventListener("DOMContentLoaded", function() {
  renderMathInElement(document.body, {
    delimiters: [
      {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false}
    ]
  });
});
</script>
<style>
.katex {
  font-size: 1.12em;
}

.katex-display > .katex {
  text-align: left;
  padding-left: 2rem;
}
</style>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-V60H2JH0G6"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-V60H2JH0G6', { 'anonymize_ip': false });
}
</script>
<link rel="stylesheet" href="/slides/lib/reveal.js/reveal.css">
<script defer src="/slides/lib/reveal.js/reveal.js"></script>
<script defer src="/slides/lib/reveal.js/plugin/notes/notes.js"></script>
<script defer src="/slides/lib/reveal.js/plugin/search/search.js"></script>
<script defer src="/slides/lib/reveal-initialize.js"></script>
<script>
window.addEventListener('DOMContentLoaded', function() {
  Reveal.configure({width: 1440, height: 1080});
  document.querySelector('html').style.fontSize = '240%';
})
</script>
<script defer src="/slides/lib/reload-img-onclick.js"></script>
<link rel="stylesheet" href="/slides/css/style-reveal.css">
<link rel="stylesheet" href="style.css">
</head>
<body>
<div class="reveal">
<div class="slides">
<section>
<h1 id="hands-on-introduction-to-r-2023"><a href=".">Hands-on Introduction to R 2023</a></h1>
<div class="author">
岩嵜 航 (Watal M. Iwasaki, PhD)
</div>
<div class="affiliation">
Graduate School of Life Sciences, Tohoku University
</div>
<ol>
<li><a href="1-introduction.html">Introduction: what is data analysis and R basics</a>
<li><a href="2-visualization.html">Data visualization and reporting</a>
<li><a href="3-structure1.html">Data transformation 1: extract, summarize</a>
<li><a href="4-structure2.html">Data transformation 2: join, pivot</a>
<li><a href="5-content.html">Data cleansing and conversion: numbers, text</a>
<li><a href="6-input.html">Data input and interpretation</a>
<li class="current-deck"><a href="7-distribution.html">Statistical modeling 1: probability distribution, likelihood</a>
<li><a href="8-glm.html">Statistical modeling 2: linear regression</a>
</ol>
<div class="footnote">
2023-12-05 Tohoku University<br>
<a href="https://heavywatal.github.io/slides/english2023r/">https://heavywatal.github.io/slides/english2023r/</a>
</div>

</section>
<section>
<h2 id="purposes-of-this-hands-on-lectures">Purposes of this hands-on lectures</h2>
<h3 id="-delevery-biological-research-involves-data-and-modelsdel">✅ <del>Every biological research involves data and models</del></h3>
<h3 id="-delyou-want-to-do-reproducible-analysisdel">✅ <del>You want to do reproducible analysis</del></h3>
<h3 id="-dellearn-how-to-do-it-and-how-to-learn-moredel">✅ <del>Learn how to do it and how to learn more</del></h3>
<h3 id="-glance-at-the-basics-of-data-analysis">⬜ Glance at the basics of data analysis</h3>
<hr>
<p>You don&rsquo;t have to remember every command.<br>
Just repeat forgetting and searching.
</section>
<section>
<h2 id="what-do-you-want-to-do-with-data">What do you want to do with data?</h2>
<ul>
<li>to <strong>understand</strong> phenomena</li>
<li>to <strong>predict</strong> future</li>
<li>to <strong>classify</strong> objects</li>
<li>to <strong>control</strong> behavior</li>
<li>to <strong>generate</strong> something new</li>
</ul>
<p>Is analysis necessary for that?<br>
Why not just raw data?
</section>
<section>
<h2 id="look-back-day-1">Look back day 1</h2>
<iframe width="600" height="450" src="./1-introduction.html#/4"></iframe>
<iframe width="600" height="450" src="./1-introduction.html#/5"></iframe>
<iframe width="600" height="450" src="./1-introduction.html#/6"></iframe>
<iframe width="600" height="450" src="./1-introduction.html#/7"></iframe>
</section>
<section>
<h2 id="mathematical-models-in-data-science">Mathematical models in data science</h2>
<p>Mathematical expression of assumptions to simulate data generation<br>
e.g., the larger the more expensive: $\text{price} = A \times \text{carat} + B + \epsilon$</p>
<p><img src="./figure/lm-diamonds-1.png" alt="plot of chunk lm-diamonds"></p>
<dl>
<dt>Regression</dt>
<dd>express y as a function of x.</dd>
</dl>

</section>
<section>
<h2 id="extending-linear-regression">Extending linear regression</h2>
<figure style="float: right;">
<a href="https://kuboweb.github.io/-kubo/ce/IwanamiBook.html">
<img src="../tokiomarine2021/image/kubo-book.jpg" width="280" alt="データ解析のための統計モデリング入門 久保拓弥 2012">
</a>
</figure>
<p><strong>Linear Model (LM)</strong> 👈 #7 today</p>
<p><span style="color: #888888;">    ↓ probability distribution</span></p>
<p><strong>Generalized Linear Model (GLM)</strong> <a href="8-glm.html">&mdash; #8 next time</a></p>
<p><span style="color: #888888;">    ↓ individual difference, random effect</span></p>
<p><strong>Generalized Linear Mixed Model (GLMM)</strong></p>
<p><span style="color: #888888;">    ↓ flexible modelling</span></p>
<p><strong>Hierarchical Bayesian Model (HBM)</strong></p>
<p><cite><a href="https://amzn.to/33suMIZ">データ解析のための統計モデリング入門</a> 久保拓弥 2012 より改変</cite></p>

</section>
<section>
<h2 id="two-parts-to-a-regression-model">Two parts to a regression model</h2>
<ol>
<li>
<p>Define a <strong>family of models</strong>: express generic pattern</p>
<ul>
<li>straight line: $y = a_1 + a_2 x$</li>
<li>log curve: $\log(y) = a_1 + a_2 x$</li>
<li>quadratic curve: $y = a_1 + a_2 x^2$</li>
</ul>
</li>
<li>
<p>Generate a <strong>fitted model</strong>: adjust parameters to get closer to the data</p>
<ul>
<li>$y = 3x + 7$</li>
<li>$y = 9x^2$</li>
</ul>
</li>
</ol>
<cite>
<a href="https://r4ds.had.co.nz/model-basics.html" class="url">https://r4ds.had.co.nz/model-basics.html</a>
</cite>
</section>
<section>
<h2 id="can-see-a-strong-pattern-the-taller-the-heavier">Can see a strong pattern: the taller the heavier</h2>
<p>The relationship looks linear, $y = a x + b$.<br>
 </p>
<p><img src="./figure/weight-height-1.png" alt="plot of chunk weight-height"></p>

</section>
<section>
<h2 id="can-see-a-strong-pattern-the-taller-the-heavier">Can see a strong pattern: the taller the heavier</h2>
<p>The relationship looks linear, $y = a x + b$.<br>
OK, let&rsquo;s try random slope <em>a</em> and intersect <em>b</em>:</p>
<p><img src="./figure/weight-lines-1.png" alt="plot of chunk weight-lines"></p>
<p>Need to find a good slope and intersect.</p>

</section>
<section>
<h2 id="ordinary-least-square-ols">Ordinary Least Square (OLS)</h2>
<p>minimizes the <strong style="color: #E69F00">residual</strong> sum of squares (RSS)
from <span style="color: #3366ff">the regression line</span>.</p>
<p><img src="./figure/weight-residual-1.png" alt="plot of chunk weight-residual"></p>

</section>
<section>
<h2 id="searching-for-models-to-minimize-rss">Searching for models to minimize RSS</h2>
<p>Try random values, and pick the best ones.<br>
May need to generate much more to find good one.</p>
<p><img src="./figure/weight-goodlines-1.png" alt="plot of chunk weight-goodlines"></p>

</section>
<section>
<h2 id="searching-for-models-to-minimize-rss">Searching for models to minimize RSS</h2>
<p><strong>Grid search</strong>: generate an evenly spaced grid of points.<br>
Slightly more efficient than random search?</p>
<p><img src="./figure/weight-grid-1.png" alt="plot of chunk weight-grid"></p>
<p>There are many other <strong>optimization</strong> techniques although not covered here.</p>

</section>
<section>
<h2 id="r-can-find-the-optimum-in-an-instant">R can find the optimum in an instant</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">par_init</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="n">intercept</span> <span class="o">=</span> <span class="m">0</span><span class="p">,</span> <span class="n">slope</span> <span class="o">=</span> <span class="m">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span> <span class="o">=</span> <span class="nf">optim</span><span class="p">(</span><span class="n">par_init</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">rss_weight</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">df_weight</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span><span class="o">$</span><span class="n">par</span>
</span></span></code></pre></div><pre tabindex="0"><code>intercept     slope 
-69.68394  78.53490 
</code></pre><p><img src="./figure/weight-lm-1.png" alt="plot of chunk weight-lm"></p>
<p>The code above is for general optimization.<br>
For simple linear regression, an easier way is as follows&hellip;</p>

</section>
<section>
<h2 id="lm-function-to-fit-linear-models"><code>lm()</code> function to fit linear models</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">fit</span> <span class="o">=</span> <span class="nf">lm</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">mpg</span><span class="p">,</span> <span class="n">formula</span> <span class="o">=</span> <span class="n">hwy</span> <span class="o">~</span> <span class="n">displ</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">broom</span><span class="o">::</span><span class="nf">tidy</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>         term  estimate std.error statistic       p.value
1 (Intercept) 35.697651 0.7203676  49.55477 2.123519e-125
2       displ -3.530589 0.1945137 -18.15085  2.038974e-46
</code></pre><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">mpg_added</span> <span class="o">=</span> <span class="n">modelr</span><span class="o">::</span><span class="nf">add_predictions</span><span class="p">(</span><span class="n">mpg</span><span class="p">,</span> <span class="n">fit</span><span class="p">,</span> <span class="n">type</span> <span class="o">=</span> <span class="s">&#34;response&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">ggplot</span><span class="p">(</span><span class="n">mpg_added</span><span class="p">)</span> <span class="o">+</span> <span class="nf">aes</span><span class="p">(</span><span class="n">displ</span><span class="p">,</span> <span class="n">hwy</span><span class="p">)</span> <span class="o">+</span> <span class="nf">geom_point</span><span class="p">()</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">  <span class="nf">geom_line</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">pred</span><span class="p">),</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">&#34;#3366ff&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="./figure/lm-mpg-1.png" alt="plot of chunk lm-mpg"></p>
<p>🔰 Try <code>lm()</code> with <code>diamonds</code> and <code>iris</code>.</p>

</section>
<section>
<h2 id="straight-lm-does-not-fit-all">Straight LM does not fit all</h2>
<p><img src="./figure/lm-bad-1.png" alt="plot of chunk lm-bad"></p>
<ul>
<li>Prediction goes below zero whereas all the observations are <strong>positive</strong>.</li>
<li>Y values are <strong>integer</strong>. Their <strong>dispersion</strong> is larger when X is larger.</li>
</ul>

</section>
<section>
<h2 id="straight-lm-does-not-fit-all">Straight LM does not fit all</h2>
<p><img src="./figure/glm-better-1.png" alt="plot of chunk glm-better"></p>
<ul>
<li>Prediction goes below zero whereas all the observations are <strong>positive</strong>.</li>
<li>Y values are <strong>integer</strong>. Their <strong>dispersion</strong> is larger when X is larger.</li>
<li>Let&rsquo;s learn statistical modelling for better fitting to the data.</li>
</ul>

</section>
<section>
<h2 id="extending-linear-regression">Extending linear regression</h2>
<figure style="float: right;">
<a href="https://kuboweb.github.io/-kubo/ce/IwanamiBook.html">
<img src="../tokiomarine2021/image/kubo-book.jpg" width="280" alt="データ解析のための統計モデリング入門 久保拓弥 2012">
</a>
</figure>
<p><strong>Linear Model (LM)</strong> 👈 #7 today</p>
<p><span style="color: #888888;">    ↓ <span class="fragment highlight-blue custom bold">probability distribution</span></span></p>
<p><strong>Generalized Linear Model (GLM)</strong> <a href="8-glm.html">&mdash; #8 next time</a></p>
<p><span style="color: #888888;">    ↓ individual difference, random effect</span></p>
<p><strong>Generalized Linear Mixed Model (GLMM)</strong></p>
<p><span style="color: #888888;">    ↓ flexible modelling</span></p>
<p><strong>Hierarchical Bayesian Model (HBM)</strong></p>
<p><cite><a href="https://amzn.to/33suMIZ">データ解析のための統計モデリング入門</a> 久保拓弥 2012 より改変</cite></p>

</section>
<section>
<h2 id="probability-distribution">Probability distribution</h2>
<p>The relationship between phenomena and their frequencies.</p>
<dl>
<dt>empirical distribution</dt>
<dd>created by collecting samples.<br></dd>
<dd>e.g., rolling a dice 12 times, heights of 1000 students:</dd>
</dl>
<p><img src="./figure/distribution-1.png" alt="plot of chunk distribution"></p>
<dl>
<dt>theoretical distribution</dt>
<dd>described with math equation and a few parameters.</dd>
</dl>

</section>
<section>
<h2 id="random-variable-x-follows-probability-distribution-f">Random variable $X$ follows probability distribution $f$</h2>
<p>$X \sim f(\theta)$</p>
<p>e.g.,<br>
The number of heads in tossing 3 fair coins $X$ <strong>follows binomial distribution</strong>.<br>
$X \sim \text{Binomial}(n = 3, p = 0.5)$</p>
<div class="column-container">
  <div class="column" style="flex-shrink: 2.0;">
<p><img src="./figure/dbinom-1.png" alt="plot of chunk dbinom"></p>
  </div>
  <div class="column" style="padding-top: 10px;">
\[\begin{split}
\text{Prob}(X = k) &= \binom n k p^k (1 - p)^{n - k} \\
k &\in \{0, 1, 2, \ldots, n\}
\end{split}\]
  </div>
</div>
<p>Let&rsquo;s experiment.</p>

</section>
<section>
<h2 id="record-repeated-trials">Record repeated trials</h2>
<p>The number of heads observed in tossing 3 fair coins: $X$</p>
<p>trial 1: <strong>H</strong> T <strong>H</strong> → $X = 2$<br>
trial 2: T T T → $X = 0$<br>
trial 3: <strong>H</strong> T T → $X = 1$, subsequently, $2, 1, 3, 0, 2, \ldots$</p>
<p><img src="./figure/rbinom-1.png" alt="plot of chunk rbinom"></p>
<div style="text-align: right;">
It approaches asymptotically to <b>binomial distribution</b>.<br>
0 and 3 is rare. 1 and 2 are three times more likely.
</div>
</section>
<section>
<h2 id="you-can-generate-similar-values-without-tossing-coins">You can generate similar values without tossing coins</h2>
<ul>
<li>The number of heads $X$ observed in tossing 3 fair coins.</li>
<li>Random samples $X$ from the binomial distribution with $n = 3, p = 0.5$.</li>
</ul>
<div class="column-container">
  <div class="column" style="flex-shrink: 2.0;">
<img src="figure/dbinom-1.png" alt="plot of chunk dbinom">
  </div>
  <div class="column" style="padding-top: 10px;">
$X \sim \text{Binomial}(n = 3, p = 0.5)$
<p>   ↓ sample</p>
<p>{2, 0, 1, 2, 1, 3, 0, 2, &hellip;}</p>
  </div>
</div>
<p>These are so similar that we can say<br>
&ldquo;The number of heads in <em>n</em> tosses follows binary distribution.&rdquo;</p>
<p>Conversely, we can understand it like<br>
&ldquo;Random variable of binomial distribution is the number of successes in <em>n</em> trials.&rdquo;</p>

</section>
<section>
<h2 id="a-kind-of-statistical-modelling">A kind of statistical modelling</h2>
<p>Tossing 3 fair coins repeatedly {2, 0, 1, 2, 1, 3, 0, 2, &hellip;}</p>
<p>   ↓ describe with only two parameters. information reduction.</p>
<p>Can reproduce with binary distribution with $n = 3, p = 0.5$</p>
<figure>
<img src="../tokiomarine2021/math-model.drawio.svg" width="900"><br>
<figcaption><cite>「データ分析のための数理モデル入門」江崎貴裕 2020 より改変</cite></figcaption>
</figure>
<p>Any other probability distributions related to real phenomena like this?</p>

</section>
<section>
<h2 id="major-probability-distributions-and-related-phenomena">Major probability distributions and related phenomena</h2>
<dl>
<dt>Discrete uniform distribution</dt>
<dd>コインの表裏、サイコロの出目1–6</dd>
<dt>Negative binomial distribution (Geometric distribution if n = 1)</dt>
<dd>成功率pの試行が初めて成功するまでの失敗回数</dd>
<dt>Binomial distribution</dt>
<dd>成功率p、試行回数nのうちの成功回数</dd>
<dt>Poisson distribution</dt>
<dd>単位時間あたり平均$\lambda$回起こる事象の発生回数</dd>
<dt>Gamma distribution (Exponential distribution if k = 1)</dt>
<dd>ポアソン過程でk回起こるまでの待ち時間</dd>
<dt>Normal/Gaussian distribution</dt>
<dd>確率変数の和、平均値</dd>
</dl>

</section>
<section>
<h2 id="discrete-uniform-distribution">Discrete uniform distribution</h2>
<p>同じ確率で起こるn通りの事象のうちXが起こる確率</p>
<p>e.g., コインの表裏、サイコロの出目1–6</p>
<p><img src="./figure/dunif-1.png" alt="plot of chunk dunif"></p>
<p>🔰 一様分布になりそうな例を考えてみよう</p>

</section>
<section>
<h2 id="geometric-textgeomp">Geometric $~\text{Geom}(p)$</h2>
<p>成功率pの試行が初めて成功するまでの失敗回数</p>
<p>e.g., コイントスで表が出るまでに何回裏が出るか</p>
<p><img src="./figure/geometric-1.png" alt="plot of chunk geometric"></p>
<p>\[
\text{Prob}(X = k \mid p) = p (1 - p)^k
\]</p>
<p>「初めて成功するまでの試行回数」とする定義もある。</p>
<p>🔰 幾何分布になりそうな例を考えてみよう</p>

</section>
<section>
<h2 id="負の二項分布-textnbn-p">負の二項分布 $~\text{NB}(n, p)$</h2>
<p>成功率pの試行がn回成功するまでの失敗回数X。
n = 1 のとき幾何分布と一致。</p>
<p><img src="./figure/nbinom-1.png" alt="plot of chunk nbinom"></p>
<p>\[
\text{Prob}(X = k \mid n,~p) = \binom {n + k - 1} k p^n (1 - p)^k
\]</p>
<p>失敗回数ではなく試行回数を変数とする定義もある。</p>
<p>🔰 負の二項分布になりそうな例を考えてみよう</p>
<!--
平均$\lambda$がガンマ分布でばらついたポアソン分布、とも解釈できる。<br>
($k \to \infty$でポアソン分布と一致)
-->

</section>
<section>
<h2 id="二項分布-textbinomialnp">二項分布 $~\text{Binomial}(n,~p)$</h2>
<p>確率$p$で当たるクジを$n$回引いてX回当たる確率。平均は$np$。</p>
<p><img src="./figure/dbinom-n-1.png" alt="plot of chunk dbinom-n"></p>
<p>\[
\text{Prob}(X = k \mid n,~p) = \binom n k p^k (1 - p)^{n - k}
\]</p>
<p>🔰 二項分布になりそうな例を考えてみよう</p>

</section>
<section>
<h2 id="ポアソン分布-textpoissonlambda">ポアソン分布 $~\text{Poisson}(\lambda)$</h2>
<p>平均$\lambda$で単位時間(空間)あたりに発生する事象の回数。</p>
<p>e.g., 1時間あたりのメッセージ受信件数、メッシュ区画内の生物個体数</p>
<p><img src="./figure/dpoisson-1.png" alt="plot of chunk dpoisson"></p>
<p>\[
\text{Prob}(X = k \mid \lambda) = \frac {\lambda^k e^{-\lambda}} {k!}
\]</p>
<p>二項分布の極限 $(\lambda = np;~n \to \infty;~p \to 0)$。<br>
めったに起きないことを何回も試行するような感じ。</p>

</section>
<section>
<h2 id="指数分布-textexplambda">指数分布 $~\text{Exp}(\lambda)$</h2>
<p>ポアソン過程の事象の発生間隔。平均は $1 / \lambda$ 。</p>
<p>e.g., メッセージの受信間隔、道路沿いに落ちてる手袋の間隔</p>
<p><img src="./figure/dexp-1.png" alt="plot of chunk dexp"></p>
<p>\[
\text{Prob}(x \mid \lambda) = \lambda e^{-\lambda x}
\]</p>
<p>幾何分布の連続値版。</p>
<p>🔰 ポアソン分布・指数分布になりそうな例を考えてみよう</p>

</section>
<section>
<h2 id="ガンマ分布-textgammaklambda">ガンマ分布 $~\text{Gamma}(k,~\lambda)$</h2>
<p>ポアソン過程の事象k回発生までの待ち時間</p>
<p>e.g., メッセージを2つ受信するまでの待ち時間</p>
<p><img src="./figure/dgamma-1.png" alt="plot of chunk dgamma"></p>
<p>\[
\text{Prob}(x \mid k,~\lambda) = \frac {\lambda^k x^{k - 1} e^{-\lambda x}} {\Gamma(k)}
\]</p>
<p>指数分布をkのぶん右に膨らませた感じ。<br>
shapeパラメータ $k = 1$ のとき指数分布と一致。</p>

</section>
<section>
<h2 id="正規分布-mathcalnmusigma">正規分布 $~\mathcal{N}(\mu,~\sigma)$</h2>
<p>平均 $\mu$、標準偏差 $\sigma$ の美しい分布。よく登場する。<br>
e.g., $\mu = 50, ~\sigma = 10$ (濃い灰色にデータの95%, 99%が含まれる):</p>
<p><img src="./figure/gaussian-1.png" alt="plot of chunk gaussian"></p>
<p>\[
\text{Prob}(x \mid \mu,~\sigma) = \frac 1 {\sqrt{2 \pi \sigma^2}} \exp \left(\frac {-(x - \mu)^2} {2\sigma^2} \right)
\]</p>

</section>
<section>
<h2 id="正規分布に近づくものがいろいろある">正規分布に近づくものがいろいろある</h2>
<p>標本平均の反復(<strong>中心極限定理</strong>);
e.g., 一様分布 [0, 100) から40サンプル</p>
<p><img src="./figure/central-limit-1.png" alt="plot of chunk central-limit"></p>
<p>大きい$n$の二項分布</p>
<p><img src="./figure/binom-normal-1.png" alt="plot of chunk binom-normal"></p>

</section>
<section>
<h2 id="正規分布に近づくものがいろいろある">正規分布に近づくものがいろいろある</h2>
<p>大きい$\lambda$のポアソン分布</p>
<p><img src="./figure/poisson-normal-1.png" alt="plot of chunk poisson-normal"></p>
<p>平均値固定なら$k$が大きくなるほど左右対称に尖るガンマ分布</p>
<p><img src="./figure/gamma-normal-1.png" alt="plot of chunk gamma-normal"></p>

</section>
<section>
<h2 id="major-probability-distributions-and-related-phenomena">Major probability distributions and related phenomena</h2>
<figure style="float: right;">
<img src="../tokiomarine2021/math-model.drawio.svg" width="420"><br>
</figure>
<dl>
<dt>Discrete uniform distribution</dt>
<dd>コインの表裏、サイコロの出目1–6</dd>
<dt>Negative binomial distribution (Geometric distribution if n = 1)</dt>
<dd>成功率pの試行が初めて成功するまでの失敗回数</dd>
<dt>Binomial distribution</dt>
<dd>成功率p、試行回数nのうちの成功回数</dd>
<dt>Poisson distribution</dt>
<dd>単位時間あたり平均$\lambda$回起こる事象の発生回数</dd>
<dt>Gamma distribution (Exponential distribution if k = 1)</dt>
<dd>ポアソン過程でk回起こるまでの待ち時間</dd>
<dt>Normal/Gaussian distribution</dt>
<dd>確率変数の和、平均値</dd>
</dl>

</section>
<section>
<h2 id="現実には確率分布に従わないことが多い">現実には、確率分布に「従わない」ことが多い</h2>
<p>植物100個体から8個ずつ種子を取って植えたら全体で半分ちょい発芽。<br>
親1個体あたりの生存数は<span style="color: #56B4E9;">n=8の二項分布</span>になるはずだけど、<br>
極端な値(全部死亡、全部生存)が多かった。</p>
<img src="figure/overdispersion-1.png" alt="plot of chunk overdispersion">
<p>「それはなぜ？」と考えて要因を探るのも統計モデリングの仕事。<br>
<strong>「普通はこれに従うはず」を理解してこそ</strong>できる思考。</p>

</section>
<section>
<h2 id="pseudo-random-number-generator">Pseudo Random Number Generator</h2>
<p>コンピューター上でランダム<strong>っぽい</strong>数値を出力する装置。<br>
実際には<strong>決定論的</strong>に計算されているので、<br>
シード(出発点)と呼び出し回数が同じなら出る数も同じになる。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="nf">set.seed</span><span class="p">(</span><span class="m">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">runif</span><span class="p">(</span><span class="m">3L</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 0.9148060 0.9370754 0.2861395</span>
</span></span><span class="line"><span class="cl"><span class="nf">runif</span><span class="p">(</span><span class="m">3L</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 0.8304476 0.6417455 0.5190959</span>
</span></span><span class="line"><span class="cl"><span class="nf">set.seed</span><span class="p">(</span><span class="m">42</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">runif</span><span class="p">(</span><span class="m">6L</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 0.9148060 0.9370754 0.2861395 0.8304476 0.6417455 0.5190959</span>
</span></span></code></pre></div><p>シードに適当な固定値を与えておくことで再現性を保てる。<br>
ただし「このシードじゃないと良い結果が出ない」はダメ。</p>
<p>さまざまな「分布に従う」乱数を生成することもできる。</p>

</section>
<section>
<h2 id="いろんな乱数を生成可視化して感覚を掴もう">いろんな乱数を生成・可視化して感覚を掴もう</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">n</span> <span class="o">=</span> <span class="m">100</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="nf">sample.int</span><span class="p">(</span><span class="m">6</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">replace</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="nf">runif</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">min</span> <span class="o">=</span> <span class="m">0</span><span class="p">,</span> <span class="n">max</span> <span class="o">=</span> <span class="m">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="nf">rgeom</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="nf">rbinom</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="m">3</span><span class="p">,</span> <span class="n">prob</span> <span class="o">=</span> <span class="m">0.5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="nf">rpois</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">lambda</span> <span class="o">=</span> <span class="m">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">mean</span> <span class="o">=</span> <span class="m">50</span><span class="p">,</span> <span class="n">sd</span> <span class="o">=</span> <span class="m">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">p1</span> <span class="o">=</span> <span class="nf">ggplot</span><span class="p">(</span><span class="nf">data.frame</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">p1</span> <span class="o">+</span> <span class="nf">geom_histogram</span><span class="p">()</span> <span class="c1"># for continuous values</span>
</span></span><span class="line"><span class="cl"><span class="n">p1</span> <span class="o">+</span> <span class="nf">geom_bar</span><span class="p">()</span>       <span class="c1"># for discrete values</span>
</span></span></code></pre></div><p>🔰 小さい <code>n</code> から徐々に大きくして変化を確認しよう。</p>
<p>🔰 ほかのオプションもいろいろ変えて変化を確認しよう。</p>
<p>🔰 1%の当たりを狙って10連ガチャを回す人が100万人いたら、<br>
全部はずれ、1つ当たり、2つ当たり&hellip; の人はどれくらいいるか？</p>
<p>(Quartoでどうまとめるか、腕の見せ所)</p>

</section>
<section>
<h2 id="fitting-probability-distributions-to-data">Fitting probability distributions to data</h2>
<p>The number of seeds were counted for each of 50 plant individuals.<br>
Individual A has 2 seeds, B has 4 seeds, &hellip;</p>
<p><img src="./figure/poisson-seed-1.png" alt="plot of chunk poisson-seed"></p>
<p>This count data looks <span class="fragment custom blur">Poisson</span>-distributed.<br>
What is the optimal $\lambda$ value?</p>

</section>
<section>
<h2 id="fitting-probability-distributions-to-data">Fitting probability distributions to data</h2>
<p>The number of seeds were counted for each of 50 plant individuals.<br>
Individual A has 2 seeds, B has 4 seeds, &hellip;</p>
<p><img src="./figure/poisson-seed-lambda-1.png" alt="plot of chunk poisson-seed-lambda"></p>
<p>This count data looks Poisson-distributed.<br>
What is the optimal $\lambda$ value?</p>
<p>Observations in black.
<span style="color: #56B4E9;">Poisson distribution in blue</span>.
$\lambda \approx 3$ looks good.</p>

</section>
<section>
<h2 id="likelihood-a-measure-for-goodness-of-fit">Likelihood: a measure for goodness-of-fit</h2>
<p>The probability to observe the data $D$ given the model $M$.<br>
$\text{Prob}(D \mid M)$</p>
<p><strong>Likelihood function</strong> is the same probability from different viewpoints:</p>
<ul>
<li>as a function of model $M$ given the data $D$,<br>
$L(M \mid D)$<br></li>
<li>as a function of parameters $\theta$,<br>
$L(\theta \mid D)$ or $L(\theta)$</li>
</ul>

</section>
<section>
<h2 id="example-of-likelihood-calculation">Example of likelihood calculation</h2>
<p>Data $D$: 4 heads (H) and 1 tail (T) in tossing a coin 5 times</p>
<p>Assuming the probability of coming up head $p = 0.5$:</p>
<div>\[\begin{split}
L(0.5 \mid D)
  &= \binom 5 1 \times \text{Prob}(H \mid 0.5) ^ 4 \times \text{Prob}(T \mid 0.5) ^ 1 \\
  &= 5 \times 0.5 ^ 4 \times 0.5 ^ 1 = 0.15625
\end{split}\]</div>
<p>Assuming the probability of coming up head $p = 0.8$:</p>
<div>\[\begin{split}
L(0.8 \mid D)
  &= \binom 5 1 \times \text{Prob}(H \mid 0.8) ^ 4 \times \text{Prob}(T \mid 0.8) ^ 1 \\
  &= 5 \times 0.8 ^ 4 \times 0.2 ^ 1 = 0.4096
\end{split}\]</div>
<p>$L(0.8 \mid D) &gt; L(0.5 \mid D)$</p>
<p>$p = 0.8$ is more likely.</p>

</section>
<section>
<h2 id="likelihood-in-the-example-of-poisson-distribution">Likelihood in the example of Poisson distribution</h2>
<p>The number of seeds were counted for each of 50 plant individuals.</p>
<div>\[\begin{split}
L(\lambda \mid D)
  = \prod _i ^n \text{Prob}(X_i \mid \lambda)
  = \prod _i ^n \frac {\lambda ^ {X_i} e ^ {-\lambda}} {X_i !}
\end{split}\]</div>
<p><img src="./figure/poisson-seed-likelihood-1.png" alt="plot of chunk poisson-seed-likelihood"></p>
<p>OK, $\lambda = 3$ is better than the other two. What is the best.</p>

</section>
<section>
<h2 id="umuaximum-uluikelihood-ueustimation"><u>M</u>aximum <u>L</u>ikelihood <u>E</u>stimation</h2>
<p><strong>Log likelihood</strong> is often easier to handle.<br>
Solving the differential equation for $\lambda$ &hellip;&hellip; finds <strong>the sample mean</strong></p>
<div>\[\begin{split}
\log L(\lambda \mid D)
  &= \sum _i ^n \left[ X_i \log (\lambda) - \lambda - \log (X_i !) \right] \\
\frac {\mathrm d \log L(\lambda \mid D)} {\mathrm d \lambda}
  &= \frac 1 \lambda \sum _i ^n X_i - n = 0 \\
\hat \lambda &= \frac 1 n \sum _i ^n X_i
\end{split}\]</div>
<p><img src="./figure/poisson-mle-1.png" alt="plot of chunk poisson-mle"></p>

</section>
<section>
<h2 id="mle-does-not-give-you-true-λ">MLE does not give you “true λ”</h2>
<p>The data was actually generated from “$X \sim \text{Poisson}(\lambda = 3.0)$”.</p>
<p>By replicating &ldquo;sample 50 individuals → MLE&rdquo; 1,000 times,<br>
we find great variability in estimation and empirical distributions:</p>
<p><img src="./figure/poisson-mle-repl-1.png" alt="plot of chunk poisson-mle-repl"></p>
<p>Note: Fitting to each sample looks not bad!</p>

</section>
<section>
<h2 id="alleviated-by-increasing-sample-size">Alleviated by increasing sample size</h2>
<p>1,000 replications of MLE with $n$ individuals from $X \sim \text{Poisson}(\lambda = 3.0)$:</p>
<p><img src="./figure/poisson-mle-nsam-1.png" alt="plot of chunk poisson-mle-nsam"></p>
<p>Q. How much is enough?<br>
A. Depends on what you estimate, acceptable error range, etc.</p>

</section>
<section>
<h2 id="mathematical-models-in-data-science">Mathematical models in data science</h2>
<blockquote>
<p>All models are wrong, but some are useful. &mdash; George E. P. Box</p>
</blockquote>
<figure>
<img src="../tokiomarine2021/math-model.drawio.svg" width="900"><br>
<figcaption><cite>「データ分析のための数理モデル入門」江崎貴裕 2020 より改変</cite></figcaption>
</figure>

</section>
<section>
<h2 id="toolbox-of-statistical-modelling">Toolbox of statistical modelling</h2>
<ul>
<li><strong>Random variable</strong> $X$</li>
<li><strong>Probability distribution</strong> $X \sim f(\theta)$
<ul>
<li><strong>parameters</strong> $\theta$</li>
</ul>
</li>
<li><strong>Likelihood</strong>
<ul>
<li>The probability to observe the data given the model: $\text{Prob}(D \mid M)$</li>
<li>as a function of model given the data → <strong>likelihood function</strong> $L(M \mid D),~L(\theta \mid D)$</li>
<li><strong>Maximum Likelihood Estimation</strong> to fit parameters $\hat \theta$</li>
</ul>
</li>
</ul>

</section>
<section>
<h2 id="-challenge-1-likelihood">🔰 Challenge 1: likelihood</h2>
<p>Rolling a dice 10 times, 3 sixes were observed.</p>
<ol>
<li>
<p>Calculate likelihood assuming the probability to come up 6 $p = 1/6$.</p>
</li>
<li>
<p>Calculate likelihood assuming the probability to come up 6 $p = 0.2$.</p>
</li>
<li>
<p>Draw a graph with $p$ as horizontal axis, log likelihood as vertical axis.</p>
</li>
<li>
<p>Estimate $p$ with MLE.<br>
Excellent, if solved with math; Good, if solved with R; OK, by eye or intuition.</p>
</li>
</ol>
<dl>
<dt>Hint</dt>
<dd>$\binom 5 2 = {}_5 \mathrm{C} _2 = 10$ can be achieved with <code>choose(5, 2)</code> in R.</dd>
</dl>

</section>
<section>
<h2 id="参考文献">参考文献</h2>
<ul>
<li><a href="https://amzn.to/33suMIZ">データ解析のための統計モデリング入門</a> 久保拓弥 2012</li>
<li><a href="https://amzn.to/3uwx7Pb">StanとRでベイズ統計モデリング</a> 松浦健太郎 2016</li>
<li><a href="https://amzn.to/3o1eCzP">RとStanではじめる ベイズ統計モデリングによるデータ分析入門</a> 馬場真哉 2019</li>
<li><a href="https://amzn.to/3uCxTKo">データ分析のための数理モデル入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3uznzCK">分析者のためのデータ解釈学入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3ty80Kv">統計学を哲学する</a> 大塚淳 2020</li>
<li><a href="https://amzn.to/2Q0f6JQ">科学とモデル&mdash;シミュレーションの哲学 入門</a> Michael Weisberg 2017<br>
(原著: <a href="https://amzn.to/3bdvhuI">Simulation and Similarity</a> 2013)</li>
</ul>
<a href="8-glm.html" class="readmore">
8. Statistical modeling 2: linear regression
</a>

</section>
</div>
</div>
</body>
</html>
