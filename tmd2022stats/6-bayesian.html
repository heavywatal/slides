<!DOCTYPE html>
<html>
<head prefix="og: http://ogp.me/ns#">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">
<title>6. ベイズの定理、事後分布、MCMC — 統計モデリング実習 2022 TMDU</title>
<meta name="author" content="Watal M. Iwasaki">
<meta property="og:title" content="6. ベイズの定理、事後分布、MCMC — 統計モデリング実習 2022 TMDU">
<meta property="og:type" content="article">
<meta property="og:url" content="https://heavywatal.github.io/slides/tmd2022stats/6-bayesian.html">
<meta property="og:image" content="https://avatars.githubusercontent.com/heavywatal">
<meta property="og:description" content="">
<meta property="og:site_name" content="Slide decks — Heavy Watal">
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@heavywatal">
<meta name="twitter:creator" content="@heavywatal">
<link rel="stylesheet" href="/lib/katex/katex.min.css">
<script defer src="/lib/katex/katex.min.js"></script>
<script defer src="/lib/katex/contrib/auto-render.min.js"></script>
<script>
document.addEventListener("DOMContentLoaded", function() {
  renderMathInElement(document.body, {
    delimiters: [
      {left: "\\[", right: "\\]", display: true},
      {left: "$", right: "$", display: false}
    ]
  });
});
</script>
<style>
.katex {
  font-size: 1.12em;
}

.katex-display > .katex {
  text-align: left;
  padding-left: 2rem;
}
</style>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-V60H2JH0G6"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-V60H2JH0G6', { 'anonymize_ip': false });
}
</script>
<link rel="stylesheet" href="/slides/lib/reveal.js/reveal.css">
<script defer src="/slides/lib/reveal.js/reveal.js"></script>
<script defer src="/slides/lib/reveal.js/plugin/notes/notes.js"></script>
<script defer src="/slides/lib/reveal.js/plugin/search/search.js"></script>
<script defer src="/slides/lib/reveal-initialize.js"></script>
<script>
window.addEventListener('DOMContentLoaded', function() {
  Reveal.configure({width: 1333, height: 1000});
  document.querySelector('html').style.fontSize = '222%';
})
</script>
<script defer src="/slides/lib/reload-img-onclick.js"></script>
<link rel="stylesheet" href="/slides/css/style-reveal.css">
<link rel="stylesheet" href="style.css">
</head>
<body>
<div class="reveal">
<div class="slides">
<section>
<h1 id="統計モデリング実習-2022-tmdu"><a href=".">統計モデリング実習 2022 TMDU</a></h1>
<div class="author">
岩嵜 航 (Watal M. Iwasaki, PhD)
</div>
<div class="affiliation">
東北大学 生命科学研究科 進化ゲノミクス分野 特任助教<br>
(Graduate School of Life Sciences, Tohoku University)
</div>
<ol>
<li><a href="1-introduction.html">導入、直線回帰</a>
<li><a href="2-distribution.html">確率分布、擬似乱数生成</a>
<li><a href="3-likelihood.html">尤度、最尤推定</a>
<li><a href="4-glm.html">一般化線形モデル (GLM)</a>
<li><a href="5-glmm.html">個体差、一般化線形混合モデル (GLMM)</a>
<li class="current-deck"><a href="6-bayesian.html">ベイズの定理、事後分布、MCMC</a>
<li><a href="7-stan.html">StanでGLM</a>
<li><a href="8-hbm.html">階層ベイズモデル (HBM)</a>
</ol>
<div class="footnote">
2023-03-25 東京医科歯科大学<br>
<a href="https://heavywatal.github.io/slides/tmd2022stats/">https://heavywatal.github.io/slides/tmd2022stats/</a>
</div>

</section>
<section>
<h2 id="コイントス4回たまたま表が1回だったら">コイントス4回、たまたま表が1回だったら</h2>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">
<dl>
<dt>最尤推定</dt>
<dd>推定結果は最も尤もらしい1点。</dd>
<dd>データが少ないとき過剰適合気味。</dd>
<dd>表が出る確率 p = 0.25 のコインだろう。<br>
(信じ難いけどデータはこう言っている)</dd>
</dl>
<br>
<dl>
<dt>ベイズ推定</dt>
<dd>推定結果は確率分布そのもの。</dd>
<dd>データが少ないなりの不確実さも表現。</dd>
<dd>p = 0.25 らへんである確率は高いが、<br>
p = 0.6 とかである可能性もまあある。
</div>
<div class="column" style="flex-shrink: 1.4;">
</dd>
</dl>
<p><img src="./figure/freq-vs-bayes-1.png" alt="plot of chunk freq-vs-bayes"><img src="./figure/freq-vs-bayes-2.png" alt="plot of chunk freq-vs-bayes"></p>
  </div>
</div>
</section>
<section>
<h2 id="コイントスの回数が増えていったら">コイントスの回数が増えていったら</h2>
<p><strong>最尤推定</strong>: 推定値が真の値に近づいていく</p>
<p><img src="./figure/coin-frequentist-1.png" alt="plot of chunk coin-frequentist"></p>
<p><strong>ベイズ推定</strong>: 確率分布がどんどん尖り、確信が強まる</p>
<p><img src="./figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian"></p>

</section>
<section>
<h2 id="確率おさらい">確率おさらい</h2>
<dl>
<dt>同時分布/結合確率: <span style="font-weight: normal;"> <span style="color: #E69F00;">A</span>かつ<span style="color: #0072B2;">B</span>の確率</span></dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#E69F00}{A} \cap \textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#E69F00}{A}) \text{Prob}(\textcolor{#0072B2}{B})$</dd>
<dt>周辺確率: <span style="font-weight: normal;"> <span style="color: #0072B2;">B</span>によらず<span style="color: #E69F00;">A</span>になる確率</span></dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A}) = \sum_{\textcolor{#0072B2}{B}} \text{Prob}(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B})$</dd>
<dt>条件付き確率: <span style="font-weight: normal;"> <span style="color: #0072B2;">B</span>である条件の下で<span style="color: #E69F00;">A</span>になる確率。重要。</span></dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B}) = \frac {\text{Prob}(\textcolor{#E69F00}{A}, \textcolor{#0072B2}{B})} {\text{Prob}(\textcolor{#0072B2}{B})}$</dd>
</dl>
<p><img src="./figure/venn-1.png" alt="plot of chunk venn"></p>
</section>
<section>
<h2 id="条件付き確率がよくわかる具体例">条件付き確率がよくわかる具体例</h2>
<dl>
<dt><span style="color: #0072B2;">B Brewery</span>のビールが<span style="color: #E69F00;">Awesome</span>な確率</dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{\text{Awesome}} \mid \textcolor{#0072B2}{\text{B Brewery}}) = \frac {\text{Prob}(\textcolor{#E69F00}{\text{Awesome}},~\textcolor{#0072B2}{\text{B Brewery}})} {\text{Prob}(\textcolor{#0072B2}{\text{B Brewery}})}$</dd>
<dd>かなり高い確率。良い醸造所。</dd>
<dt><span style="color: #E69F00;">Awesome</span>なビールが<span style="color: #0072B2;">B Brewery</span>のものである確率</dt>
<dd>$\text{Prob}(\textcolor{#0072B2}{\text{B Brewery}} \mid \textcolor{#E69F00}{\text{Awesome}}) = \frac {\text{Prob}(\textcolor{#E69F00}{\text{Awesome}},~\textcolor{#0072B2}{\text{B Brewery}})} {\text{Prob}(\textcolor{#E69F00}{\text{Awesome}})}$</dd>
<dd>かなり低い確率。Awesomeなビールはほかにもたっくさんある。</dd>
</dl>
<img src="figure/venn-1.png" alt="plot of chunk venn">

</section>
<section>
<h2 id="ベイズの定理">ベイズの定理</h2>
<dl>
<dt>乗法定理</dt>
<dd>$\text{Prob}(\textcolor{#E69F00}{A},~\textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#E69F00}{A} \mid \textcolor{#0072B2}{B})~\text{Prob}(\textcolor{#0072B2}{B}) = \text{Prob}(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A})~\text{Prob}(\textcolor{#E69F00}{A})$</dd>
</dl>
<a href="https://en.wikipedia.org/wiki/Thomas_Bayes">
<img src="../tokiomarine2021/image/Thomas_Bayes.gif" height="200" align="right"></a>
<p>移項するだけで<strong>ベイズの定理</strong>:
<img src="../tokiomarine2021/bayes.drawio.svg" style="padding-left: 1rem;"></p>
<p>宴会場にビールが運ばれてきた。これはどこのブルワリーの？</p>
<dl>
<dt>事前確率: $\text{Prob}(\textcolor{#0072B2}{B})$</dt>
<dd>飲む前、手元のビールが<span style="color: #0072B2;">B Brewery</span>のである確率。</dd>
<dd>↓ 🍻 飲んでみて更新</dd>
<dt>事後確率: $\text{Prob}(\textcolor{#0072B2}{B} \mid \textcolor{#E69F00}{A})$</dt>
<dd>飲んでみて<span style="color: #E69F00;">Awesome</span>だったビールが
<span style="color: #0072B2;">B Brewery</span>のである確率。</dd>
</dl>

</section>
<section>
<h2 id="ベイズの定理-in-感染症検査">ベイズの定理 in 感染症検査</h2>
<ul>
<li>有病率 $\text{Prob}(I)$ : 0.3% (この地域の感染者の割合; 事前確率)</li>
<li>感度 $\text{Prob}(P \mid I)$ : 90% (感染してる人に陽性判定が出る)</li>
<li>特異度 $\text{Prob}(\lnot P \mid \lnot I)$: 99% (感染してない人に陰性判定が出る)</li>
</ul>
<p>さて、陽性適中率(検査陽性の人が実際に感染者である確率)は？</p>
<div>\[\begin{split}
\text{Prob}(I \mid P)
  &= \frac {\text{Prob}(P \mid I)~\text{Prob}(I)} {\text{Prob}(P)} \\
  &= \frac {\text{Prob}(P \mid I)~\text{Prob}(I)}
           {\text{Prob}(P \mid I)~\text{Prob}(I) + \text{Prob}(P \mid \lnot I)~\text{Prob}(\lnot I)} \\
  &= \frac {0.9 \times 0.003} {0.9 \times 0.003 + 0.01 \times 0.997} \approx 0.21
\end{split}\]</div>
<p>感染者を隔離するスクリーニング目的では使いものにならない性能。</p>
<p>🔰 同様に $\text{Prob}(\lnot I \mid \lnot P)$ 陰性的中率を計算してみよう<br>
🔰 計算結果が検査性能だけでなく有病率にも依存することを確認しよう</p>

</section>
<section>
<h2 id="ベイズの定理-in-統計モデリング">ベイズの定理 in 統計モデリング</h2>
<p>
<img src="../tokiomarine2021/bayesian.drawio.svg">
</p>
<p>モデル$M$に対する確信度合いをデータ$D$に基づいて更新する。<br>
モデル$M$を仮説$H$やパラメータ$\theta$に置き換えてもいい。</p>
<p><strong>周辺尤度</strong>は「確率分布の積分は1」を満たすための正規化定数とみなせる。<br>
比例関係だけ抜き出してこう書くことが多い:</p>
<div>\[\begin{align}
\text{Prob}(M \mid D) &\propto \text{Prob}(D \mid M)~\text{Prob}(M) \tag{Model}\\
\text{Prob}(H \mid D) &\propto \text{Prob}(D \mid H)~\text{Prob}(H) \tag{Hypothesis} \\
\text{Prob}(\theta \mid D) &\propto \text{Prob}(D \mid \theta)~\text{Prob}(\theta) \tag{Parameter}
\end{align}\]</div>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-1-事前分布">表が出る確率のベイズ推定: 1. 事前分布</h2>
<p>コイントスを繰り返して、表が出る確率pをベイズ推定したい。</p>
<p>事前分布には<strong>ベータ分布</strong>を採用(理由は後で分かる):</p>
<div>\[\begin{split}
\text{Beta}(p \mid a, b) =
   \frac{\Gamma(a + b)}{\Gamma(a) \Gamma(b)} p^{a-1} (1 - p)^{b-1}
\end{split}\]</div>
<p>分布の形は $a,~b$ によって決まる。<br>
ガンマ関数の部分は厳つく見えるけどただの正規化定数。<br>
投げる前なのでとりあえず真っ平らを仮定 $\text{Beta}(p \mid a = 1, b = 1)$:</p>
<div class="column-container">
  <div class="column"></div>
  <div class="column"></div>
  <div class="column">
<img src="figure/prior-beta-1.png" alt="plot of chunk prior-beta" style="vertical-align: middle;">
  </div>
</div>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-2-尤度関数">表が出る確率のベイズ推定: 2. 尤度関数</h2>
<p>4回投げて表が1回だった、というデータで<strong>尤度</strong>を計算(<strong>二項分布</strong>):</p>
<div>\[\begin{split}
\text{Binom}(1 \mid 4,~p) = \binom {1} {4} p^{1} (1 - p)^{3}
\end{split}\]</div>
<p>これに事前分布を掛けて正規化したら事後分布になるはず。</p>
<div class="column-container">
  <div class="column"></div>
  <div class="column">
<img src="figure/likelihood-binom-1.png" alt="plot of chunk likelihood-binom" style="vertical-align: middle;">
&ensp;⨉
  </div>
  <div class="column">
<img src="figure/prior-beta-1.png" alt="plot of chunk prior-beta" style="vertical-align: middle;">
  </div>
</div>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-3-事後分布">表が出る確率のベイズ推定: 3. 事後分布</h2>
<p>なんと、事後分布もベータ分布になる。</p>
<div>\[\begin{split}
\text{Posterior}
  &\propto \text{Binom}(1 \mid 4,~p) \times \text{Beta}(p \mid  1, 1)\\
  &= \binom {1} {4} p^{1} (1 - p)^{3} \times
     \frac{\Gamma(1 + 1)}{\Gamma(1) \Gamma(1)} p^{1-1} (1 - p)^{1-1} \\
  &= C p^{2-1} (1 - p)^{4-1} \\
  &= \text{Beta}(p \mid 2, 4)
\end{split}\]</div>
<p>ベータ分布の形パラメータ$a$が表、$b$が裏の回数分だけ増加。</p>
<div class="column-container">
  <div class="column">
<img src="figure/posterior-beta-1.png" alt="plot of chunk posterior-beta" style="vertical-align: middle;">
&ensp;$\propto$
  </div>
  <div class="column">
<img src="figure/likelihood-binom-1.png" alt="plot of chunk likelihood-binom" style="vertical-align: middle;">
&ensp;⨉
  </div>
  <div class="column">
<img src="figure/prior-beta-1.png" alt="plot of chunk prior-beta" style="vertical-align: middle;">
  </div>
</div>

</section>
<section>
<h2 id="表が出る確率のベイズ推定-4-逐次学習">表が出る確率のベイズ推定: 4. 逐次学習</h2>
<p>さっきの事後分布を事前分布として、さらにデータを集める。</p>
<p>コイントス4回のうち表1回、に基づく<strong>事前分布</strong>: $\text{Beta}(p \mid 2,~4)$</p>
<p>さらに16回投げたら表が7回、の<strong>尤度</strong>: $\text{Binomial}(7 \mid 16,~p)$</p>
<p><strong>事後分布</strong>はまた事前分布と同じ形になる:</p>
<div>\[\begin{split}
\text{Beta}(p \mid 9, 13) \propto
  \text{Binomial}(7 \mid 16,~p) \times \text{Beta}(p \mid 2, 4)
\end{split}\]</div>
<p>データを加えるたびに更新していける:</p>
<img src="figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian" width="85%">
</section>
<section>
<h2 id="共役事前分布">共役事前分布</h2>
<p>事後分布が事前分布と同じ形なので計算しやすい、という組み合わせ。</p>
<table>
<thead>
<tr>
<th>尤度関数</th>
<th>共役事前分布</th>
</tr>
</thead>
<tbody>
<tr>
<td>二項分布</td>
<td>ベータ分布</td>
</tr>
<tr>
<td>ポアソン分布</td>
<td>ガンマ分布</td>
</tr>
<tr>
<td>正規分布</td>
<td>ガンマ分布</td>
</tr>
<tr>
<td>正規分布 (分散既知)</td>
<td>正規分布</td>
</tr>
</tbody>
</table>
<p>共役事前分布を使うことが常に最善とは限らない。<br>
計算コストがかかっても<strong>無情報事前分布</strong>を使う風潮。</p>

</section>
<section>
<h2 id="事後分布を用いた推定">事後分布を用いた推定</h2>
<div class="column-container">
  <div class="column" style="flex-shrink: 1.0;">
<dl>
<dt>区間推定</dt>
<dd>幅のある推定値を提示</dd>
<dd>e.g., 95%ベイズ確信区間:<br>
等裾事後確信区間 (<u>E</u>qual-<u>T</u>ailed <u>I</u>nterval)<br>
最高密度区間 (<u>H</u>ighest <u>D</u>ensity <u>I</u>nterval)</dd>
<dt>点推定</dt>
<dd>値を1点だけ提示</dd>
<dd>e.g.,<br>
事後確率最大値 (<u>M</u>aximum <u>A</u> <u>P</u>osteriori)<br>
事後中央値 (Posterior <u>Med</u>ian)<br>
事後期待値 (<u>E</u>xpected <u>A</u> <u>P</u>osteriori)
</div>
<div class="column" style="flex-shrink: 1.3;">
</dd>
</dl>
<p><img src="./figure/integrate-1.png" alt="plot of chunk integrate"></p>
  </div>
</div>
</section>
<section>
<h2 id="ベイズ推定の中間まとめ">ベイズ推定の中間まとめ</h2>
<ul>
<li>推定結果は<strong>事後分布</strong> ∝ 尤度関数。
<ul>
<li>広がり具合によって不確実性も表現できる。</li>
<li><strong>逐次学習</strong>で尖っていき、確信が強まる。</li>
</ul>
</li>
</ul>
<img src="figure/coin-bayesian-1.png" alt="plot of chunk coin-bayesian" width="70%">
<hr>
<p>コイン投げモデルのベータ分布は美しい例。<br>
→ 解析的(数学的)に解ける。</p>
<p>実践的なモデル・事後分布はもっと複雑。<br>
→ コンピュータに頼って数値計算: MCMC</p>

</section>
<section>
<h2 id="mcmc-umuarcov-ucuhain-umuonte-ucuarlo">MCMC: <u>M</u>arcov <u>C</u>hain <u>M</u>onte <u>C</u>arlo</h2>
<a href="https://en.wikipedia.org/wiki/Andrey_Markov">
<img src="../tokiomarine2021/image/AAMarkov.jpg" height="240" align="right"></a>
<dl>
<dt>マルコフ連鎖</dt>
<dd>次の時点の挙動が現在の値だけで決定されるような確率過程。</dd>
<dd>$\ldots \to X_{t - 2} \to X_{t - 1} \to X_{t} \to X_{t + 1}$</dd>
<dd>$\text{Prob}(X_{t+1} \mid X_{t}, X_{t-1}, X_{t-2}, \ldots) = \text{Prob}(X_{t+1} \mid X_{t})$</dd>
<dd>e.g., すごろく</dd>
<dt>モンテカルロ法</dt>
<dd>乱数を用いた計算方法の総称。</dd>
<dd><a href="https://en.wikipedia.org/wiki/Monte_Carlo_Casino">
<img src="../tokiomarine2021/image/Real_Monte_Carlo_Casino.jpg" height="300"></a>
<a href="https://en.wikipedia.org/wiki/Stanislaw_Ulam">
<img src="../tokiomarine2021/image/Stanislaw_Ulam.jpg" height="300"></a>
<a href="https://en.wikipedia.org/wiki/John_von_Neumann">
<img src="../tokiomarine2021/image/John_von_Neumann.jpg" height="300"></a>
<a href="https://en.wikipedia.org/wiki/Nicholas_Metropolis">
<img src="../tokiomarine2021/image/Nicholas_Metropolis.png" height="300"></a>
</dd>
</dl>

</section>
<section>
<h2 id="モンテカルロ法は乱数を用いた計算方法">モンテカルロ法は乱数を用いた計算方法</h2>
<p>e.g., 半径1の円の面積</p>
<p>数学を知っていれば $\pi r ^ 2 \approx 3.14159$</p>
<p>面積4の正方形に400個の一様乱数を打ち込んだら318個が円に乗った:<br>
$4 \times \frac {318} {400} = 3.18$</p>
<p><img src="./figure/circle-1.png" alt="plot of chunk circle"></p>

</section>
<section>
<h2 id="変な分布もモンテカルロ法で扱えそう">変な分布もモンテカルロ法で扱えそう</h2>
<p>e.g., 確率密度分布に従って変数Xを集める(棄却サンプリング)。</p>
<div>
<img src="figure/mcpdf-2.png" alt="plot of chunk mcpdf" style="vertical-align: middle;">
$\;\sim\;$
<img src="figure/mcpdf-1.png" alt="plot of chunk mcpdf" style="vertical-align: middle;">
</div>
<p>でも、ハズレの値もけっこう引いてしまう。</p>

</section>
<section>
<h2 id="次元の呪い-高次元になるほど当たりにくくなる">次元の呪い: 高次元になるほど当たりにくくなる</h2>
<p>(N次元球の体積 / N次元の立方体) はゼロに近づいていく。</p>
<img src="figure/circle-1.png" alt="plot of chunk circle" align="right">
<ul>
<li>2次元: $\frac {\pi r ^ 2} {(2r) ^ 2} = \frac \pi 4 \approx 0.79$</li>
<li>3次元: $\frac {\frac 4 3 \pi r ^ 3} {(2r) ^ 3} = \frac \pi 6 \approx 0.52$</li>
<li>N次元: $\frac {\frac {\pi ^ {N/2}} {\Gamma (N/2 + 1)} r ^ N} {(2r) ^ N} = \frac {\pi ^ {N/2}} {2^N \Gamma (N/2 + 1)} \to 0$</li>
</ul>
<p>パラメータが増えると計算量(≈乱数の無駄撃ち)が急増。</p>
<hr>
<p>密度の高い「当たり」付近を効率よく探索したい。<br>
「当たり」は「当たり」の近くにありがちだろう。<br>
→ マルコフ連鎖が使えそう</p>

</section>
<section>
<h2 id="metropolis--hastings法-mh法">Metropolis&ndash;Hastings法 (MH法)</h2>
<ol start="0">
<li>パラメータ $\theta$ の初期値を選ぶ</li>
<li>$\theta$ をちょっと増減させて $\theta_\text{new}$ を作る</li>
<li>それぞれ尤度を計算し、比較。
<ul>
<li>$L(\theta_\text{new}) \ge L(\theta)$ なら $\theta_\text{new}$ を即採択</li>
<li>$L(\theta_\text{new}) &lt; L(\theta)$ でも
確率 $r = \frac {L(\theta_\text{new})} {L(\theta)}$ で  $\theta_\text{new}$ を採択</li>
</ul>
</li>
<li>$\theta_\text{new}$ が採択されたら $\theta$ を更新。手順1に戻る。</li>
</ol>
<p><img src="./figure/metropolis-1.png" alt="plot of chunk metropolis"></p>
</section>
<section>
<h2 id="採択されたパラメータ値の軌跡">採択されたパラメータ値の軌跡</h2>
<p>尤度が高い方にただ向かうだけでなく、結構うろつく。<br>
通ったパラメータ値を集めるといい感じの分布が得られる。</p>
<p><img src="./figure/metropolis-trajectory-.gif" alt="plot of chunk metropolis-trajectory"></p>

</section>
<section>
<h2 id="尤度に比例する事後分布からサンプルしたのと等価">尤度に比例する事後分布からサンプルしたのと等価</h2>
<p>全体にばら撒く棄却サンプリングよりも効率よく集められる。<br>
が、パラメータ1つの1次元ではご利益はわかりにくい。</p>
<div>
<img src="figure/propto-lik-1.png" alt="plot of chunk propto-lik" style="vertical-align: middle;">
$\;\sim\;$
<img src="figure/propto-lik-2.png" alt="plot of chunk propto-lik" style="vertical-align: middle;">
$\;\propto\;$
<img src="figure/propto-lik-3.png" alt="plot of chunk propto-lik" style="vertical-align: middle;">
</div>
<p>パラメータが複数ある場合は？</p>

</section>
<section>
<h2 id="gibbs-sampling">Gibbs Sampling</h2>
<p>パラメータが複数の場合「ほかを固定してひとつ更新」を繰り返す。</p>
<p>e.g., 二次元正規分布。(-2, 2) からスタート。</p>
<p><img src="./figure/gibbs-.gif" alt="plot of chunk gibbs"></p>

</section>
<section>
<h2 id="何回やっても似たような結果になってほしい">何回やっても似たような結果になってほしい</h2>
<p>乱数や初期値によって偶々、じゃないことを確認したい。</p>
<p>e.g., <code>chains = 3</code> 。ほぼ同じところをうろうろ:</p>
<p><img src="./figure/chains-1.png" alt="plot of chunk chains"></p>
<p>収束(convergence)の判定については後ほど。</p>

</section>
<section>
<h2 id="初期値の影響が消えるまでウォーミングアップ">初期値の影響が消えるまでウォーミングアップ</h2>
<p>定常分布の山に到達してからが本番。</p>
<p>e.g., <code>iter_warmup = 200, iter_sampling = 600</code> で灰色の部分を捨てる:</p>
<p><img src="./figure/warmup-1.png" alt="plot of chunk warmup"></p>
<p>どれくらい長く捨てるべきかは場合による。</p>

</section>
<section>
<h2 id="適度に間引いて自己相関を軽減したい">適度に間引いて自己相関を軽減したい</h2>
<p>直前の値と似すぎていたら独立サンプルとして扱えないので。</p>
<p>e.g., <code>thin = 5</code> で5回に1回だけサンプルする:</p>
<p><img src="./figure/thin-1.png" alt="plot of chunk thin"></p>
<p>間引かなくても大丈夫な場合も、間引いても解決しない場合もある。</p>

</section>
<section>
<h2 id="収束判定">収束判定</h2>
<ul>
<li>複数chainsで異なる初期値から実行し、軌跡を可視化(traceplot)</li>
<li>Gelman-Rubin統計量 $\hat R &lt; 1.05$</li>
<li>Effective Sample Size (ESS) $N_\text{eff} &gt; 100$ per chain</li>
</ul>
<p><img src="./figure/convergence-1.png" alt="plot of chunk convergence"></p>
<p><a href="https://mc-stan.org/docs/cmdstan-guide/diagnose.html"><code>diagnose()</code></a>
みたいな機能が提供されていれば利用する。</p>
<p>実行時に<a href="https://mc-stan.org/misc/warnings.html">警告してもらえること</a>もある。</p>

</section>
<section>
<h2 id="収束自己相関が悪い場合にどう改善するか">収束・自己相関が悪い場合にどう改善するか</h2>
<ul>
<li>小手先の対処
<ul>
<li>iteration (warmup + sampling) をもっと長く</li>
<li>thinを大きくして間引く</li>
</ul>
</li>
<li>ちょっと大掛かり
<ul>
<li>プログラムの書き方を改善する</li>
<li>モデルの構造を見直す</li>
<li>アルゴリズム・ソフトウェアを変える</li>
</ul>
</li>
</ul>

</section>
<section>
<h2 id="mcmcの方法いろいろ">MCMCの方法いろいろ</h2>
<p>採択率を高め、早く収束するように改良されてきている。</p>
<ul>
<li>Metropolis&ndash;Hastings法
<ul>
<li>Gibbs Sampling</li>
<li>Hamiltonian Monte Carlo (HMC)
<ul>
<li>No-U-Turn Sampler (NUTS)</li>
</ul>
</li>
</ul>
</li>
</ul>
</section>
<section>
<h2 id="mcmcソフトウェア">MCMCソフトウェア</h2>
<ul>
<li><a href="https://www.mrc-bsu.cam.ac.uk/software/bugs/">BUGS</a>
<ul>
<li>クローズドソースで、ほぼWindows専用。</li>
</ul>
</li>
<li><a href="https://mcmc-jags.sourceforge.io/">JAGS</a>
<ul>
<li>オープンソースで、さまざまなOS・言語から利用可能。</li>
<li>マニュアルや用例が不足。</li>
</ul>
</li>
<li><a href="https://mc-stan.org/"><strong>Stan</strong></a> 👈
<ul>
<li>オープンソースで、さまざまなOS・言語から利用可能。</li>
<li>開発も利用も活発。マニュアルや用例も充実。</li>
<li>HMC/NUTSにより早く収束。</li>
</ul>
</li>
<li><a href="https://docs.pymc.io/">PyMC3</a></li>
<li><a href="https://num.pyro.ai/">NumPyro</a></li>
<li><a href="https://www.tensorflow.org/probability/">TensorFlow Probability</a></li>
</ul>

</section>
<section>
<h2 id="ベイズ推定とmcmcまとめ">ベイズ推定とMCMCまとめ</h2>
<ul>
<li>推定結果は<strong>事後分布</strong> ∝ 尤度関数。
<ul>
<li>広がり具合によって不確実性も表現できる。</li>
<li><strong>逐次学習</strong>で尖っていき、確信が強まる。</li>
</ul>
</li>
<li>コンピュータに頼った計算方法としてのモンテカルロ法。
<ul>
<li>高次元・変な形の分布でも効率よくサンプルできるかが肝。</li>
<li>ソフトウェアの代表は<strong>Stan</strong> → これから見ていく</li>
</ul>
</li>
</ul>

</section>
<section>
<h2 id="stan">Stan</h2>
<a href="https://mc-stan.org/">
<img src="/slides/image/stan/logo_name.png" width="180" align="right">
</a>
<ul>
<li>Stan言語で<strong>モデルを柔軟に記述</strong>できる。</li>
<li>C++で書かれていて<strong>高速に動作</strong>。</li>
<li>RやPythonなどから呼び出して使うのが便利。</li>
</ul>
<h2 id="r-interface">R Interface</h2>
<dl>
<dt><a href="http://mc-stan.org/rstan/">RStan</a></dt>
<dd><a href="https://heavywatal.github.io/rstats/rcpp.html">Rcpp</a>を介して<a href="https://github.com/stan-dev/rstan/tree/develop/StanHeaders">StanHeaders</a>を取り込んだパッケージ。</dd>
<dt><a href="https://mc-stan.org/cmdstanr/">CmdStanR</a> 👈 今後の主流</dt>
<dd><a href="https://mc-stan.org/users/interfaces/cmdstan">CmdStan</a>
を呼び出し、書き出されたCSVを読み取る。</dd>
</dl>

</section>
<section>
<h2 id="cmdstanr-インストールがちょっと特殊">CmdStanR: インストールがちょっと特殊</h2>
<p>実行の前後にRを再起動してまっさらにすることを推奨。</p>
<ol>
<li>C++言語を扱うためのツールを用意。
<ul>
<li><img height=24 width=24 src="https://cdn.simpleicons.org/apple"></img>
macOS: Command Line Tools (<code>xcode-select --install</code>)</li>
<li><img height=24 width=24 src="https://cdn.simpleicons.org/windows"></img>
Windows: <a href="https://cran.r-project.org/bin/windows/Rtools/">RTools</a>
(Rのバージョンに合わせる)</li>
</ul>
</li>
<li><a href="https://mc-stan.org/cmdstanr/">CmdStanR</a>パッケージをインストール。
(まだCRANに登録されていない):
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="nf">install.packages</span><span class="p">(</span><span class="s">&#34;cmdstanr&#34;</span><span class="p">,</span> <span class="n">repos</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;https://mc-stan.org/r-packages/&#34;</span><span class="p">,</span> <span class="nf">getOption</span><span class="p">(</span><span class="s">&#34;repos&#34;</span><span class="p">)))</span>
</span></span></code></pre></div></li>
<li>CmdStan本体と可視化パッケージのインストール:
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">cmdstanr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">check_cmdstan_toolchain</span><span class="p">(</span><span class="n">fix</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">install_cmdstan</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nf">install.packages</span><span class="p">(</span><span class="s">&#34;bayesplot&#34;</span><span class="p">)</span>
</span></span></code></pre></div></li>
</ol>
<p><a href="https://mc-stan.org/cmdstanr/articles/cmdstanr.html">https://mc-stan.org/cmdstanr/articles/cmdstanr.html</a></p>

</section>
<section>
<h2 id="-とりあえずstanを動かしてみよう">🔰 とりあえずStanを動かしてみよう</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">cmdstanr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">bayesplot</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>This is cmdstanr version 0.5.3
- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr
- CmdStan path: /Users/watal/.cmdstan/cmdstan-2.31.0
- CmdStan version: 2.31.0
</code></pre><pre tabindex="0"><code>This is bayesplot version 1.10.0
</code></pre><p>おおまかな流れ:</p>
<ol>
<li>データ準備</li>
<li>Stan言語でモデルを書く</li>
<li>モデルをコンパイルして機械語に翻訳 → 実行ファイル</li>
<li>実行ファイルにデータを渡してMCMCサンプリング</li>
<li>結果を見る</li>
</ol>
</section>
<section>
<h2 id="説明変数なしのベイズ推定-データ準備">説明変数なしのベイズ推定: データ準備</h2>
<p>表が出る確率 $p=0.7$ のイカサマコインをN回投げたデータを作る。<br>
この $p$ をStanで推定してみよう。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">true_p</span> <span class="o">=</span> <span class="m">0.7</span>
</span></span><span class="line"><span class="cl"><span class="n">N</span> <span class="o">=</span> <span class="m">40L</span>
</span></span><span class="line"><span class="cl"><span class="n">coin_data</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="nf">rbinom</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="n">true_p</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nf">print</span><span class="p">(</span><span class="n">coin_data</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code>$N
[1] 40

$x
 [1] 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1
</code></pre><p>Rならlist型、Pythonならdict型にまとめてStanに渡す。</p>

</section>
<section>
<h2 id="説明変数なしのベイズ推定-stan言語でモデル定義">説明変数なしのベイズ推定: Stan言語でモデル定義</h2>
<p>別ファイルに書いておく。
e.g., <code>coin.stan</code>:</p>
<pre tabindex="0"><code class="language-stan" data-lang="stan">data {
  int&lt;lower=0&gt; N;
  array[N] int x;
}
parameters {
  real&lt;lower=0,upper=1&gt; p;
}
model {
  x ~ binomial(1, p);
}
</code></pre><ul>
<li>いくつかのブロックに分けて記述する:<br>
R/Pythonから受け取る <code>data</code>, 推定する <code>parameter</code>, 本体の <code>model</code>.</li>
<li><a href="https://mc-stan.org/docs/reference-manual/overview-of-data-types.html">変数には型や制約を設定できる</a></li>
<li><a href="https://mc-stan.org/docs/functions-reference/">関数もたくさん用意されている</a></li>
</ul>
</section>
<section>
<h2 id="stan言語の7種のブロック">Stan言語の7種のブロック</h2>
<p>順番厳守。よく使うのは<strong>太字のやつ</strong>。</p>
<ol>
<li><code>functions {...}</code></li>
<li><strong><code>data {...}</code></strong></li>
<li><code>transformed data {...}</code></li>
<li><strong><code>parameters {...}</code></strong></li>
<li><code>transformed parameters {...}</code></li>
<li><strong><code>model {...}</code></strong></li>
<li><code>generated quantities {...}</code></li>
</ol>
<p><a href="https://mc-stan.org/docs/reference-manual/overview-of-stans-program-blocks.html">https://mc-stan.org/docs/reference-manual/overview-of-stans-program-blocks.html</a></p>

</section>
<section>
<h2 id="説明変数なしのベイズ推定-mcmcサンプル">説明変数なしのベイズ推定: MCMCサンプル</h2>
<p>予め実行速度の速い機械語に翻訳(コンパイル):</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">cmdstanr</span><span class="o">::</span><span class="nf">cmdstan_model</span><span class="p">(</span><span class="s">&#34;stan/coin.stan&#34;</span><span class="p">)</span>
</span></span></code></pre></div><p>モデルとデータを使ってMCMCサンプリング:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">fit</span> <span class="o">=</span> <span class="n">model</span><span class="o">$</span><span class="nf">sample</span><span class="p">(</span><span class="n">coin_data</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="m">24601L</span><span class="p">)</span>
</span></span></code></pre></div><p>いろいろオプションはあるけど、ここではデフォルトに任せる:<br>
<code>chains</code>, <code>inits</code>, <code>iter_warmup</code>, <code>iter_samples</code>, <code>thin</code>, &hellip;</p>
<p>問題があったら警告してくれるので<strong>ちゃんと読む</strong>。</p>

</section>
<section>
<h2 id="説明変数なしのベイズ推定-結果を眺める">説明変数なしのベイズ推定: 結果を眺める</h2>
<p><code>parameters</code> ブロックに書いた変数の情報が出てくる。<br>
乱数を使った計算なので(乱数シードを固定しない限り)毎回変わる。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="nf">print</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>
</span></span></code></pre></div><pre tabindex="0"><code> variable   mean median   sd  mad     q5    q95 rhat ess_bulk ess_tail
     lp__ -25.62 -25.35 0.70 0.30 -27.00 -25.13 1.00     1949     2646
     p      0.72   0.72 0.07 0.07   0.60   0.82 1.00     1586     2132
</code></pre><p>真の値に近い $p \approx 0.7$ が得られた
(0.6 から
0.82 である確率が90%)。<br>
$\hat R$ もほぼ1で $N_\text{eff}$ も大きいのでよさそう。</p>
<p><code>lp__</code> はlog posterior(対数事後確率)。後述。</p>
<p>念のため trace plot も確認しておこう→</p>

</section>
<section>
<h2 id="説明変数なしのベイズ推定-trace-plot-確認">説明変数なしのベイズ推定: trace plot 確認</h2>
<p>どのchainも似た範囲を動いていて、しっかり毛虫っぽい:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">draws</span> <span class="o">=</span> <span class="n">fit</span><span class="o">$</span><span class="nf">draws</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">params</span> <span class="o">=</span> <span class="nf">names</span><span class="p">(</span><span class="n">model</span><span class="o">$</span><span class="nf">variables</span><span class="p">()</span><span class="o">$</span><span class="n">parameters</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">bayesplot</span><span class="o">::</span><span class="nf">mcmc_trace</span><span class="p">(</span><span class="n">draws</span><span class="p">,</span> <span class="n">pars</span> <span class="o">=</span> <span class="n">params</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="./figure/stan-binom-traceplot-1.png" alt="plot of chunk stan-binom-traceplot"></p>

</section>
<section>
<h2 id="説明変数なしのベイズ推定-自己相関の確認">説明変数なしのベイズ推定: 自己相関の確認</h2>
<p>2&ndash;3ステップくらいで自己相関がほぼ消えるので問題なし:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">bayesplot</span><span class="o">::</span><span class="nf">mcmc_acf_bar</span><span class="p">(</span><span class="n">draws</span><span class="p">,</span> <span class="n">pars</span> <span class="o">=</span> <span class="n">params</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="./figure/stan-binom-ac-1.png" alt="plot of chunk stan-binom-ac"></p>

</section>
<section>
<h2 id="説明変数なしのベイズ推定-推定結果確認">説明変数なしのベイズ推定: 推定結果確認</h2>
<p>サンプルサイズNが小さいせいか裾野の広い推定結果。<br>
真の$p$の値も含まれている:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">bayesplot</span><span class="o">::</span><span class="nf">mcmc_hist</span><span class="p">(</span><span class="n">draws</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="m">20</span><span class="p">,</span> <span class="n">pars</span> <span class="o">=</span> <span class="n">params</span><span class="p">)</span>
</span></span></code></pre></div><p><img src="./figure/stan-binom-hist-1.png" alt="plot of chunk stan-binom-hist"></p>

</section>
<section>
<h2 id="lp__-log-posterior-とは"><code>lp__</code>: log posterior とは?</h2>
<p><code>model</code> ブロックに次のように書いてあると:</p>
<pre tabindex="0"><code class="language-stan" data-lang="stan">model {
  mu ~ normal(0.0, 10.0);  // prior
  x ~ normal(mu, 1.0);     // likelihood
}
</code></pre><p>内部的には次のような処理が行われている:</p>
<pre tabindex="0"><code class="language-stan" data-lang="stan">target += normal_lpdf(theta | 0.0, 10.0)  // prior
target += normal_lpdf(x | theta, 1.0);    // likelihood
</code></pre><p>つまり、事前確率と尤度の対数の和を取っている。<br>
ベイズの定理により、事後確率はこれに比例する。<br>
<code>lp__</code> はこの <code>target</code> 変数を記録しておいたようなもの。</p>

</section>
<section>
<h2 id="ベイズ推定とmcmc">ベイズ推定とMCMC</h2>
<p>
<img src="../tokiomarine2021/bayesian.drawio.svg">
</p>
<ul>
<li>推定結果は<strong>事後分布</strong> ∝ 尤度関数。
<ul>
<li>広がり具合によって不確実性も表現できる。</li>
<li><strong>逐次学習</strong>で尖っていき、確信が強まる。</li>
</ul>
</li>
<li>コンピュータに頼った計算方法としてのモンテカルロ法。
<ul>
<li>高次元・変な形の分布でも効率よくサンプルできるかが肝。</li>
<li>ソフトウェアの代表は<strong>Stan</strong>。</li>
<li>Stan言語でモデルを書き、RやPythonから動かす。</li>
</ul>
</li>
</ul>
</section>
<section>
<h2 id="参考文献">参考文献</h2>
<ul>
<li><a href="https://amzn.to/33suMIZ">データ解析のための統計モデリング入門</a> 久保拓弥 2012</li>
<li><a href="https://amzn.to/3uwx7Pb">StanとRでベイズ統計モデリング</a> 松浦健太郎 2016</li>
<li><a href="https://amzn.to/3o1eCzP">RとStanではじめる ベイズ統計モデリングによるデータ分析入門</a> 馬場真哉 2019</li>
<li><a href="https://amzn.to/3uCxTKo">データ分析のための数理モデル入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3uznzCK">分析者のためのデータ解釈学入門</a> 江崎貴裕 2020</li>
<li><a href="https://amzn.to/3ty80Kv">統計学を哲学する</a> 大塚淳 2020</li>
</ul>
<a href="7-stan.html" class="readmore">
7. StanでGLM
</a>

</section>
</div>
</div>
</body>
</html>
